"""
åˆ†ææœåŠ¡

å°è£… TradingAgentsGraphï¼Œæä¾›å¼‚æ­¥åˆ†æä»»åŠ¡ç®¡ç†ã€‚
"""
import uuid
import threading
import logging
import json
from pathlib import Path
from datetime import datetime
from typing import Optional, Dict, List
from enum import Enum
from dataclasses import dataclass, field

logger = logging.getLogger(__name__)


class TaskStatus(Enum):
    """ä»»åŠ¡çŠ¶æ€"""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"


@dataclass
class AnalysisTask:
    """åˆ†æä»»åŠ¡"""
    task_id: str
    user_id: str
    ticker: str
    ticker_name: str
    date: str
    status: TaskStatus = TaskStatus.PENDING
    progress: Dict = field(default_factory=dict)
    logs: List[str] = field(default_factory=list)
    result: Optional[Dict] = None
    error: Optional[str] = None
    created_at: str = field(default_factory=lambda: datetime.now().isoformat())
    completed_at: Optional[str] = None
    log_file: Optional[str] = None  # message_tool.log æ–‡ä»¶è·¯å¾„
    cancelled: bool = False  # å–æ¶ˆæ ‡å¿—

    def to_dict(self) -> dict:
        return {
            "task_id": self.task_id,
            "ticker": self.ticker,
            "ticker_name": self.ticker_name,
            "date": self.date,
            "status": self.status.value,
            "progress": self.progress,
            "logs": self.logs[-50:],  # åªè¿”å›æœ€è¿‘50æ¡æ—¥å¿—
            "result": self.result,
            "error": self.error,
            "created_at": self.created_at,
            "completed_at": self.completed_at
        }


class AnalysisService:
    """åˆ†ææœåŠ¡"""

    # åˆ†ææ­¥éª¤å®šä¹‰ï¼ˆç”¨äºè¿›åº¦è¿½è¸ªï¼‰
    ANALYSIS_STEPS = [
        ("market_analyst", "å¸‚åœºåˆ†æå¸ˆ"),
        ("social_analyst", "æƒ…ç»ªåˆ†æå¸ˆ"),
        ("news_analyst", "æ–°é—»åˆ†æå¸ˆ"),
        ("fundamentals_analyst", "åŸºæœ¬é¢åˆ†æå¸ˆ"),
        ("bull_researcher", "çœ‹æ¶¨ç ”ç©¶å‘˜"),
        ("bear_researcher", "çœ‹è·Œç ”ç©¶å‘˜"),
        ("research_manager", "ç ”ç©¶ä¸»ç®¡"),
        ("risky_manager", "æ¿€è¿›é£æ§"),
        ("conservative_manager", "ä¿å®ˆé£æ§"),
        ("neutral_manager", "ä¸­ç«‹é£æ§"),
        ("risk_manager", "é£é™©ä¸»ç®¡"),
        ("consolidation", "ç»¼åˆæŠ¥å‘Š"),
    ]

    def __init__(self):
        """åˆå§‹åŒ–åˆ†ææœåŠ¡"""
        self._tasks: Dict[str, AnalysisTask] = {}
        self._user_tasks: Dict[str, List[str]] = {}  # user_id -> [task_ids]
        self._lock = threading.Lock()

    def start_analysis(
        self,
        user_id: str,
        ticker: str,
        ticker_name: str = "",
        date: Optional[str] = None
    ) -> str:
        """
        å¯åŠ¨åˆ†æä»»åŠ¡

        Args:
            user_id: ç”¨æˆ· ID
            ticker: è‚¡ç¥¨ä»£ç 
            ticker_name: è‚¡ç¥¨åç§°
            date: åˆ†ææ—¥æœŸï¼ˆé»˜è®¤ä»Šå¤©ï¼‰

        Returns:
            task_id: ä»»åŠ¡ ID
        """
        if date is None:
            date = datetime.now().strftime("%Y-%m-%d")

        task_id = str(uuid.uuid4())[:8]

        # åˆ›å»ºä»»åŠ¡
        task = AnalysisTask(
            task_id=task_id,
            user_id=user_id,
            ticker=ticker,
            ticker_name=ticker_name or ticker,
            date=date,
            progress={
                "current_step": None,
                "current_step_name": None,
                "completed_steps": [],
                "total_steps": len(self.ANALYSIS_STEPS)
            }
        )

        with self._lock:
            self._tasks[task_id] = task
            if user_id not in self._user_tasks:
                self._user_tasks[user_id] = []
            self._user_tasks[user_id].append(task_id)

        # åœ¨åå°çº¿ç¨‹ä¸­è¿è¡Œåˆ†æ
        thread = threading.Thread(
            target=self._run_analysis,
            args=(task_id,),
            daemon=True
        )
        thread.start()

        logger.info(f"åˆ†æä»»åŠ¡å·²å¯åŠ¨: {task_id} - {ticker} ({date})")
        return task_id

    # èŠ‚ç‚¹åç§°åˆ°æ­¥éª¤ key çš„æ˜ å°„
    NODE_TO_STEP = {
        "Market Analyst": "market_analyst",
        "Social Analyst": "social_analyst",
        "News Analyst": "news_analyst",
        "Fundamentals Analyst": "fundamentals_analyst",
        "Bull Researcher": "bull_researcher",
        "Bear Researcher": "bear_researcher",
        "Research Manager": "research_manager",
        "Trader": "trader",
        "Risky Analyst": "risky_manager",
        "Safe Analyst": "conservative_manager",
        "Neutral Analyst": "neutral_manager",
        "Risk Judge": "risk_manager",
        "Consolidation Report": "consolidation",
    }

    def _init_results_dir(self, task_id: str) -> tuple:
        """åˆå§‹åŒ–ç»“æœç›®å½•å’Œæ–‡ä»¶ï¼ˆä¸ CLI è¡Œä¸ºä¸€è‡´ï¼‰"""
        from pathlib import Path
        import csv

        task = self._tasks.get(task_id)
        if not task:
            return None, None, None

        # å‰¥ç¦»å¸‚åœºåç¼€ï¼ˆ.SZ/.SHï¼‰ï¼Œä¸ CLI è¡Œä¸ºä¸€è‡´
        ticker_for_path = task.ticker.split('.')[0] if '.' in task.ticker else task.ticker

        # åˆ›å»ºç›®å½•ç»“æ„
        # Docker å®¹å™¨å†…: /app/app/services/analysis_service.py â†’ 3ä¸ªparent â†’ /app â†’ /app/results
        project_dir = Path(__file__).parent.parent.parent
        results_dir = project_dir / "results" / ticker_for_path / task.date
        report_dir = results_dir / "reports"
        results_dir.mkdir(parents=True, exist_ok=True)
        report_dir.mkdir(parents=True, exist_ok=True)

        # åˆ›å»º message_tool.logï¼ˆä¸ CLI ä¸€è‡´ï¼‰
        log_file = results_dir / "message_tool.log"
        log_file.touch(exist_ok=True)

        # tool_data.csv è·¯å¾„ï¼ˆç”± ToolDataLogger åˆ›å»ºå’Œç®¡ç†ï¼‰
        tool_data_csv = results_dir / "tool_data.csv"

        return results_dir, log_file, tool_data_csv

    def _run_analysis(self, task_id: str):
        """åœ¨åå°è¿è¡Œåˆ†æï¼ˆä½¿ç”¨æµå¼æ¨¡å¼è·Ÿè¸ªè¿›åº¦ï¼‰"""
        task = self._tasks.get(task_id)
        if not task:
            logger.warning(f"ä»»åŠ¡ä¸å­˜åœ¨: {task_id}")
            return

        try:
            task.status = TaskStatus.RUNNING

            # åˆå§‹åŒ–ç»“æœç›®å½•å’Œæ–‡ä»¶ï¼ˆä¸ CLI ä¸€è‡´ï¼‰
            results_dir, log_file, tool_data_csv = self._init_results_dir(task_id)
            if log_file:
                task.log_file = str(log_file)  # ä¿å­˜æ—¥å¿—æ–‡ä»¶è·¯å¾„åˆ° task

            # å¼€å§‹æ—¥å¿—ï¼ˆlog_file å·²è®¾ç½®ï¼Œä¼šåŒæ—¶å†™å…¥æ–‡ä»¶ï¼‰
            self._add_log(task_id, f"å¼€å§‹åˆ†æ {task.ticker_name} ({task.ticker})")

            # å»¶è¿Ÿå¯¼å…¥ï¼Œé¿å…å¯åŠ¨æ—¶åŠ è½½
            from tradingagents.graph.trading_graph import TradingAgentsGraph
            from tradingagents.default_config import DEFAULT_CONFIG
            from tradingagents.utils.data_logger import ToolDataLogger
            from langchain_core.messages import ToolMessage

            # åˆ›å»ºå·¥å…·æ•°æ®è®°å½•å™¨ï¼ˆä¸ CLI ä¸€è‡´ï¼‰
            ticker_for_path = task.ticker.split('.')[0] if '.' in task.ticker else task.ticker
            data_logger = ToolDataLogger(tool_data_csv, ticker_for_path)

            config = DEFAULT_CONFIG.copy()
            # Docker ç¯å¢ƒä¸‹ä½¿ç”¨æŒ‚è½½çš„ named volume è·¯å¾„
            config["chroma_db_path"] = "/app/chroma_db"

            # åˆ›å»º Graph
            self._add_log(task_id, "åˆå§‹åŒ–åˆ†æç³»ç»Ÿ...")
            trading_graph = TradingAgentsGraph(
                config=config,
                selected_analysts=["market", "social", "news", "fundamentals"]
            )

            # ä½¿ç”¨æµå¼æ¨¡å¼è¿è¡Œï¼Œè·Ÿè¸ªæ¯ä¸ªèŠ‚ç‚¹çš„è¿›åº¦
            self._add_log(task_id, f"å¼€å§‹æ‰§è¡Œåˆ†ææµç¨‹...")

            # åˆå§‹åŒ–çŠ¶æ€
            init_state = trading_graph.propagator.create_initial_state(
                task.ticker, task.date
            )
            args = trading_graph.propagator.get_graph_args()

            # æµå¼æ‰§è¡Œï¼Œæ•è·æ¯ä¸ªèŠ‚ç‚¹å®Œæˆ
            # æ³¨æ„ï¼šä½¿ç”¨ stream_mode="values" æ—¶ï¼Œæ¯ä¸ª chunk æ˜¯å®Œæ•´çš„çŠ¶æ€å¿«ç…§
            # ä¸ CLI ä¸€è‡´ï¼Œä½¿ç”¨ trace åˆ—è¡¨ä¿å­˜æ‰€æœ‰ chunksï¼Œæœ€åä¸€ä¸ªæ˜¯æœ€ç»ˆçŠ¶æ€
            trace = []

            # è®¾ç½®åˆå§‹å½“å‰æ­¥éª¤
            self._set_current_step(task_id, "market_analyst", "å¸‚åœºåˆ†æå¸ˆ")
            self._add_log(task_id, "ğŸ“Š å¸‚åœºåˆ†æå¸ˆå¼€å§‹åˆ†æ...")

            # ä½¿ç”¨ stream_mode="values"ï¼ˆä¸ CLI ä¸€è‡´ï¼‰ï¼Œé€šè¿‡æ£€æµ‹æŠ¥å‘Šå†…å®¹å˜åŒ–è¿½è¸ªè¿›åº¦
            chunk_count = 0
            # è¿½è¸ªå·²å®Œæˆçš„æŠ¥å‘Š
            completed_reports = set()

            for chunk in trading_graph.graph.stream(init_state, **args):
                # æ£€æŸ¥å–æ¶ˆæ ‡å¿—
                if task.cancelled:
                    logger.info(f"ä»»åŠ¡ {task_id} æ£€æµ‹åˆ°å–æ¶ˆæ ‡å¿—ï¼Œæ­£åœ¨é€€å‡º...")
                    task.status = TaskStatus.FAILED
                    task.error = "ç”¨æˆ·å–æ¶ˆ"
                    task.completed_at = datetime.now().isoformat()
                    self._add_log(task_id, "âš ï¸ åˆ†æå·²è¢«ç”¨æˆ·å–æ¶ˆ")
                    return

                chunk_count += 1
                # ä¿å­˜ chunk åˆ° traceï¼ˆä¸ CLI ä¸€è‡´ï¼‰
                trace.append(chunk)

                # è°ƒè¯•ï¼šæ‰“å°æ¯ä¸ª chunk åŒ…å«çš„ keysï¼ˆä½¿ç”¨ print ç¡®ä¿è¾“å‡ºï¼‰
                chunk_keys = list(chunk.keys()) if isinstance(chunk, dict) else ["not_a_dict"]
                print(f"[DEBUG] ä»»åŠ¡ {task_id}: chunk#{chunk_count} keys={chunk_keys}", flush=True)
                self._add_log(task_id, f"ğŸ“¦ chunk#{chunk_count}: {len(chunk_keys)} keys")

                # æ£€æŸ¥å…³é”®æŠ¥å‘Šå­—æ®µ
                report_status = []
                if "market_report" in chunk and chunk["market_report"]:
                    report_status.append("marketâœ“")
                if "sentiment_report" in chunk and chunk["sentiment_report"]:
                    report_status.append("sentimentâœ“")
                if "news_report" in chunk and chunk["news_report"]:
                    report_status.append("newsâœ“")
                if "fundamentals_report" in chunk and chunk["fundamentals_report"]:
                    report_status.append("fundamentalsâœ“")
                if report_status:
                    print(f"[DEBUG] ä»»åŠ¡ {task_id}: chunk#{chunk_count} æŠ¥å‘ŠçŠ¶æ€: {report_status}", flush=True)

                # è®°å½•å·¥å…·è°ƒç”¨ï¼ˆä¸ CLI ä¸€è‡´ï¼‰
                if "messages" in chunk and chunk["messages"]:
                    for message in chunk["messages"]:
                        # æ£€æµ‹å·¥å…·è°ƒç”¨ï¼ˆAIMessage ä¸­çš„ tool_callsï¼‰
                        if hasattr(message, "tool_calls") and message.tool_calls:
                            for tool_call in message.tool_calls:
                                tool_name = tool_call["name"] if isinstance(tool_call, dict) else tool_call.name
                                tool_args = tool_call.get("args", {}) if isinstance(tool_call, dict) else getattr(tool_call, 'args', {})
                                tool_call_id = tool_call.get("id", "") if isinstance(tool_call, dict) else getattr(tool_call, 'id', '')
                                # æ³¨å†Œå·¥å…·è°ƒç”¨åˆ° data_logger
                                data_logger.register_tool_call(tool_call_id, tool_name, tool_args)
                                self._add_log(task_id, f"ğŸ”§ è°ƒç”¨å·¥å…·: {tool_name}")

                        # æ£€æµ‹å·¥å…·è¿”å›ç»“æœï¼ˆToolMessageï¼‰- è®°å½•åˆ° CSV
                        if isinstance(message, ToolMessage):
                            tool_call_id = message.tool_call_id
                            result_content = message.content if isinstance(message.content, str) else str(message.content)
                            data_logger.log_tool_result(tool_call_id, result_content)

                # æ£€æµ‹æŠ¥å‘Šå®Œæˆå¹¶å®æ—¶ä¿å­˜ï¼ˆä¸ CLI ç›¸åŒçš„é€»è¾‘ï¼‰
                # å¸‚åœºåˆ†æå¸ˆ
                if "market_report" in chunk and chunk["market_report"] and "market_analyst" not in completed_reports:
                    print(f"[PROGRESS] ä»»åŠ¡ {task_id}: ğŸ¯ æ£€æµ‹åˆ°å¸‚åœºåˆ†æå¸ˆå®Œæˆ!", flush=True)
                    completed_reports.add("market_analyst")
                    self._update_progress(task_id, "market_analyst")
                    self._add_log(task_id, "âœ“ å¸‚åœºåˆ†æå¸ˆå®Œæˆ")
                    # å®æ—¶ä¿å­˜æŠ¥å‘Š
                    self._save_report_realtime(task_id, "market_report", chunk["market_report"], "market_report.md")
                    # è®¾ç½®ä¸‹ä¸€æ­¥
                    self._set_current_step(task_id, "social_analyst", "æƒ…ç»ªåˆ†æå¸ˆ")
                    self._add_log(task_id, "ğŸ“Š æƒ…ç»ªåˆ†æå¸ˆå¼€å§‹åˆ†æ...")

                # æƒ…ç»ªåˆ†æå¸ˆ
                if "sentiment_report" in chunk and chunk["sentiment_report"] and "social_analyst" not in completed_reports:
                    print(f"[PROGRESS] ä»»åŠ¡ {task_id}: ğŸ¯ æ£€æµ‹åˆ°æƒ…ç»ªåˆ†æå¸ˆå®Œæˆ!", flush=True)
                    completed_reports.add("social_analyst")
                    self._update_progress(task_id, "social_analyst")
                    self._add_log(task_id, "âœ“ æƒ…ç»ªåˆ†æå¸ˆå®Œæˆ")
                    # å®æ—¶ä¿å­˜æŠ¥å‘Š
                    self._save_report_realtime(task_id, "sentiment_report", chunk["sentiment_report"], "sentiment_report.md")
                    self._set_current_step(task_id, "news_analyst", "æ–°é—»åˆ†æå¸ˆ")
                    self._add_log(task_id, "ğŸ“° æ–°é—»åˆ†æå¸ˆå¼€å§‹åˆ†æ...")

                # æ–°é—»åˆ†æå¸ˆ
                if "news_report" in chunk and chunk["news_report"] and "news_analyst" not in completed_reports:
                    print(f"[PROGRESS] ä»»åŠ¡ {task_id}: ğŸ¯ æ£€æµ‹åˆ°æ–°é—»åˆ†æå¸ˆå®Œæˆ!", flush=True)
                    completed_reports.add("news_analyst")
                    self._update_progress(task_id, "news_analyst")
                    self._add_log(task_id, "âœ“ æ–°é—»åˆ†æå¸ˆå®Œæˆ")
                    # å®æ—¶ä¿å­˜æŠ¥å‘Š
                    self._save_report_realtime(task_id, "news_report", chunk["news_report"], "news_report.md")
                    self._set_current_step(task_id, "fundamentals_analyst", "åŸºæœ¬é¢åˆ†æå¸ˆ")
                    self._add_log(task_id, "ğŸ“ˆ åŸºæœ¬é¢åˆ†æå¸ˆå¼€å§‹åˆ†æ...")

                # åŸºæœ¬é¢åˆ†æå¸ˆ
                if "fundamentals_report" in chunk and chunk["fundamentals_report"] and "fundamentals_analyst" not in completed_reports:
                    print(f"[PROGRESS] ä»»åŠ¡ {task_id}: ğŸ¯ æ£€æµ‹åˆ°åŸºæœ¬é¢åˆ†æå¸ˆå®Œæˆ!", flush=True)
                    completed_reports.add("fundamentals_analyst")
                    self._update_progress(task_id, "fundamentals_analyst")
                    self._add_log(task_id, "âœ“ åŸºæœ¬é¢åˆ†æå¸ˆå®Œæˆ")
                    # å®æ—¶ä¿å­˜æŠ¥å‘Š
                    self._save_report_realtime(task_id, "fundamentals_report", chunk["fundamentals_report"], "fundamentals_report.md")
                    self._set_current_step(task_id, "bull_researcher", "çœ‹æ¶¨ç ”ç©¶å‘˜")
                    self._add_log(task_id, "ğŸ”¬ ç ”ç©¶å›¢é˜Ÿå¼€å§‹è¾©è®º...")

                # ç ”ç©¶å›¢é˜Ÿï¼ˆé€šè¿‡ investment_debate_state è¿½è¸ªï¼‰
                if "investment_debate_state" in chunk and chunk["investment_debate_state"]:
                    debate = chunk["investment_debate_state"]
                    if debate.get("bull_history") and "bull_researcher" not in completed_reports:
                        completed_reports.add("bull_researcher")
                        self._update_progress(task_id, "bull_researcher")
                        self._add_log(task_id, "âœ“ çœ‹æ¶¨ç ”ç©¶å‘˜å®Œæˆ")
                        self._set_current_step(task_id, "bear_researcher", "çœ‹è·Œç ”ç©¶å‘˜")
                    if debate.get("bear_history") and "bear_researcher" not in completed_reports:
                        completed_reports.add("bear_researcher")
                        self._update_progress(task_id, "bear_researcher")
                        self._add_log(task_id, "âœ“ çœ‹è·Œç ”ç©¶å‘˜å®Œæˆ")
                        self._set_current_step(task_id, "research_manager", "ç ”ç©¶ä¸»ç®¡")
                    if debate.get("judge_decision") and "research_manager" not in completed_reports:
                        completed_reports.add("research_manager")
                        self._update_progress(task_id, "research_manager")
                        self._add_log(task_id, "âœ“ ç ”ç©¶ä¸»ç®¡å®Œæˆ")
                        # ä¿å­˜ç ”ç©¶ç»“è®ºæŠ¥å‘Šï¼ˆä¾›é¢„è§ˆä½¿ç”¨ï¼‰
                        research_content = self._format_research_report(debate)
                        self._save_report_realtime(task_id, "research_report", research_content, "research_report.md")
                        self._set_current_step(task_id, "risky_manager", "æ¿€è¿›é£æ§")
                        self._add_log(task_id, "ğŸ›¡ï¸ é£æ§å›¢é˜Ÿå¼€å§‹è¯„ä¼°...")

                # é£é™©ç®¡ç†å›¢é˜Ÿï¼ˆé€šè¿‡ risk_debate_state è¿½è¸ªï¼‰
                if "risk_debate_state" in chunk and chunk["risk_debate_state"]:
                    risk = chunk["risk_debate_state"]
                    if risk.get("risky_history") and "risky_manager" not in completed_reports:
                        completed_reports.add("risky_manager")
                        self._update_progress(task_id, "risky_manager")
                        self._add_log(task_id, "âœ“ æ¿€è¿›é£æ§å®Œæˆ")
                        self._set_current_step(task_id, "conservative_manager", "ä¿å®ˆé£æ§")
                    if risk.get("safe_history") and "conservative_manager" not in completed_reports:
                        completed_reports.add("conservative_manager")
                        self._update_progress(task_id, "conservative_manager")
                        self._add_log(task_id, "âœ“ ä¿å®ˆé£æ§å®Œæˆ")
                        self._set_current_step(task_id, "neutral_manager", "ä¸­ç«‹é£æ§")
                    if risk.get("neutral_history") and "neutral_manager" not in completed_reports:
                        completed_reports.add("neutral_manager")
                        self._update_progress(task_id, "neutral_manager")
                        self._add_log(task_id, "âœ“ ä¸­ç«‹é£æ§å®Œæˆ")
                        self._set_current_step(task_id, "risk_manager", "é£é™©ä¸»ç®¡")
                    if risk.get("judge_decision") and "risk_manager" not in completed_reports:
                        completed_reports.add("risk_manager")
                        self._update_progress(task_id, "risk_manager")
                        self._add_log(task_id, "âœ“ é£é™©ä¸»ç®¡å®Œæˆ")
                        # ä¿å­˜é£æ§è¯„ä¼°æŠ¥å‘Šï¼ˆä¾›é¢„è§ˆä½¿ç”¨ï¼‰
                        risk_content = self._format_risk_report(risk)
                        self._save_report_realtime(task_id, "risk_report", risk_content, "risk_report.md")
                        self._set_current_step(task_id, "consolidation", "ç»¼åˆæŠ¥å‘Š")
                        self._add_log(task_id, "ğŸ“ æ­£åœ¨ç”Ÿæˆç»¼åˆæŠ¥å‘Š...")

                # ç»¼åˆæŠ¥å‘Š
                if "consolidation_report" in chunk and chunk["consolidation_report"] and "consolidation" not in completed_reports:
                    completed_reports.add("consolidation")
                    self._update_progress(task_id, "consolidation")
                    self._add_log(task_id, "âœ“ ç»¼åˆæŠ¥å‘Šç”Ÿæˆå®Œæˆ")
                    # å®æ—¶ä¿å­˜ç»¼åˆæŠ¥å‘Š
                    self._save_report_realtime(task_id, "consolidation_report", chunk["consolidation_report"], "consolidation_report.md")

            logger.info(f"åˆ†æä»»åŠ¡ {task_id}: graph.stream() å®Œæˆ, å…± {chunk_count} ä¸ª chunks")
            self._add_log(task_id, f"æµå¼æ‰§è¡Œå®Œæˆï¼Œå…± {chunk_count} ä¸ª chunks")

            # ä½¿ç”¨æœ€åä¸€ä¸ª chunk ä½œä¸ºæœ€ç»ˆçŠ¶æ€ï¼ˆä¸ CLI ä¸€è‡´ï¼‰
            if not trace:
                raise ValueError("æµå¼æ‰§è¡Œæœªè¿”å›ä»»ä½• chunk")

            full_final_state = trace[-1]
            trading_graph.ticker = task.ticker
            trading_graph.curr_state = full_final_state

            # è°ƒè¯•ï¼šæ‰“å°çŠ¶æ€ä¸­çš„å…³é”®å­—æ®µ
            state_keys = list(full_final_state.keys())
            logger.info(f"åˆ†æä»»åŠ¡ {task_id}: æœ€ç»ˆçŠ¶æ€åŒ…å« keys: {state_keys}")
            self._add_log(task_id, f"çŠ¶æ€ keys: {len(state_keys)} ä¸ª")

            # æ£€æŸ¥ final_trade_decision æ˜¯å¦å­˜åœ¨
            if "final_trade_decision" not in full_final_state:
                logger.warning(f"åˆ†æä»»åŠ¡ {task_id}: final_trade_decision ä¸å­˜åœ¨äºçŠ¶æ€ä¸­")
                self._add_log(task_id, "âš ï¸ è­¦å‘Š: final_trade_decision ç¼ºå¤±ï¼Œå°è¯•ä»æŠ¥å‘Šæå–")
                # å°è¯•ä» consolidation_report æˆ– risk_debate_state ä¸­æå–
                if "risk_debate_state" in full_final_state and full_final_state["risk_debate_state"]:
                    risk_state = full_final_state["risk_debate_state"]
                    if risk_state.get("judge_decision"):
                        full_final_state["final_trade_decision"] = risk_state["judge_decision"]
                        self._add_log(task_id, "ä½¿ç”¨é£é™©ä¸»ç®¡å†³ç­–ä½œä¸ºæœ€ç»ˆå†³ç­–")
                elif "consolidation_report" in full_final_state and full_final_state["consolidation_report"]:
                    full_final_state["final_trade_decision"] = full_final_state["consolidation_report"]
                    self._add_log(task_id, "ä½¿ç”¨ç»¼åˆæŠ¥å‘Šä½œä¸ºæœ€ç»ˆå†³ç­–")
                else:
                    full_final_state["final_trade_decision"] = "HOLD"
                    self._add_log(task_id, "æ— æ³•æå–å†³ç­–ï¼Œé»˜è®¤ HOLD")

            # æå–ç»“æœ
            signal = trading_graph.process_signal(full_final_state.get("final_trade_decision", "HOLD"))
            self._add_log(task_id, f"æå–ä¿¡å·: {signal}")
            result = self._extract_result(full_final_state, signal, task.ticker)
            task.result = result

            # ä¿å­˜æŠ¥å‘Šåˆ°ç£ç›˜
            self._save_reports_to_disk(task, full_final_state, result)

            task.status = TaskStatus.COMPLETED
            task.completed_at = datetime.now().isoformat()

            self._add_log(task_id, f"åˆ†æå®Œæˆï¼äº¤æ˜“ä¿¡å·: {signal}")
            logger.info(f"åˆ†æä»»åŠ¡å®Œæˆ: {task_id}")

        except Exception as e:
            logger.error(f"åˆ†æä»»åŠ¡å¤±è´¥: {task_id} - {e}", exc_info=True)
            task.status = TaskStatus.FAILED
            task.error = str(e)
            task.completed_at = datetime.now().isoformat()
            self._add_log(task_id, f"åˆ†æå¤±è´¥: {e}")

    def _update_progress(self, task_id: str, step: str):
        """æ›´æ–°è¿›åº¦ï¼ˆåªæ›´æ–°çŠ¶æ€ï¼Œä¸æ·»åŠ æ—¥å¿—ï¼Œæ—¥å¿—ç”±è°ƒç”¨æ–¹æ§åˆ¶ï¼‰"""
        task = self._tasks.get(task_id)
        if not task:
            return

        # æŸ¥æ‰¾æ­¥éª¤åç§°
        step_name = step
        for s, name in self.ANALYSIS_STEPS:
            if s == step:
                step_name = name
                break

        # æ›´æ–°è¿›åº¦
        if step not in task.progress["completed_steps"]:
            task.progress["completed_steps"].append(step)

        task.progress["current_step"] = step
        task.progress["current_step_name"] = step_name

    def _set_current_step(self, task_id: str, step: str, step_name: str):
        """è®¾ç½®å½“å‰æ‰§è¡Œçš„æ­¥éª¤ï¼ˆä¸æ·»åŠ åˆ°completed_stepsï¼‰"""
        task = self._tasks.get(task_id)
        if task:
            task.progress["current_step"] = step
            task.progress["current_step_name"] = step_name

    def _save_report_realtime(self, task_id: str, report_key: str, content: str, filename: str):
        """å®æ—¶ä¿å­˜æŠ¥å‘Šï¼ˆä¸ CLI è¡Œä¸ºä¸€è‡´ï¼‰"""
        task = self._tasks.get(task_id)
        if not task or not content:
            return

        from pathlib import Path

        # å‰¥ç¦»å¸‚åœºåç¼€ï¼ˆ.SZ/.SHï¼‰ï¼Œä¸ CLI è¡Œä¸ºä¸€è‡´
        ticker_for_path = task.ticker.split('.')[0] if '.' in task.ticker else task.ticker

        # è·å– results ç›®å½•ï¼ˆä¸ _init_results_dir ä¿æŒä¸€è‡´ï¼‰
        project_dir = Path(__file__).parent.parent.parent
        report_dir = project_dir / "results" / ticker_for_path / task.date / "reports"

        try:
            report_dir.mkdir(parents=True, exist_ok=True)
            file_path = report_dir / filename
            with open(file_path, "w", encoding="utf-8") as f:
                f.write(content)
            print(f"[SAVE] ä»»åŠ¡ {task_id}: å·²ä¿å­˜ {filename}", flush=True)
            self._add_log(task_id, f"ğŸ“„ å·²ä¿å­˜æŠ¥å‘Š: {filename}")
        except Exception as e:
            logger.error(f"å®æ—¶ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")

    def _format_research_report(self, debate_state: dict) -> str:
        """æ ¼å¼åŒ–ç ”ç©¶ç»“è®ºæŠ¥å‘Š"""
        bull = debate_state.get('bull_history', 'æš‚æ— ')
        bear = debate_state.get('bear_history', 'æš‚æ— ')
        decision = debate_state.get('judge_decision', 'æš‚æ— ')

        return f"""# ç ”ç©¶ç»“è®ºæŠ¥å‘Š

## çœ‹æ¶¨è§‚ç‚¹

{bull}

## çœ‹è·Œè§‚ç‚¹

{bear}

## ç ”ç©¶ä¸»ç®¡ç»“è®º

{decision}
"""

    def _format_risk_report(self, risk_state: dict) -> str:
        """æ ¼å¼åŒ–é£æ§è¯„ä¼°æŠ¥å‘Š"""
        risky = risk_state.get('risky_history', 'æš‚æ— ')
        safe = risk_state.get('safe_history', 'æš‚æ— ')
        neutral = risk_state.get('neutral_history', 'æš‚æ— ')
        decision = risk_state.get('judge_decision', 'æš‚æ— ')

        return f"""# é£æ§è¯„ä¼°æŠ¥å‘Š

## æ¿€è¿›é£æ§æ„è§

{risky}

## ä¿å®ˆé£æ§æ„è§

{safe}

## ä¸­ç«‹é£æ§æ„è§

{neutral}

## é£æ§ä¸»ç®¡ç»“è®º

{decision}
"""

    def _add_log(self, task_id: str, message: str):
        """æ·»åŠ æ—¥å¿—ï¼ˆåŒæ—¶å†™å…¥ message_tool.logï¼‰"""
        task = self._tasks.get(task_id)
        if task:
            timestamp = datetime.now().strftime("%H:%M:%S")
            task.logs.append(f"[{timestamp}] {message}")
            # åŒæ—¶å†™å…¥ message_tool.logï¼ˆä¸ CLI ä¸€è‡´ï¼‰
            if task.log_file:
                try:
                    content = message.replace("\n", " ")
                    with open(task.log_file, "a", encoding="utf-8") as f:
                        f.write(f"{timestamp} [Log] {content}\n")
                except Exception:
                    pass  # å¿½ç•¥å†™å…¥å¤±è´¥

    def _extract_result(self, final_state: dict, signal: str, ticker: str) -> dict:
        """æå–åˆ†æç»“æœ"""
        result = {
            "ticker": ticker,
            "signal": signal,
            "decision": self._signal_to_decision(signal),
            "reports": {}
        }

        # æå–å„ç±»æŠ¥å‘Š
        report_keys = [
            ("consolidation_report", "ç»¼åˆæŠ¥å‘Š"),
            ("final_trade_decision", "æœ€ç»ˆå†³ç­–"),
            ("market_report", "å¸‚åœºåˆ†æ"),
            ("sentiment_report", "æƒ…ç»ªåˆ†æ"),
            ("news_report", "æ–°é—»åˆ†æ"),
            ("fundamentals_report", "åŸºæœ¬é¢åˆ†æ"),
        ]

        for key, name in report_keys:
            if key in final_state and final_state[key]:
                result["reports"][key] = {
                    "name": name,
                    "content": final_state[key]
                }

        # å°è¯•è§£æç»¼åˆæŠ¥å‘Šä¸­çš„å…³é”®ä¿¡æ¯
        if "consolidation_report" in result["reports"]:
            result["summary"] = self._extract_summary(
                result["reports"]["consolidation_report"]["content"]
            )

        return result

    def _save_reports_to_disk(self, task: AnalysisTask, final_state: dict, result: dict):
        """ä¿å­˜æŠ¥å‘Šåˆ°ç£ç›˜ï¼ˆä¸ CLI è¡Œä¸ºä¸€è‡´ï¼‰"""
        from pathlib import Path
        import json

        # å‰¥ç¦»å¸‚åœºåç¼€ï¼ˆ.SZ/.SHï¼‰ï¼Œä¸ CLI è¡Œä¸ºä¸€è‡´
        ticker_for_path = task.ticker.split('.')[0] if '.' in task.ticker else task.ticker

        # è·å– results ç›®å½•ï¼ˆä¸ _init_results_dir ä¿æŒä¸€è‡´ï¼‰
        project_dir = Path(__file__).parent.parent.parent
        results_dir = project_dir / "results" / ticker_for_path / task.date

        try:
            # åˆ›å»ºç›®å½•
            report_dir = results_dir / "reports"
            report_dir.mkdir(parents=True, exist_ok=True)

            # ä¿å­˜å„ä¸ªæŠ¥å‘Š
            report_mappings = {
                "market_report": "market_report.md",
                "sentiment_report": "sentiment_report.md",
                "news_report": "news_report.md",
                "fundamentals_report": "fundamentals_report.md",
                "consolidation_report": "consolidation_report.md",
                "final_trade_decision": "final_trade_decision.md",
                "trader_investment_plan": "trader_investment_plan.md",
            }

            saved_count = 0
            for state_key, filename in report_mappings.items():
                content = final_state.get(state_key)
                if content:
                    file_path = report_dir / filename
                    with open(file_path, "w", encoding="utf-8") as f:
                        f.write(content)
                    saved_count += 1
                    self._add_log(task.task_id, f"æŠ¥å‘Šå·²ä¿å­˜: {filename}")

            # ä¿å­˜å®Œæ•´çŠ¶æ€ï¼ˆJSON æ ¼å¼ï¼Œæ–¹ä¾¿åç»­åˆ†æï¼‰
            state_log = {
                "ticker": task.ticker,
                "ticker_name": task.ticker_name,
                "date": task.date,
                "signal": result.get("signal"),
                "decision": result.get("decision"),
                "user_id": task.user_id,
                "created_at": task.created_at,
                "completed_at": task.completed_at,
            }
            with open(results_dir / "analysis_summary.json", "w", encoding="utf-8") as f:
                json.dump(state_log, f, ensure_ascii=False, indent=2)

            logger.info(f"æŠ¥å‘Šå·²ä¿å­˜åˆ° {report_dir}ï¼Œå…± {saved_count} ä¸ªæ–‡ä»¶")
            self._add_log(task.task_id, f"æ‰€æœ‰æŠ¥å‘Šå·²ä¿å­˜åˆ° results/{task.ticker}/{task.date}/reports/")

        except Exception as e:
            logger.error(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}", exc_info=True)
            self._add_log(task.task_id, f"æŠ¥å‘Šä¿å­˜å¤±è´¥: {e}")

    def _signal_to_decision(self, signal: str) -> str:
        """å°†ä¿¡å·è½¬æ¢ä¸ºå†³ç­–æ–‡æœ¬"""
        signal_map = {
            "buy": "ä¹°å…¥",
            "sell": "å–å‡º",
            "hold": "æŒæœ‰",
            "strong_buy": "å¼ºçƒˆä¹°å…¥",
            "strong_sell": "å¼ºçƒˆå–å‡º",
        }
        return signal_map.get(signal.lower(), signal)

    def _extract_summary(self, consolidation_report: str) -> dict:
        """ä»ç»¼åˆæŠ¥å‘Šä¸­æå–æ‘˜è¦ä¿¡æ¯"""
        import re

        summary = {
            "decision": None,
            "target_price": None,
            "confidence": None,
            "key_points": []
        }

        # å°è¯•æå–å†³ç­–
        decision_patterns = [
            r"æŠ•èµ„å»ºè®®[ï¼š:]\s*(ä¹°å…¥|å–å‡º|æŒæœ‰|è§‚æœ›)",
            r"å»ºè®®[ï¼š:]\s*(ä¹°å…¥|å–å‡º|æŒæœ‰|è§‚æœ›)",
            r"å†³ç­–[ï¼š:]\s*(BUY|SELL|HOLD)",
        ]
        for pattern in decision_patterns:
            match = re.search(pattern, consolidation_report, re.IGNORECASE)
            if match:
                summary["decision"] = match.group(1)
                break

        # å°è¯•æå–ç›®æ ‡ä»·
        price_patterns = [
            r"ç›®æ ‡ä»·[ï¼š:]\s*[Â¥ï¿¥]?([\d.]+)",
            r"ç›®æ ‡ä»·ä½[ï¼š:]\s*[Â¥ï¿¥]?([\d.]+)",
            r"target.*?[ï¼š:]\s*[Â¥ï¿¥]?([\d.]+)",
        ]
        for pattern in price_patterns:
            match = re.search(pattern, consolidation_report, re.IGNORECASE)
            if match:
                summary["target_price"] = float(match.group(1))
                break

        # å°è¯•æå–ç½®ä¿¡åº¦
        conf_patterns = [
            r"ç½®ä¿¡åº¦[ï¼š:]\s*([\d.]+)%?",
            r"confidence[ï¼š:]\s*([\d.]+)%?",
        ]
        for pattern in conf_patterns:
            match = re.search(pattern, consolidation_report, re.IGNORECASE)
            if match:
                conf = float(match.group(1))
                summary["confidence"] = conf if conf <= 1 else conf / 100
                break

        return summary

    def get_task_status(self, task_id: str) -> Optional[dict]:
        """è·å–ä»»åŠ¡çŠ¶æ€"""
        task = self._tasks.get(task_id)
        if task:
            return task.to_dict()
        return None

    def get_task_result(self, task_id: str) -> Optional[dict]:
        """è·å–ä»»åŠ¡ç»“æœ"""
        task = self._tasks.get(task_id)
        if task and task.status == TaskStatus.COMPLETED:
            return task.result
        return None

    def get_user_history(self, user_id: str, limit: int = 10) -> List[dict]:
        """è·å–ç”¨æˆ·çš„å†å²åˆ†æ"""
        task_ids = self._user_tasks.get(user_id, [])

        # è·å–ä»»åŠ¡åˆ—è¡¨ï¼ˆæŒ‰åˆ›å»ºæ—¶é—´å€’åºï¼‰
        tasks = []
        for task_id in reversed(task_ids):
            task = self._tasks.get(task_id)
            if task:
                tasks.append({
                    "task_id": task.task_id,
                    "ticker": task.ticker,
                    "ticker_name": task.ticker_name,
                    "date": task.date,
                    "status": task.status.value,
                    "decision": task.result.get("decision") if task.result else None,
                    "created_at": task.created_at,
                    "completed_at": task.completed_at
                })

            if len(tasks) >= limit:
                break

        return tasks

    def cancel_task(self, task_id: str) -> bool:
        """å–æ¶ˆä»»åŠ¡ï¼ˆæ”¯æŒå–æ¶ˆ PENDING å’Œ RUNNING çŠ¶æ€çš„ä»»åŠ¡ï¼‰"""
        task = self._tasks.get(task_id)
        if not task:
            return False

        if task.status == TaskStatus.PENDING:
            # ç›´æ¥å–æ¶ˆæœªå¼€å§‹çš„ä»»åŠ¡
            task.status = TaskStatus.FAILED
            task.error = "ç”¨æˆ·å–æ¶ˆ"
            task.completed_at = datetime.now().isoformat()
            return True
        elif task.status == TaskStatus.RUNNING:
            # è®¾ç½®å–æ¶ˆæ ‡å¿—ï¼Œè®©è¿è¡Œä¸­çš„ä»»åŠ¡åœ¨ä¸‹ä¸€ä¸ª chunk æ—¶æ£€æµ‹åˆ°å¹¶é€€å‡º
            task.cancelled = True
            logger.info(f"ä»»åŠ¡ {task_id} å·²æ ‡è®°ä¸ºå–æ¶ˆï¼Œç­‰å¾…ä»»åŠ¡é€€å‡º...")
            return True

        return False

    def _get_results_base_dir(self) -> Path:
        """è·å–ç»“æœç›®å½•æ ¹è·¯å¾„ï¼ˆä¸ _init_results_dir ä¿æŒä¸€è‡´ï¼‰"""
        from pathlib import Path
        return Path(__file__).parent.parent.parent / "results"

    def get_intermediate_report(self, task_id: str, report_type: str) -> Optional[str]:
        """
        è·å–åˆ†æè¿‡ç¨‹ä¸­çš„ä¸­é—´æŠ¥å‘Š

        Args:
            task_id: ä»»åŠ¡ ID
            report_type: æŠ¥å‘Šç±»å‹ (market_report, sentiment_report, news_report, fundamentals_report)

        Returns:
            æŠ¥å‘Šå†…å®¹å­—ç¬¦ä¸²ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è¿”å› None
        """
        from pathlib import Path

        task = self._tasks.get(task_id)
        if not task:
            return None

        # æ„å»ºæŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        # æŠ¥å‘Šä¿å­˜åœ¨ results/{ticker}/{date}/reports/{report_type}.md
        ticker_code = task.ticker.split('.')[0] if '.' in task.ticker else task.ticker
        report_dir = self._get_results_base_dir() / ticker_code / task.date / "reports"
        report_file = report_dir / f"{report_type}.md"

        if not report_file.exists():
            return None

        try:
            with open(report_file, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            logger.error(f"è¯»å–æŠ¥å‘Šæ–‡ä»¶å¤±è´¥: {report_file}, é”™è¯¯: {e}")
            return None

    def browse_all_stocks(self) -> List[Dict]:
        """
        æµè§ˆæ‰€æœ‰æœ‰å†å²æŠ¥å‘Šçš„è‚¡ç¥¨

        Returns:
            è‚¡ç¥¨åˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« ticker, latest_date, report_count
        """
        from pathlib import Path

        results_dir = self._get_results_base_dir()
        if not results_dir.exists():
            return []

        stocks = []
        for ticker_dir in sorted(results_dir.iterdir()):
            if not ticker_dir.is_dir():
                continue

            # è·å–æ‰€æœ‰æ—¥æœŸç›®å½•
            dates = []
            for date_dir in ticker_dir.iterdir():
                if date_dir.is_dir() and (date_dir / "reports").exists():
                    dates.append(date_dir.name)

            if dates:
                dates.sort(reverse=True)
                stocks.append({
                    "ticker": ticker_dir.name,
                    "latest_date": dates[0],
                    "report_count": len(dates)
                })

        # æŒ‰æœ€æ–°æ—¥æœŸæ’åº
        stocks.sort(key=lambda x: x["latest_date"], reverse=True)
        return stocks

    def get_stock_report_dates(self, ticker: str) -> List[Dict]:
        """
        è·å–æŸåªè‚¡ç¥¨çš„æ‰€æœ‰åˆ†ææ—¥æœŸ

        Args:
            ticker: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ 600036ï¼‰

        Returns:
            æ—¥æœŸåˆ—è¡¨ï¼Œæ¯é¡¹åŒ…å« date, has_summary, reports
        """
        from pathlib import Path

        ticker_code = ticker.split('.')[0] if '.' in ticker else ticker
        ticker_dir = self._get_results_base_dir() / ticker_code

        if not ticker_dir.exists():
            return []

        dates = []
        for date_dir in sorted(ticker_dir.iterdir(), reverse=True):
            if not date_dir.is_dir():
                continue

            report_dir = date_dir / "reports"
            summary_file = date_dir / "analysis_summary.json"

            # æ£€æŸ¥å­˜åœ¨çš„æŠ¥å‘Šç±»å‹
            available_reports = []
            if report_dir.exists():
                for report_file in report_dir.glob("*.md"):
                    available_reports.append(report_file.stem)

            dates.append({
                "date": date_dir.name,
                "has_summary": summary_file.exists(),
                "reports": available_reports
            })

        return dates

    def get_historical_report(self, ticker: str, date: str, report_type: str = "final_report") -> Optional[Dict]:
        """
        è·å–å†å²æŠ¥å‘Šå†…å®¹

        Args:
            ticker: è‚¡ç¥¨ä»£ç 
            date: æ—¥æœŸï¼ˆYYYY-MM-DDï¼‰
            report_type: æŠ¥å‘Šç±»å‹ï¼ˆfinal_report, market_report, sentiment_report, news_report, fundamentals_reportï¼‰

        Returns:
            æŠ¥å‘Šå†…å®¹å­—å…¸ï¼ŒåŒ…å« content, summaryï¼ˆå¦‚æœæœ‰ï¼‰
        """
        ticker_code = ticker.split('.')[0] if '.' in ticker else ticker
        date_dir = self._get_results_base_dir() / ticker_code / date

        if not date_dir.exists():
            return None

        result = {}

        # æŠ¥å‘Šç±»å‹æ˜ å°„ï¼šå‰ç«¯åç§° -> å®é™…æ–‡ä»¶å
        REPORT_FILE_MAP = {
            "final_report": "consolidation_report",
            "market_report": "market_report",
            "sentiment_report": "sentiment_report",
            "news_report": "news_report",
            "fundamentals_report": "fundamentals_report",
        }

        # è¯»å–æŠ¥å‘Šæ–‡ä»¶
        report_dir = date_dir / "reports"
        actual_report_name = REPORT_FILE_MAP.get(report_type, report_type)
        report_file = report_dir / f"{actual_report_name}.md"

        if report_file.exists():
            try:
                with open(report_file, 'r', encoding='utf-8') as f:
                    result["content"] = f.read()
            except Exception as e:
                logger.error(f"è¯»å–æŠ¥å‘Šå¤±è´¥: {report_file}, é”™è¯¯: {e}")
                result["content"] = None
        else:
            result["content"] = None

        # è¯»å–åˆ†ææ‘˜è¦ï¼ˆå¦‚æœè¯·æ±‚çš„æ˜¯æœ€ç»ˆæŠ¥å‘Šï¼‰
        if report_type == "final_report":
            summary_file = date_dir / "analysis_summary.json"
            if summary_file.exists():
                try:
                    with open(summary_file, 'r', encoding='utf-8') as f:
                        result["summary"] = json.load(f)
                except Exception as e:
                    logger.error(f"è¯»å–æ‘˜è¦å¤±è´¥: {summary_file}, é”™è¯¯: {e}")
                    result["summary"] = None

        return result if result.get("content") else None
