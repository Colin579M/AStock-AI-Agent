"""
Tushare Pro æ•°æ®è·å–æ¨¡å—

æä¾›ä¸­å›½Aè‚¡æ•°æ®è·å–åŠŸèƒ½ï¼ŒåŒ…æ‹¬ï¼š
- è´¢åŠ¡æŠ¥è¡¨ï¼ˆåˆ©æ¶¦è¡¨ã€èµ„äº§è´Ÿå€ºè¡¨ã€ç°é‡‘æµé‡è¡¨ï¼‰
- è´¢åŠ¡æŒ‡æ ‡ï¼ˆROEã€ROAã€æ¯›åˆ©ç‡ç­‰150+æŒ‡æ ‡ï¼‰
- æ¯æ—¥ä¼°å€¼ï¼ˆPEã€PBã€å¸‚å€¼ã€æ¢æ‰‹ç‡ï¼‰
- ä¸šç»©é¢„å‘Š
- è‚¡ä¸œæ•°æ®
- èµ„é‡‘æµå‘
- å®è§‚ç»æµæ•°æ®
"""

import os
import logging
from typing import Optional
from datetime import datetime, timedelta

import tushare as ts
import pandas as pd
import numpy as np

from .retry_utils import (
    retry_with_backoff,
    safe_api_call,
    get_tushare_error_message,
    DataResponse,
    ErrorCategory
)

logger = logging.getLogger(__name__)


# å…¨å±€ pro API å®ä¾‹
_pro_api = None


def get_tushare_token() -> str:
    """
    è·å– Tushare Tokenï¼Œä¼˜å…ˆä»ç¯å¢ƒå˜é‡è¯»å–ï¼Œå…¶æ¬¡ä» .env æ–‡ä»¶è¯»å–
    """
    # ä¼˜å…ˆç¯å¢ƒå˜é‡
    token = os.getenv("TUSHARE_TOKEN", "")
    if token:
        return token

    # å…¶æ¬¡å°è¯•ä» .env æ–‡ä»¶è¯»å–
    try:
        from dotenv import load_dotenv
        import pathlib
        # å°è¯•å¤šä¸ªå¯èƒ½çš„ .env ä½ç½®
        possible_paths = [
            pathlib.Path(".env"),
            pathlib.Path(__file__).parent.parent.parent / ".env",  # é¡¹ç›®æ ¹ç›®å½•
        ]
        for env_path in possible_paths:
            if env_path.exists():
                load_dotenv(env_path)
                token = os.getenv("TUSHARE_TOKEN", "")
                if token:
                    return token
    except ImportError:
        pass

    # å†æ¬¡å°è¯•ä»é…ç½®æ–‡ä»¶è¯»å–
    try:
        from tradingagents.default_config import DEFAULT_CONFIG
        token = DEFAULT_CONFIG.get("tushare_token", "")
        if token:
            return token
    except ImportError:
        pass

    return ""


def get_pro_api():
    """è·å– Tushare Pro API å®ä¾‹"""
    global _pro_api
    if _pro_api is None:
        token = get_tushare_token()
        if not token:
            raise ValueError(
                "Tushare Token æœªè®¾ç½®ã€‚è¯·è®¾ç½®ç¯å¢ƒå˜é‡ TUSHARE_TOKEN æˆ–åœ¨ default_config.py ä¸­é…ç½® tushare_tokenã€‚\n"
                "è·å–Token: https://tushare.pro/register"
            )
        ts.set_token(token)
        _pro_api = ts.pro_api()
    return _pro_api


def convert_stock_code(stock_code: str) -> str:
    """
    å°†è‚¡ç¥¨ä»£ç è½¬æ¢ä¸º Tushare æ ¼å¼

    Args:
        stock_code: 6ä½è‚¡ç¥¨ä»£ç  (å¦‚ "601899") æˆ–å¸¦åç¼€æ ¼å¼ (å¦‚ "601899.SH")

    Returns:
        Tushare æ ¼å¼çš„è‚¡ç¥¨ä»£ç  (å¦‚ "601899.SH")
    """
    # ç§»é™¤å¯èƒ½çš„åç¼€
    clean_code = stock_code.split('.')[0]

    # æ ¹æ®ä»£ç å‰ç¼€ç¡®å®šäº¤æ˜“æ‰€
    if clean_code.startswith(('6', '9')):  # ä¸Šæµ·
        return f"{clean_code}.SH"
    elif clean_code.startswith(('0', '2', '3')):  # æ·±åœ³
        return f"{clean_code}.SZ"
    elif clean_code.startswith(('4', '8')):  # åŒ—äº¤æ‰€/æ–°ä¸‰æ¿
        return f"{clean_code}.BJ"
    else:
        return f"{clean_code}.SH"  # é»˜è®¤ä¸Šæµ·


@retry_with_backoff(max_retries=3, initial_delay=1.0, backoff_factor=2.0)
def _fetch_stock_basic(ts_code: str):
    """å†…éƒ¨å‡½æ•°ï¼šè·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼ˆå¸¦é‡è¯•ï¼‰"""
    pro = get_pro_api()
    return pro.stock_basic(
        ts_code=ts_code,
        fields='ts_code,symbol,name,area,industry,fullname,list_date,market'
    )


def get_stock_basic_info(stock_code: str) -> str:
    """
    è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯ï¼ˆæ”¯æŒæ¨¡ç³Šæœç´¢ï¼‰

    æ”¯æŒä¸‰ç§è¾“å…¥æ–¹å¼:
    1. è‚¡ç¥¨ä»£ç : "601899", "000001", "300750"
    2. å®Œæ•´åç§°: "ç´«é‡‘çŸ¿ä¸š", "è´µå·èŒ…å°"
    3. æ¨¡ç³Šåç§°: "ç´«é‡‘", "èŒ…å°"

    Args:
        stock_code: è‚¡ç¥¨ä»£ç æˆ–åç§°

    Returns:
        è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    try:
        pro = get_pro_api()

        # 1. åˆ¤æ–­è¾“å…¥ç±»å‹ï¼šä»£ç  vs åç§°
        clean_code = stock_code.strip()

        # å¦‚æœæ˜¯çº¯æ•°å­—ä¸”é•¿åº¦ä¸º6ï¼Œè®¤ä¸ºæ˜¯è‚¡ç¥¨ä»£ç 
        if clean_code.isdigit() and len(clean_code) == 6:
            ts_code = convert_stock_code(clean_code)
            df = _fetch_stock_basic(ts_code)

            if df.empty:
                return f"[not_found] æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„åŸºæœ¬ä¿¡æ¯ã€‚è¯·ç¡®è®¤ä»£ç æ­£ç¡®ä¸”è‚¡ç¥¨æœªé€€å¸‚ã€‚"

            row = df.iloc[0]
            return _format_stock_basic_info(row)

        # 2. åç§°æœç´¢ï¼ˆç²¾ç¡®åŒ¹é… + æ¨¡ç³ŠåŒ¹é…ï¼‰
        df_all = pro.stock_basic(
            exchange='',
            list_status='L',  # åªæœç´¢ä¸Šå¸‚ä¸­çš„è‚¡ç¥¨
            fields='ts_code,symbol,name,area,industry,fullname,list_date,market'
        )

        if df_all.empty:
            return "[error] æ— æ³•è·å–è‚¡ç¥¨åˆ—è¡¨æ•°æ®"

        # 2.1 ç²¾ç¡®åŒ¹é…åç§°
        exact_match = df_all[df_all['name'] == clean_code]
        if not exact_match.empty:
            row = exact_match.iloc[0]
            return _format_stock_basic_info(row)

        # 2.2 æ¨¡ç³ŠåŒ¹é…åç§°ï¼ˆåŒ…å«å…³ç³»ï¼‰
        fuzzy_match = df_all[df_all['name'].str.contains(clean_code, na=False)]

        if fuzzy_match.empty:
            # 2.3 å°è¯•åŒ¹é…å…¨ç§°
            fuzzy_match = df_all[df_all['fullname'].str.contains(clean_code, na=False)]

        if fuzzy_match.empty:
            return f"[not_found] æœªæ‰¾åˆ°åŒ¹é… '{stock_code}' çš„è‚¡ç¥¨ã€‚è¯·å°è¯•æ›´ç²¾ç¡®çš„åç§°æˆ–ä½¿ç”¨6ä½ä»£ç ã€‚"

        if len(fuzzy_match) == 1:
            row = fuzzy_match.iloc[0]
            return _format_stock_basic_info(row)

        # 2.4 å¤šä¸ªåŒ¹é…ç»“æœï¼Œè¿”å›å€™é€‰åˆ—è¡¨
        result = [f"## æ‰¾åˆ° {len(fuzzy_match)} ä¸ªåŒ¹é…ç»“æœï¼Œè¯·é€‰æ‹©å…·ä½“è‚¡ç¥¨ä»£ç ï¼š\n"]
        result.append("| ä»£ç  | åç§° | è¡Œä¸š | åœ°åŒº |")
        result.append("|------|------|------|------|")

        for _, row in fuzzy_match.head(10).iterrows():
            ts_code = row.get('ts_code', 'N/A')
            name = row.get('name', 'N/A')
            industry = row.get('industry', 'N/A')
            area = row.get('area', 'N/A')
            result.append(f"| {ts_code} | {name} | {industry} | {area} |")

        if len(fuzzy_match) > 10:
            result.append(f"\n*ï¼ˆä»…æ˜¾ç¤ºå‰10ä¸ªï¼Œå…±{len(fuzzy_match)}ä¸ªåŒ¹é…ç»“æœï¼‰*")

        result.append("\n**æç¤º**: è¯·ä½¿ç”¨å…·ä½“çš„6ä½è‚¡ç¥¨ä»£ç é‡æ–°æŸ¥è¯¢ã€‚")
        return "\n".join(result)

    except Exception as e:
        logger.error(f"è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯å¤±è´¥ [{stock_code}]: {e}")
        return get_tushare_error_message(stock_code, "è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯", e)


def _format_stock_basic_info(row) -> str:
    """æ ¼å¼åŒ–å•åªè‚¡ç¥¨çš„åŸºæœ¬ä¿¡æ¯"""
    return f"""
## è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯

- **ä»£ç **: {row.get('ts_code', 'N/A')}
- **åç§°**: {row.get('name', 'N/A')}
- **å…¨ç§°**: {row.get('fullname', 'N/A')}
- **è¡Œä¸š**: {row.get('industry', 'N/A')}
- **åœ°åŒº**: {row.get('area', 'N/A')}
- **ä¸Šå¸‚æ—¥æœŸ**: {row.get('list_date', 'N/A')}
- **å¸‚åœº**: {row.get('market', 'N/A')}
"""


def get_financial_statements(stock_code: str) -> str:
    """
    è·å–è´¢åŠ¡æŠ¥è¡¨ï¼ˆåˆ©æ¶¦è¡¨ã€èµ„äº§è´Ÿå€ºè¡¨ã€ç°é‡‘æµé‡è¡¨ï¼‰

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 

    Returns:
        è´¢åŠ¡æŠ¥è¡¨çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    try:
        pro = get_pro_api()
        ts_code = convert_stock_code(stock_code)

        result = []
        result.append("# è´¢åŠ¡æŠ¥è¡¨åˆ†æ\n")

        # è·å–åˆ©æ¶¦è¡¨
        income_df = pro.income(ts_code=ts_code,
                              fields='ts_code,end_date,revenue,operate_profit,total_profit,n_income,basic_eps')
        if not income_df.empty:
            income_df = income_df.head(4)  # æœ€è¿‘4ä¸ªå­£åº¦
            result.append("## åˆ©æ¶¦è¡¨ï¼ˆæœ€è¿‘4ä¸ªå­£åº¦ï¼‰\n")
            result.append("| æŠ¥å‘ŠæœŸ | è¥ä¸šæ”¶å…¥(äº¿) | è¥ä¸šåˆ©æ¶¦(äº¿) | åˆ©æ¶¦æ€»é¢(äº¿) | å‡€åˆ©æ¶¦(äº¿) | åŸºæœ¬EPS |")
            result.append("|--------|------------|------------|------------|----------|---------|")
            for _, row in income_df.iterrows():
                revenue = row['revenue'] / 1e8 if pd.notna(row['revenue']) else 0
                op_profit = row['operate_profit'] / 1e8 if pd.notna(row['operate_profit']) else 0
                total_profit = row['total_profit'] / 1e8 if pd.notna(row['total_profit']) else 0
                n_income = row['n_income'] / 1e8 if pd.notna(row['n_income']) else 0
                eps = row['basic_eps'] if pd.notna(row['basic_eps']) else 0
                result.append(f"| {row['end_date']} | {revenue:.2f} | {op_profit:.2f} | {total_profit:.2f} | {n_income:.2f} | {eps:.3f} |")
            result.append("")

        # è·å–èµ„äº§è´Ÿå€ºè¡¨
        balance_df = pro.balancesheet(ts_code=ts_code,
                                      fields='ts_code,end_date,total_assets,total_liab,total_hldr_eqy_exc_min_int,money_cap')
        if not balance_df.empty:
            balance_df = balance_df.head(4)
            result.append("## èµ„äº§è´Ÿå€ºè¡¨ï¼ˆæœ€è¿‘4ä¸ªå­£åº¦ï¼‰\n")
            result.append("| æŠ¥å‘ŠæœŸ | æ€»èµ„äº§(äº¿) | æ€»è´Ÿå€º(äº¿) | è‚¡ä¸œæƒç›Š(äº¿) | è´§å¸èµ„é‡‘(äº¿) |")
            result.append("|--------|----------|----------|------------|------------|")
            for _, row in balance_df.iterrows():
                total_assets = row['total_assets'] / 1e8 if pd.notna(row['total_assets']) else 0
                total_liab = row['total_liab'] / 1e8 if pd.notna(row['total_liab']) else 0
                equity = row['total_hldr_eqy_exc_min_int'] / 1e8 if pd.notna(row['total_hldr_eqy_exc_min_int']) else 0
                cash = row['money_cap'] / 1e8 if pd.notna(row['money_cap']) else 0
                result.append(f"| {row['end_date']} | {total_assets:.2f} | {total_liab:.2f} | {equity:.2f} | {cash:.2f} |")
            result.append("")

        # è·å–ç°é‡‘æµé‡è¡¨
        cashflow_df = pro.cashflow(ts_code=ts_code,
                                   fields='ts_code,end_date,n_cashflow_act,n_cashflow_inv_act,n_cash_flows_fnc_act,free_cashflow')
        if not cashflow_df.empty:
            cashflow_df = cashflow_df.head(4)
            result.append("## ç°é‡‘æµé‡è¡¨ï¼ˆæœ€è¿‘4ä¸ªå­£åº¦ï¼‰\n")
            result.append("| æŠ¥å‘ŠæœŸ | ç»è¥ç°é‡‘æµ(äº¿) | æŠ•èµ„ç°é‡‘æµ(äº¿) | ç­¹èµ„ç°é‡‘æµ(äº¿) | è‡ªç”±ç°é‡‘æµ(äº¿) |")
            result.append("|--------|--------------|--------------|--------------|--------------|")
            for _, row in cashflow_df.iterrows():
                cf_op = row['n_cashflow_act'] / 1e8 if pd.notna(row['n_cashflow_act']) else 0
                cf_inv = row['n_cashflow_inv_act'] / 1e8 if pd.notna(row['n_cashflow_inv_act']) else 0
                cf_fin = row['n_cash_flows_fnc_act'] / 1e8 if pd.notna(row['n_cash_flows_fnc_act']) else 0
                fcf = row['free_cashflow'] / 1e8 if pd.notna(row['free_cashflow']) else 0
                result.append(f"| {row['end_date']} | {cf_op:.2f} | {cf_inv:.2f} | {cf_fin:.2f} | {fcf:.2f} |")
            result.append("")

        return "\n".join(result) if result else "æœªè·å–åˆ°è´¢åŠ¡æŠ¥è¡¨æ•°æ®"

    except Exception as e:
        return f"è·å–è´¢åŠ¡æŠ¥è¡¨å¤±è´¥: {str(e)}"


def _calc_cycle_position(current: float, min_val: float, max_val: float) -> str:
    """è®¡ç®—å½“å‰å€¼åœ¨å†å²åŒºé—´ä¸­çš„å‘¨æœŸä½ç½®"""
    if max_val == min_val or pd.isna(current):
        return "â€”"
    ratio = (current - min_val) / (max_val - min_val)
    if ratio <= 0.25:
        return "**ä½ä½**"
    elif ratio <= 0.5:
        return "åä½"
    elif ratio <= 0.75:
        return "åé«˜"
    else:
        return "**é«˜ä½**"


def get_financial_indicators(stock_code: str) -> str:
    """
    è·å–è´¢åŠ¡æŒ‡æ ‡ï¼ˆROEã€ROAã€æ¯›åˆ©ç‡ã€å‡€åˆ©ç‡ç­‰ï¼‰

    è¿”å›è¿‘4å­£åº¦è¯¦ç»†æ•°æ® + 5å¹´å†å²æ‘˜è¦ï¼ˆç”¨äºå‘¨æœŸè‚¡ä¼°å€¼ï¼‰

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 

    Returns:
        è´¢åŠ¡æŒ‡æ ‡çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    try:
        pro = get_pro_api()
        ts_code = convert_stock_code(stock_code)

        # æ³¨æ„ï¼šgross_marginæ˜¯æ¯›åˆ©(é‡‘é¢)ï¼Œgrossprofit_marginæ‰æ˜¯é”€å”®æ¯›åˆ©ç‡(ç™¾åˆ†æ¯”)
        df = pro.fina_indicator(ts_code=ts_code,
                               fields='ts_code,end_date,eps,bps,roe,roa,grossprofit_margin,netprofit_margin,debt_to_assets,current_ratio,quick_ratio,netprofit_yoy,tr_yoy')

        if df.empty:
            return f"æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„è´¢åŠ¡æŒ‡æ ‡"

        # è·å–20ä¸ªå­£åº¦ï¼ˆ5å¹´ï¼‰ç”¨äºå†å²åˆ†æ
        df_full = df.head(20)
        # è¿‘4å­£åº¦ç”¨äºè¯¦ç»†è¡¨æ ¼
        df_recent = df.head(4)

        result = []
        result.append("# è´¢åŠ¡æŒ‡æ ‡åˆ†æ\n")

        # === å†å²æ‘˜è¦ï¼ˆå‘¨æœŸåˆ†æç”¨ï¼‰===
        if len(df_full) >= 8:  # è‡³å°‘2å¹´æ•°æ®æ‰æ˜¾ç¤ºæ‘˜è¦
            result.append("## å†å²æŒ‡æ ‡æ‘˜è¦ï¼ˆå‘¨æœŸåˆ†æï¼‰\n")
            result.append(f"*æ•°æ®è¦†ç›–: {df_full['end_date'].iloc[-1]} ~ {df_full['end_date'].iloc[0]}ï¼Œå…±{len(df_full)}ä¸ªå­£åº¦*\n")
            result.append("| æŒ‡æ ‡ | 5å¹´å¹³å‡ | 5å¹´æœ€é«˜ | 5å¹´æœ€ä½ | å½“å‰ | å‘¨æœŸä½ç½® |")
            result.append("|------|--------|--------|--------|------|---------|")

            # EPS
            eps_values = df_full['eps'].dropna()
            if len(eps_values) >= 4:
                avg_eps = eps_values.mean()
                max_eps = eps_values.max()
                min_eps = eps_values.min()
                current_eps = eps_values.iloc[0]
                position = _calc_cycle_position(current_eps, min_eps, max_eps)
                result.append(f"| EPS(å…ƒ) | {avg_eps:.2f} | {max_eps:.2f} | {min_eps:.2f} | {current_eps:.2f} | {position} |")

            # ROE
            roe_values = df_full['roe'].dropna()
            if len(roe_values) >= 4:
                avg_roe = roe_values.mean()
                max_roe = roe_values.max()
                min_roe = roe_values.min()
                current_roe = roe_values.iloc[0]
                position = _calc_cycle_position(current_roe, min_roe, max_roe)
                result.append(f"| ROE(%) | {avg_roe:.1f} | {max_roe:.1f} | {min_roe:.1f} | {current_roe:.1f} | {position} |")

            # æ¯›åˆ©ç‡
            gm_values = df_full['grossprofit_margin'].dropna()
            if len(gm_values) >= 4:
                avg_gm = gm_values.mean()
                max_gm = gm_values.max()
                min_gm = gm_values.min()
                current_gm = gm_values.iloc[0]
                position = _calc_cycle_position(current_gm, min_gm, max_gm)
                result.append(f"| æ¯›åˆ©ç‡(%) | {avg_gm:.1f} | {max_gm:.1f} | {min_gm:.1f} | {current_gm:.1f} | {position} |")

            # å‡€åˆ©æ¶¦å¢é€Ÿ
            np_yoy_values = df_full['netprofit_yoy'].dropna()
            if len(np_yoy_values) >= 4:
                avg_np = np_yoy_values.mean()
                max_np = np_yoy_values.max()
                min_np = np_yoy_values.min()
                current_np = np_yoy_values.iloc[0]
                position = _calc_cycle_position(current_np, min_np, max_np)
                result.append(f"| å‡€åˆ©æ¶¦å¢é€Ÿ(%) | {avg_np:.1f} | {max_np:.1f} | {min_np:.1f} | {current_np:.1f} | {position} |")

            result.append("")

        # === è¿‘4å­£åº¦è¯¦ç»†æ•°æ® ===
        result.append("## ç›ˆåˆ©èƒ½åŠ›æŒ‡æ ‡ï¼ˆè¿‘4å­£ï¼‰\n")
        result.append("| æŠ¥å‘ŠæœŸ | ROE(%) | ROA(%) | æ¯›åˆ©ç‡(%) | å‡€åˆ©ç‡(%) |")
        result.append("|--------|--------|--------|----------|----------|")
        for _, row in df_recent.iterrows():
            roe = row['roe'] if pd.notna(row['roe']) else 0
            roa = row['roa'] if pd.notna(row['roa']) else 0
            gm = row['grossprofit_margin'] if pd.notna(row['grossprofit_margin']) else 0
            npm = row['netprofit_margin'] if pd.notna(row['netprofit_margin']) else 0
            result.append(f"| {row['end_date']} | {roe:.2f} | {roa:.2f} | {gm:.2f} | {npm:.2f} |")
        result.append("")

        # æ¯è‚¡æŒ‡æ ‡
        result.append("## æ¯è‚¡æŒ‡æ ‡ï¼ˆè¿‘4å­£ï¼‰\n")
        result.append("| æŠ¥å‘ŠæœŸ | EPS(å…ƒ) | BPS(å…ƒ) |")
        result.append("|--------|---------|---------|")
        for _, row in df_recent.iterrows():
            eps = row['eps'] if pd.notna(row['eps']) else 0
            bps = row['bps'] if pd.notna(row['bps']) else 0
            result.append(f"| {row['end_date']} | {eps:.3f} | {bps:.2f} |")
        result.append("")

        # å¿å€ºèƒ½åŠ›
        result.append("## å¿å€ºèƒ½åŠ›æŒ‡æ ‡ï¼ˆè¿‘4å­£ï¼‰\n")
        result.append("| æŠ¥å‘ŠæœŸ | èµ„äº§è´Ÿå€ºç‡(%) | æµåŠ¨æ¯”ç‡ | é€ŸåŠ¨æ¯”ç‡ |")
        result.append("|--------|--------------|---------|---------|")
        for _, row in df_recent.iterrows():
            debt_ratio = row['debt_to_assets'] if pd.notna(row['debt_to_assets']) else 0
            current = row['current_ratio'] if pd.notna(row['current_ratio']) else 0
            quick = row['quick_ratio'] if pd.notna(row['quick_ratio']) else 0
            result.append(f"| {row['end_date']} | {debt_ratio:.2f} | {current:.2f} | {quick:.2f} |")
        result.append("")

        # å¢é•¿ç‡
        result.append("## å¢é•¿ç‡æŒ‡æ ‡ï¼ˆè¿‘4å­£ï¼‰\n")
        result.append("| æŠ¥å‘ŠæœŸ | å‡€åˆ©æ¶¦åŒæ¯”(%) | è¥æ”¶åŒæ¯”(%) |")
        result.append("|--------|-------------|-----------|")
        for _, row in df_recent.iterrows():
            np_yoy = row['netprofit_yoy'] if pd.notna(row['netprofit_yoy']) else 0
            tr_yoy = row['tr_yoy'] if pd.notna(row['tr_yoy']) else 0
            result.append(f"| {row['end_date']} | {np_yoy:.2f} | {tr_yoy:.2f} |")
        result.append("")

        return "\n".join(result)

    except Exception as e:
        return f"è·å–è´¢åŠ¡æŒ‡æ ‡å¤±è´¥: {str(e)}"


def get_daily_basic(stock_code: str, trade_date: Optional[str] = None) -> str:
    """
    è·å–æ¯æ—¥ä¼°å€¼æŒ‡æ ‡ï¼ˆPEã€PBã€å¸‚å€¼ã€æ¢æ‰‹ç‡ç­‰ï¼‰+ å†å²ä¼°å€¼ç»Ÿè®¡

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        trade_date: äº¤æ˜“æ—¥æœŸ (YYYYMMDDæ ¼å¼)ï¼Œé»˜è®¤è·å–æœ€è¿‘æ•°æ®

    Returns:
        ä¼°å€¼æŒ‡æ ‡çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼ŒåŒ…å«è¿‘3å¹´å†å²ä¼°å€¼ç»Ÿè®¡
    """
    try:
        pro = get_pro_api()
        ts_code = convert_stock_code(stock_code)

        # å®‰å…¨è½¬æ¢å‡½æ•°
        def safe_float(val, default=0.0):
            """å®‰å…¨è½¬æ¢ä¸ºfloatï¼Œå¤„ç†Noneå’ŒNaN"""
            if val is None or pd.isna(val):
                return default
            return float(val)

        # è·å–è¿‘3å¹´å†å²æ•°æ®ç”¨äºä¼°å€¼åˆ†ä½è®¡ç®—
        end_date = datetime.now().strftime('%Y%m%d')
        start_date_3y = (datetime.now() - timedelta(days=365*3)).strftime('%Y%m%d')

        df_history = pro.daily_basic(
            ts_code=ts_code,
            start_date=start_date_3y,
            end_date=end_date,
            fields='ts_code,trade_date,pe,pb,ps,total_mv,circ_mv,turnover_rate,volume_ratio,dv_ratio,dv_ttm'
        )

        if df_history.empty:
            return f"æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„ä¼°å€¼æ•°æ®"

        # æœ€è¿‘10å¤©æ•°æ®ç”¨äºå±•ç¤º
        df_recent = df_history.head(10)

        result = []
        result.append("# ä¼°å€¼æŒ‡æ ‡åˆ†æ\n")

        # ===== è·å–å½“å‰è‚¡ä»·ï¼ˆdaily_basic ä¸åŒ…å« closeï¼Œéœ€ä» daily è·å–ï¼‰=====
        try:
            df_daily = pro.daily(ts_code=ts_code, start_date=end_date, end_date=end_date, fields='trade_date,close')
            if df_daily.empty:
                # å¦‚æœå½“å¤©æ²¡æ•°æ®ï¼Œå¾€å‰æ‰¾æœ€è¿‘çš„äº¤æ˜“æ—¥
                recent_start = (datetime.now() - timedelta(days=10)).strftime('%Y%m%d')
                df_daily = pro.daily(ts_code=ts_code, start_date=recent_start, end_date=end_date, fields='trade_date,close')

            if not df_daily.empty:
                current_price = safe_float(df_daily.iloc[0]['close'])
                trade_date = df_daily.iloc[0]['trade_date']
                result.append(f"**å½“å‰è‚¡ä»·**: {current_price:.2f}å…ƒï¼ˆ{trade_date}æ”¶ç›˜ä»·ï¼‰\n")
        except Exception as e:
            logger.warning(f"è·å–æ”¶ç›˜ä»·å¤±è´¥: {e}")

        # ===== å†å²ä¼°å€¼ç»Ÿè®¡ï¼ˆé‡è¦ï¼ç”¨äºç¡®å®šä¼°å€¼åŒºé—´ä¾æ®ï¼‰=====
        result.append("## å†å²ä¼°å€¼ç»Ÿè®¡ï¼ˆè¿‘3å¹´ï¼‰\n")
        result.append("**æ­¤æ•°æ®ç”¨äºç¡®å®šä¼°å€¼åŒºé—´ä¾æ®ï¼Œå¤šæƒ…æ™¯ä¼°å€¼æ—¶å¿…é¡»å¼•ç”¨**\n")

        # è¿‡æ»¤æœ‰æ•ˆçš„ PE/PB æ•°æ®ï¼ˆæ’é™¤è´Ÿå€¼å’Œå¼‚å¸¸å€¼ï¼‰
        pe_valid = df_history['pe'][(df_history['pe'] > 0) & (df_history['pe'] < 1000)]
        pb_valid = df_history['pb'][(df_history['pb'] > 0) & (df_history['pb'] < 50)]

        if len(pe_valid) > 10:
            pe_min = safe_float(pe_valid.min())
            pe_25 = safe_float(pe_valid.quantile(0.25))
            pe_median = safe_float(pe_valid.median())
            pe_75 = safe_float(pe_valid.quantile(0.75))
            pe_max = safe_float(pe_valid.max())
            latest_pe = safe_float(df_recent.iloc[0]['pe']) if pd.notna(df_recent.iloc[0]['pe']) else 0

            # è®¡ç®—å½“å‰PEæ‰€å¤„åˆ†ä½
            if latest_pe > 0:
                pe_percentile = safe_float((pe_valid < latest_pe).sum() / len(pe_valid) * 100)
            else:
                pe_percentile = 0

            result.append("| PEæŒ‡æ ‡ | æœ€å°å€¼ | 25%åˆ†ä½ | ä¸­ä½æ•° | 75%åˆ†ä½ | æœ€å¤§å€¼ | å½“å‰å€¼ | **å½“å‰åˆ†ä½** |")
            result.append("|--------|--------|---------|--------|---------|--------|--------|-------------|")
            result.append(f"| PE(TTM) | {pe_min:.1f} | {pe_25:.1f} | {pe_median:.1f} | {pe_75:.1f} | {pe_max:.1f} | {latest_pe:.1f} | **{pe_percentile:.0f}%** |")
            result.append("")

            # PE å»ºè®®ä¼°å€¼åŒºé—´
            result.append("**PEä¼°å€¼åŒºé—´ä¾æ®**ï¼š")
            result.append(f"- PEæ‚²è§‚åŒºé—´ä¸‹é™ï¼š{pe_25:.1f}ï¼ˆ25%åˆ†ä½ï¼‰")
            result.append(f"- PEä¸­æ€§å‚è€ƒï¼š{pe_median:.1f}ï¼ˆä¸­ä½æ•°ï¼‰")
            result.append(f"- PEä¹è§‚åŒºé—´ä¸Šé™ï¼š{pe_75:.1f}ï¼ˆ75%åˆ†ä½ï¼‰")
            if pe_percentile > 80:
                result.append(f"- âš ï¸ å½“å‰PEå¤„äºå†å²**{pe_percentile:.0f}%åˆ†ä½**ï¼Œä¼°å€¼åé«˜")
            elif pe_percentile < 20:
                result.append(f"- âœ… å½“å‰PEå¤„äºå†å²**{pe_percentile:.0f}%åˆ†ä½**ï¼Œä¼°å€¼åä½")
            result.append("")

        if len(pb_valid) > 10:
            pb_min = safe_float(pb_valid.min())
            pb_25 = safe_float(pb_valid.quantile(0.25))
            pb_median = safe_float(pb_valid.median())
            pb_75 = safe_float(pb_valid.quantile(0.75))
            pb_max = safe_float(pb_valid.max())
            latest_pb = safe_float(df_recent.iloc[0]['pb']) if pd.notna(df_recent.iloc[0]['pb']) else 0

            # è®¡ç®—å½“å‰PBæ‰€å¤„åˆ†ä½
            if latest_pb > 0:
                pb_percentile = safe_float((pb_valid < latest_pb).sum() / len(pb_valid) * 100)
            else:
                pb_percentile = 0

            result.append("| PBæŒ‡æ ‡ | æœ€å°å€¼ | 25%åˆ†ä½ | ä¸­ä½æ•° | 75%åˆ†ä½ | æœ€å¤§å€¼ | å½“å‰å€¼ | **å½“å‰åˆ†ä½** |")
            result.append("|--------|--------|---------|--------|---------|--------|--------|-------------|")
            result.append(f"| PB | {pb_min:.2f} | {pb_25:.2f} | {pb_median:.2f} | {pb_75:.2f} | {pb_max:.2f} | {latest_pb:.2f} | **{pb_percentile:.0f}%** |")
            result.append("")

            # ç»™å‡ºå»ºè®®ä¼°å€¼åŒºé—´
            result.append("**PBä¼°å€¼åŒºé—´ä¾æ®**ï¼š")
            result.append(f"- PBæ‚²è§‚åŒºé—´ä¸‹é™ï¼š{pb_25:.2f}ï¼ˆ25%åˆ†ä½ï¼‰")
            result.append(f"- PBä¸­æ€§å‚è€ƒï¼š{pb_median:.2f}ï¼ˆä¸­ä½æ•°ï¼‰")
            result.append(f"- PBä¹è§‚åŒºé—´ä¸Šé™ï¼š{pb_75:.2f}ï¼ˆ75%åˆ†ä½ï¼‰")
            if pb_percentile > 80:
                result.append(f"- âš ï¸ å½“å‰PBå¤„äºå†å²**{pb_percentile:.0f}%åˆ†ä½**ï¼Œä¼°å€¼åé«˜")
            elif pb_percentile < 20:
                result.append(f"- âœ… å½“å‰PBå¤„äºå†å²**{pb_percentile:.0f}%åˆ†ä½**ï¼Œä¼°å€¼åä½")
            result.append("")

        # ===== è‚¡æ¯ç‡åˆ†æï¼ˆé«˜æ¯è‚¡é‡è¦æŒ‡æ ‡ï¼‰=====
        latest_dv_ratio = safe_float(df_recent.iloc[0].get('dv_ratio')) if 'dv_ratio' in df_recent.columns else 0
        latest_dv_ttm = safe_float(df_recent.iloc[0].get('dv_ttm')) if 'dv_ttm' in df_recent.columns else 0
        # è·å–æœ€æ–°PBç”¨äºé«˜æ¯è‚¡åˆ¤æ–­
        current_pb = safe_float(df_recent.iloc[0]['pb']) if pd.notna(df_recent.iloc[0]['pb']) else 0

        if latest_dv_ratio > 0 or latest_dv_ttm > 0:
            result.append("## è‚¡æ¯ç‡åˆ†æ\n")
            result.append(f"- **è‚¡æ¯ç‡**: {latest_dv_ratio:.2f}%")
            result.append(f"- **è‚¡æ¯ç‡(TTM)**: {latest_dv_ttm:.2f}%")

            # é«˜æ¯è‚¡åˆ¤æ–­æ ‡å‡†
            if latest_dv_ratio >= 5:
                result.append(f"- âœ… **é«˜åˆ†çº¢è‚¡**: è‚¡æ¯ç‡â‰¥5%ï¼Œå±äºé«˜æ¯è‚¡")
                if current_pb > 0 and current_pb < 1:
                    result.append(f"- âœ… **ä½ä¼°å€¼é«˜åˆ†çº¢**: è‚¡æ¯ç‡{latest_dv_ratio:.2f}% + PB{current_pb:.2f}<1ï¼Œå…·å¤‡å®‰å…¨è¾¹é™…")
            elif latest_dv_ratio >= 3:
                result.append(f"- ğŸ“Š ä¸­ç­‰åˆ†çº¢: è‚¡æ¯ç‡åœ¨3%-5%ä¹‹é—´")
            elif latest_dv_ratio > 0:
                result.append(f"- ğŸ“Š æ™®é€šåˆ†çº¢: è‚¡æ¯ç‡<3%")
            result.append("")

        # ===== è¿‘æœŸä¼°å€¼æ•°æ® =====
        result.append("## æ¯æ—¥ä¼°å€¼æ•°æ®ï¼ˆæœ€è¿‘10ä¸ªäº¤æ˜“æ—¥ï¼‰\n")
        result.append("| æ—¥æœŸ | PE(TTM) | PB | PS | è‚¡æ¯ç‡(%) | æ€»å¸‚å€¼(äº¿) | æµé€šå¸‚å€¼(äº¿) | æ¢æ‰‹ç‡(%) |")
        result.append("|------|---------|-----|-----|----------|-----------|------------|----------|")

        for _, row in df_recent.iterrows():
            pe = row['pe'] if pd.notna(row['pe']) else 0
            pb = row['pb'] if pd.notna(row['pb']) else 0
            ps = row['ps'] if pd.notna(row['ps']) else 0
            dv_ratio = row.get('dv_ratio', 0) if pd.notna(row.get('dv_ratio')) else 0
            total_mv = row['total_mv'] / 10000 if pd.notna(row['total_mv']) else 0
            circ_mv = row['circ_mv'] / 10000 if pd.notna(row['circ_mv']) else 0
            turnover = row['turnover_rate'] if pd.notna(row['turnover_rate']) else 0
            result.append(f"| {row['trade_date']} | {pe:.2f} | {pb:.2f} | {ps:.2f} | {dv_ratio:.2f} | {total_mv:.2f} | {circ_mv:.2f} | {turnover:.2f} |")

        result.append("")
        return "\n".join(result)

    except Exception as e:
        logger.error(f"è·å–ä¼°å€¼æ•°æ®å¤±è´¥ [{stock_code}]: {e}")
        return f"è·å–ä¼°å€¼æ•°æ®å¤±è´¥: {str(e)}"


def get_forecast(stock_code: str) -> str:
    """
    è·å–ä¸šç»©é¢„å‘Š

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 

    Returns:
        ä¸šç»©é¢„å‘Šçš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    try:
        pro = get_pro_api()
        ts_code = convert_stock_code(stock_code)

        df = pro.forecast(ts_code=ts_code)

        if df.empty:
            return f"è‚¡ç¥¨ {stock_code} æš‚æ— ä¸šç»©é¢„å‘Š"

        df = df.head(5)  # æœ€è¿‘5æ¡

        result = []
        result.append("# ä¸šç»©é¢„å‘Š\n")

        for _, row in df.iterrows():
            result.append(f"## {row['end_date']} ä¸šç»©é¢„å‘Š\n")
            result.append(f"- **å…¬å‘Šæ—¥æœŸ**: {row.get('ann_date', 'N/A')}")
            result.append(f"- **é¢„å‘Šç±»å‹**: {row.get('type', 'N/A')}")
            result.append(f"- **ä¸šç»©å˜åŠ¨å¹…åº¦**: {row.get('p_change_min', 0):.1f}% ~ {row.get('p_change_max', 0):.1f}%")

            net_min = row.get('net_profit_min', 0)
            net_max = row.get('net_profit_max', 0)
            if net_min and net_max:
                result.append(f"- **é¢„è®¡å‡€åˆ©æ¶¦**: {net_min/10000:.2f}äº¿ ~ {net_max/10000:.2f}äº¿")

            if row.get('summary'):
                result.append(f"- **é¢„å‘Šæ‘˜è¦**: {row['summary'][:200]}...")

            if row.get('change_reason'):
                result.append(f"- **å˜åŠ¨åŸå› **: {row['change_reason'][:300]}...")

            result.append("")

        return "\n".join(result)

    except Exception as e:
        return f"è·å–ä¸šç»©é¢„å‘Šå¤±è´¥: {str(e)}"


def get_top10_holders(stock_code: str) -> str:
    """
    è·å–å‰åå¤§è‚¡ä¸œ

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 

    Returns:
        å‰åå¤§è‚¡ä¸œçš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    try:
        pro = get_pro_api()
        ts_code = convert_stock_code(stock_code)

        # è·å–æœ€è¿‘ä¸¤æœŸæ•°æ®è¿›è¡Œå¯¹æ¯”
        df = pro.top10_holders(ts_code=ts_code)

        if df.empty:
            return f"æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„è‚¡ä¸œæ•°æ®"

        # è·å–æœ€æ–°ä¸€æœŸ
        latest_date = df['end_date'].max()
        latest_df = df[df['end_date'] == latest_date].head(10)

        result = []
        result.append("# å‰åå¤§è‚¡ä¸œåˆ†æ\n")
        result.append(f"## æˆªè‡³ {latest_date} å‰åå¤§è‚¡ä¸œ\n")
        result.append("| æ’å | è‚¡ä¸œåç§° | æŒè‚¡æ•°é‡(ä¸‡è‚¡) | æŒè‚¡æ¯”ä¾‹(%) | è‚¡ä¸œç±»å‹ |")
        result.append("|------|---------|--------------|------------|---------|")

        for i, (_, row) in enumerate(latest_df.iterrows(), 1):
            name = row['holder_name'][:20] if len(row['holder_name']) > 20 else row['holder_name']
            amount = row['hold_amount'] / 10000 if pd.notna(row['hold_amount']) else 0
            ratio = row['hold_ratio'] if pd.notna(row['hold_ratio']) else 0
            holder_type = row.get('holder_type', 'N/A')
            result.append(f"| {i} | {name} | {amount:.2f} | {ratio:.2f} | {holder_type} |")

        result.append("")

        # è®¡ç®—æœºæ„æŒè‚¡æ¯”ä¾‹
        total_ratio = latest_df['hold_ratio'].sum()
        result.append(f"**å‰åå¤§è‚¡ä¸œåˆè®¡æŒè‚¡**: {total_ratio:.2f}%")
        result.append("")

        return "\n".join(result)

    except Exception as e:
        return f"è·å–è‚¡ä¸œæ•°æ®å¤±è´¥: {str(e)}"


def get_holder_number(stock_code: str) -> str:
    """
    è·å–è‚¡ä¸œäººæ•°å˜åŒ–è¶‹åŠ¿ï¼ˆç­¹ç é›†ä¸­åº¦ï¼‰

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 

    Returns:
        è‚¡ä¸œäººæ•°çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    try:
        pro = get_pro_api()
        ts_code = convert_stock_code(stock_code)

        df = pro.stk_holdernumber(ts_code=ts_code)

        if df.empty:
            return f"æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„è‚¡ä¸œäººæ•°æ•°æ®"

        df = df.head(8)  # æœ€è¿‘8æœŸ

        result = []
        result.append("# è‚¡ä¸œäººæ•°å˜åŒ–ï¼ˆç­¹ç é›†ä¸­åº¦ï¼‰\n")
        result.append("| æŠ¥å‘ŠæœŸ | è‚¡ä¸œäººæ•° | ç¯æ¯”å˜åŒ– |")
        result.append("|--------|---------|---------|")

        prev_num = None
        for _, row in df.iterrows():
            num = row['holder_num']
            if prev_num:
                change = (num - prev_num) / prev_num * 100
                change_str = f"{change:+.2f}%"
            else:
                change_str = "-"
            result.append(f"| {row['end_date']} | {num:,} | {change_str} |")
            prev_num = num

        result.append("")

        # åˆ†æè¶‹åŠ¿
        latest = df.iloc[0]['holder_num']
        oldest = df.iloc[-1]['holder_num']
        total_change = (latest - oldest) / oldest * 100

        if total_change < -10:
            trend = "è‚¡ä¸œäººæ•°æŒç»­å‡å°‘ï¼Œç­¹ç è¶‹äºé›†ä¸­ï¼Œå¯èƒ½æœ‰ä¸»åŠ›å¸ç­¹"
        elif total_change > 10:
            trend = "è‚¡ä¸œäººæ•°æŒç»­å¢åŠ ï¼Œç­¹ç è¶‹äºåˆ†æ•£ï¼Œå¯èƒ½æœ‰ä¸»åŠ›å‡ºè´§"
        else:
            trend = "è‚¡ä¸œäººæ•°ç›¸å¯¹ç¨³å®šï¼Œç­¹ç åˆ†å¸ƒå˜åŒ–ä¸å¤§"

        result.append(f"**è¶‹åŠ¿åˆ†æ**: {trend}")
        result.append(f"**æœŸé—´å˜åŒ–**: {total_change:+.2f}%")
        result.append("")

        return "\n".join(result)

    except Exception as e:
        return f"è·å–è‚¡ä¸œäººæ•°æ•°æ®å¤±è´¥: {str(e)}"


def get_moneyflow(stock_code: str, days: int = 10) -> str:
    """
    è·å–ä¸ªè‚¡èµ„é‡‘æµå‘ï¼ˆå«ä¸»åŠ›æ€åº¦åˆ¤æ–­ï¼‰

    åˆ†æç»´åº¦:
    - ç‰¹å¤§å•ï¼ˆ>100ä¸‡ï¼‰: æœºæ„/å¤§æˆ·è¡Œä¸º
    - å¤§å•ï¼ˆ20-100ä¸‡ï¼‰: ä¸­å¤§èµ„é‡‘è¡Œä¸º
    - ä¸»åŠ›åˆè®¡ = ç‰¹å¤§å• + å¤§å•: ä»£è¡¨ä¸»åŠ›èµ„é‡‘æ•´ä½“æ€åº¦

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        days: è·å–å¤©æ•°ï¼Œé»˜è®¤10å¤©

    Returns:
        èµ„é‡‘æµå‘çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼ŒåŒ…å«ä¸»åŠ›æ€åº¦åˆ¤æ–­
    """
    try:
        pro = get_pro_api()
        ts_code = convert_stock_code(stock_code)

        end_date = datetime.now().strftime('%Y%m%d')
        start_date = (datetime.now() - timedelta(days=days*2)).strftime('%Y%m%d')

        df = pro.moneyflow(ts_code=ts_code, start_date=start_date, end_date=end_date)

        if df.empty:
            return f"æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„èµ„é‡‘æµå‘æ•°æ®"

        df = df.head(days)

        result = []
        result.append(f"# {ts_code} èµ„é‡‘æµå‘åˆ†æ\n")

        # è®¡ç®—ç´¯è®¡æ•°æ®
        total_elg_net = 0  # ç‰¹å¤§å•å‡€é¢
        total_lg_net = 0   # å¤§å•å‡€é¢
        total_md_net = 0   # ä¸­å•å‡€é¢
        total_sm_net = 0   # å°å•å‡€é¢
        total_net = 0      # æ€»å‡€é¢

        daily_data = []
        for _, row in df.iterrows():
            # ç‰¹å¤§å•ï¼ˆ>100ä¸‡ï¼‰
            elg_net = (row.get('buy_elg_amount', 0) - row.get('sell_elg_amount', 0)) / 10000
            # å¤§å•ï¼ˆ20-100ä¸‡ï¼‰
            lg_net = (row.get('buy_lg_amount', 0) - row.get('sell_lg_amount', 0)) / 10000
            # ä¸­å•
            md_net = (row.get('buy_md_amount', 0) - row.get('sell_md_amount', 0)) / 10000
            # å°å•
            sm_net = (row.get('buy_sm_amount', 0) - row.get('sell_sm_amount', 0)) / 10000
            # ä¸»åŠ›åˆè®¡
            main_net = elg_net + lg_net

            total_elg_net += elg_net
            total_lg_net += lg_net
            total_md_net += md_net
            total_sm_net += sm_net
            total_net += row.get('net_mf_amount', 0) / 10000

            daily_data.append({
                'date': row['trade_date'],
                'elg_net': elg_net,
                'lg_net': lg_net,
                'main_net': main_net,
                'md_net': md_net,
                'sm_net': sm_net
            })

        # ä¸»åŠ›åˆè®¡
        total_main_net = total_elg_net + total_lg_net

        # ä¸»åŠ›æ€åº¦åˆ¤æ–­
        if total_main_net > 1000:  # >1000ä¸‡å‡€æµå…¥
            attitude = "å¼ºåŠ¿å¢æŒ"
            attitude_emoji = "ğŸŸ¢ğŸŸ¢"
        elif total_main_net > 0:
            attitude = "å°å¹…å‡€æµå…¥"
            attitude_emoji = "ğŸŸ¢"
        elif total_main_net > -1000:
            attitude = "å°å¹…å‡€æµå‡º"
            attitude_emoji = "ğŸ”´"
        else:  # < -1000ä¸‡
            attitude = "æŒç»­å‡æŒ"
            attitude_emoji = "ğŸ”´ğŸ”´"

        # è¾“å‡ºæ±‡æ€»
        result.append("## ä¸»åŠ›èµ„é‡‘æ±‡æ€»ï¼ˆè¿‘{}æ—¥ï¼‰\n".format(days))
        result.append("| èµ„é‡‘ç±»å‹ | å‡€æµå…¥(ä¸‡å…ƒ) | è¯´æ˜ |")
        result.append("|---------|-------------|------|")
        result.append(f"| ç‰¹å¤§å•(>100ä¸‡) | {total_elg_net:+,.0f} | æœºæ„/å¤§æˆ· |")
        result.append(f"| å¤§å•(20-100ä¸‡) | {total_lg_net:+,.0f} | ä¸­å¤§èµ„é‡‘ |")
        result.append(f"| **ä¸»åŠ›åˆè®¡** | **{total_main_net:+,.0f}** | ç‰¹å¤§+å¤§å• |")
        result.append(f"| ä¸­å• | {total_md_net:+,.0f} | ä¸­å°èµ„é‡‘ |")
        result.append(f"| å°å• | {total_sm_net:+,.0f} | æ•£æˆ· |")
        result.append(f"| æ€»å‡€æµå…¥ | {total_net:+,.0f} | å…¨éƒ¨ |")

        result.append(f"\n## ä¸»åŠ›æ€åº¦åˆ¤æ–­\n")
        result.append(f"- **ä¸»åŠ›æ€åº¦**: {attitude_emoji} {attitude}")
        result.append(f"- **ä¸»åŠ›å‡€æµå…¥**: {total_main_net:+,.0f}ä¸‡å…ƒ")

        # èµ„é‡‘ç»“æ„åˆ†æ
        if total_main_net > 0 and total_sm_net < 0:
            result.append(f"- **èµ„é‡‘ç»“æ„**: ä¸»åŠ›å¸ç­¹ï¼Œæ•£æˆ·å‡ºè´§ï¼ˆè‰¯æ€§æ¢æ‰‹ï¼‰")
        elif total_main_net < 0 and total_sm_net > 0:
            result.append(f"- **èµ„é‡‘ç»“æ„**: ä¸»åŠ›å‡ºè´§ï¼Œæ•£æˆ·æ¥ç›˜ï¼ˆé£é™©ä¿¡å·ï¼‰")
        elif total_main_net > 0 and total_sm_net > 0:
            result.append(f"- **èµ„é‡‘ç»“æ„**: å…¨é¢æµå…¥ï¼Œå¸‚åœºçœ‹å¤š")
        else:
            result.append(f"- **èµ„é‡‘ç»“æ„**: å…¨é¢æµå‡ºï¼Œå¸‚åœºçœ‹ç©º")

        # æ¯æ—¥æ˜ç»†
        result.append("\n## æ¯æ—¥æ˜ç»†ï¼ˆå•ä½ï¼šä¸‡å…ƒï¼‰\n")
        result.append("| æ—¥æœŸ | ç‰¹å¤§å•å‡€ | å¤§å•å‡€ | ä¸»åŠ›å‡€ | ä¸­å•å‡€ | å°å•å‡€ |")
        result.append("|------|---------|--------|--------|--------|--------|")

        for d in daily_data[:10]:
            result.append(f"| {d['date']} | {d['elg_net']:+.0f} | {d['lg_net']:+.0f} | {d['main_net']:+.0f} | {d['md_net']:+.0f} | {d['sm_net']:+.0f} |")

        result.append("")
        return "\n".join(result)

    except Exception as e:
        return f"è·å–èµ„é‡‘æµå‘æ•°æ®å¤±è´¥: {str(e)}"


def get_hsgt_flow() -> str:
    """
    è·å–æ²ªæ·±æ¸¯é€šèµ„é‡‘æµå‘ï¼ˆåŒ—å‘èµ„é‡‘æ•´ä½“æµå‘ï¼‰

    âš ï¸ æ•°æ®å·²åœæ›´è¯´æ˜ï¼š
    2024å¹´8æœˆ19æ—¥èµ·ï¼Œæ²ªæ·±äº¤æ‰€è°ƒæ•´ä¿¡æ¯æŠ«éœ²æœºåˆ¶ï¼ŒåŒ—å‘èµ„é‡‘æ•´ä½“æµå‘æ•°æ®å·²åœæ­¢å®æ—¶æŠ«éœ²ã€‚
    æ­¤å‡½æ•°ä¿ç•™ç”¨äºå‘åå…¼å®¹ï¼Œä½†ä¸å†è¿”å›æœ‰æ•ˆæ•°æ®ã€‚

    å»ºè®®æ›¿ä»£æ–¹æ¡ˆï¼š
    - get_hsgt_top10(): è·å–æ¯æ—¥åŒ—å‘èµ„é‡‘åå¤§æˆäº¤è‚¡ï¼ˆä»å¯ç”¨ï¼‰
    - å‰åå¤§è‚¡ä¸œä¸­çš„"é¦™æ¸¯ä¸­å¤®ç»“ç®—"æŒè‚¡æ¯”ä¾‹å˜åŒ–å¯ä½œä¸ºå‚è€ƒ

    Returns:
        è¯´æ˜ä¿¡æ¯
    """
    return """# åŒ—å‘èµ„é‡‘æ•´ä½“æµå‘

**âš ï¸ æ•°æ®å·²åœæ›´**

2024å¹´8æœˆ19æ—¥èµ·ï¼Œæ²ªæ·±äº¤æ‰€è°ƒæ•´ä¿¡æ¯æŠ«éœ²æœºåˆ¶ï¼ŒåŒ—å‘èµ„é‡‘æ•´ä½“æµå‘æ•°æ®å·²åœæ­¢å®æ—¶æŠ«éœ²ã€‚

**å¯ç”¨æ›¿ä»£æ•°æ®æºï¼š**
1. **åŒ—å‘åå¤§æˆäº¤è‚¡** (`hsgt_top10`)ï¼šæŸ¥çœ‹æ¯æ—¥åŒ—å‘èµ„é‡‘æœ€æ´»è·ƒçš„è‚¡ç¥¨
2. **å‰åå¤§è‚¡ä¸œ**: å…³æ³¨"é¦™æ¸¯ä¸­å¤®ç»“ç®—"æŒè‚¡æ¯”ä¾‹å­£åº¦å˜åŒ–

è¯·ä½¿ç”¨ä»¥ä¸Šæ›¿ä»£æ•°æ®è¿›è¡Œåˆ†æã€‚

æ³¨ï¼šæ¸¯äº¤æ‰€è‡ª2024å¹´8æœˆ20æ—¥èµ·åœæ­¢æŠ«éœ²åŒ—å‘èµ„é‡‘æ¯æ—¥æ•°æ®ï¼Œä¸ªè‚¡æŒè‚¡æ˜ç»†(hk_hold)ä»…æœ‰å­£åº¦å¿«ç…§ã€‚
"""


def get_margin_data(stock_code: str) -> str:
    """
    è·å–èèµ„èåˆ¸æ•°æ®

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 

    Returns:
        èèµ„èåˆ¸æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    try:
        pro = get_pro_api()
        ts_code = convert_stock_code(stock_code)

        end_date = datetime.now().strftime('%Y%m%d')
        start_date = (datetime.now() - timedelta(days=30)).strftime('%Y%m%d')

        df = pro.margin_detail(ts_code=ts_code, start_date=start_date, end_date=end_date)

        if df.empty:
            return f"æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„èèµ„èåˆ¸æ•°æ®"

        df = df.head(10)  # æœ€è¿‘10å¤©

        result = []
        result.append("# èèµ„èåˆ¸åˆ†æ\n")
        result.append("## æœ€è¿‘10ä¸ªäº¤æ˜“æ—¥èèµ„èåˆ¸æ•°æ®\n")
        result.append("| æ—¥æœŸ | èèµ„ä½™é¢(äº¿) | èèµ„ä¹°å…¥(äº¿) | èåˆ¸ä½™é¢(ä¸‡) | èåˆ¸å–å‡º(ä¸‡è‚¡) |")
        result.append("|------|------------|------------|------------|--------------|")

        for _, row in df.iterrows():
            rzye = row.get('rzye', 0) / 1e8 if pd.notna(row.get('rzye')) else 0
            rzmre = row.get('rzmre', 0) / 1e8 if pd.notna(row.get('rzmre')) else 0
            rqye = row.get('rqye', 0) / 1e4 if pd.notna(row.get('rqye')) else 0
            rqmcl = row.get('rqmcl', 0) / 1e4 if pd.notna(row.get('rqmcl')) else 0
            result.append(f"| {row['trade_date']} | {rzye:.2f} | {rzmre:.2f} | {rqye:.2f} | {rqmcl:.2f} |")

        result.append("")

        # åˆ†æè¶‹åŠ¿
        latest = df.iloc[0]
        oldest = df.iloc[-1]
        rzye_change = (latest.get('rzye', 0) - oldest.get('rzye', 0)) / oldest.get('rzye', 1) * 100 if oldest.get('rzye') else 0

        result.append(f"**èèµ„ä½™é¢å˜åŒ–**: {rzye_change:+.2f}%")
        if rzye_change > 5:
            result.append("**å¸‚åœºæƒ…ç»ª**: èèµ„ä½™é¢ä¸Šå‡ï¼Œæ æ†èµ„é‡‘çœ‹å¤š")
        elif rzye_change < -5:
            result.append("**å¸‚åœºæƒ…ç»ª**: èèµ„ä½™é¢ä¸‹é™ï¼Œæ æ†èµ„é‡‘è°¨æ…")
        else:
            result.append("**å¸‚åœºæƒ…ç»ª**: èèµ„ä½™é¢ç¨³å®šï¼Œå¸‚åœºæƒ…ç»ªä¸­æ€§")
        result.append("")

        return "\n".join(result)

    except Exception as e:
        return f"è·å–èèµ„èåˆ¸æ•°æ®å¤±è´¥: {str(e)}"


def get_pmi() -> str:
    """
    è·å–PMIé‡‡è´­ç»ç†æŒ‡æ•°

    Returns:
        PMIæ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    try:
        pro = get_pro_api()

        df = pro.cn_pmi()

        if df.empty:
            return "æœªè·å–åˆ°PMIæ•°æ®"

        df = df.head(6)  # æœ€è¿‘6ä¸ªæœˆ

        result = []
        result.append("# å®è§‚ç»æµæŒ‡æ ‡ - PMI\n")
        result.append("## é‡‡è´­ç»ç†æŒ‡æ•°ï¼ˆæœ€è¿‘6ä¸ªæœˆï¼‰\n")
        result.append("| æœˆä»½ | åˆ¶é€ ä¸šPMI | æ–°è®¢å• | ç”Ÿäº§ | ä»ä¸šäººå‘˜ |")
        result.append("|------|----------|--------|------|---------|")

        for _, row in df.iterrows():
            month = row.get('MONTH', 'N/A')
            pmi = row.get('PMI010000', 0)  # åˆ¶é€ ä¸šPMI
            new_order = row.get('PMI010100', 0)  # æ–°è®¢å•
            production = row.get('PMI010200', 0)  # ç”Ÿäº§
            employment = row.get('PMI010300', 0)  # ä»ä¸šäººå‘˜
            result.append(f"| {month} | {pmi:.1f} | {new_order:.1f} | {production:.1f} | {employment:.1f} |")

        result.append("")

        # åˆ†æ
        latest_pmi = df.iloc[0].get('PMI010000', 50)
        if latest_pmi > 50:
            result.append(f"**å®è§‚ç»æµåˆ†æ**: åˆ¶é€ ä¸šPMIä¸º{latest_pmi:.1f}ï¼Œä½äºæ‰©å¼ åŒºé—´ï¼Œç»æµæ™¯æ°”åº¦å‘å¥½")
        else:
            result.append(f"**å®è§‚ç»æµåˆ†æ**: åˆ¶é€ ä¸šPMIä¸º{latest_pmi:.1f}ï¼Œä½äºæ”¶ç¼©åŒºé—´ï¼Œç»æµé¢ä¸´å‹åŠ›")
        result.append("")

        return "\n".join(result)

    except Exception as e:
        return f"è·å–PMIæ•°æ®å¤±è´¥: {str(e)}"


def calculate_ttm_dividend(df: pd.DataFrame, ts_code: str = None) -> tuple:
    """
    è®¡ç®—TTMåˆ†çº¢ï¼ˆè¿‡å»12ä¸ªæœˆæ‰€æœ‰åˆ†çº¢ç´¯åŠ ï¼‰

    é€»è¾‘ï¼š
    1. ä¼˜å…ˆæŒ‰é™¤æƒæ—¥(ex_date)ç­›é€‰è¿‡å»12ä¸ªæœˆçš„åˆ†çº¢è®°å½•
    2. è‹¥æ— ex_dateï¼ŒæŒ‰å¹´æŠ¥æ—¥æœŸ(end_date)ç­›é€‰æœ€è¿‘å®Œæ•´å¹´åº¦çš„æ‰€æœ‰åˆ†çº¢
    3. ç´¯åŠ æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„ç°é‡‘åˆ†çº¢

    Args:
        df: åˆ†çº¢æ•°æ®DataFrameï¼ˆéœ€åŒ…å«cash_div, ex_dateæˆ–end_dateåˆ—ï¼‰
        ts_code: è‚¡ç¥¨ä»£ç ï¼ˆç”¨äºæ—¥å¿—ï¼‰

    Returns:
        (ttm_dividend, dividend_details, count, date_range)
        - ttm_dividend: TTMåˆ†çº¢é‡‘é¢
        - dividend_details: åˆ†çº¢æ˜ç»†åˆ—è¡¨ [{"date": "2024-06-20", "amount": 0.98, "type": "ä¸­æœŸ"}]
        - count: åˆ†çº¢æ¬¡æ•°
        - date_range: ç»Ÿè®¡åŒºé—´ "2024-01-19 è‡³ 2025-01-19"
    """
    if df.empty:
        return 0, [], 0, ""

    today = datetime.now()
    one_year_ago = today - timedelta(days=365)

    # ç­›é€‰æœ‰æ•ˆç°é‡‘åˆ†çº¢è®°å½•
    df_valid = df[df['cash_div'].notna() & (df['cash_div'] > 0)].copy()
    if df_valid.empty:
        return 0, [], 0, ""

    # å°è¯•ç”¨é™¤æƒæ—¥ç­›é€‰è¿‡å»12ä¸ªæœˆ
    df_ttm = pd.DataFrame()
    date_range = ""

    if 'ex_date' in df_valid.columns:
        # æ¸…æ´—ex_dateåˆ—
        df_valid['ex_date_clean'] = df_valid['ex_date'].apply(
            lambda x: str(x) if pd.notna(x) and x != '' else None
        )
        df_with_ex = df_valid[df_valid['ex_date_clean'].notna()].copy()

        if not df_with_ex.empty:
            try:
                df_with_ex['ex_date_dt'] = pd.to_datetime(df_with_ex['ex_date_clean'], errors='coerce')
                mask = df_with_ex['ex_date_dt'] >= one_year_ago
                df_ttm = df_with_ex[mask]

                if not df_ttm.empty:
                    date_range = f"{one_year_ago.strftime('%Y-%m-%d')} è‡³ {today.strftime('%Y-%m-%d')}"
            except Exception:
                pass

    # å›é€€ï¼šè‹¥æ— æœ‰æ•ˆé™¤æƒæ—¥ï¼Œå–æœ€è¿‘å®Œæ•´å¹´åº¦çš„æ‰€æœ‰åˆ†çº¢
    if df_ttm.empty and 'end_date' in df_valid.columns:
        # æ‰¾åˆ°æœ€è¿‘å¹´åº¦
        df_valid['year'] = df_valid['end_date'].astype(str).str[:4]
        latest_year = df_valid['year'].max()
        if latest_year:
            df_ttm = df_valid[df_valid['year'] == latest_year]
            date_range = f"{latest_year}å¹´åº¦å…¨éƒ¨åˆ†çº¢"

    # å¦‚æœä»ä¸ºç©ºï¼Œå–æœ€è¿‘ä¸€æ¡
    if df_ttm.empty:
        df_ttm = df_valid.head(1)
        date_range = "æœ€è¿‘ä¸€æ¬¡åˆ†çº¢"

    # ç´¯åŠ è®¡ç®—
    ttm_div = float(df_ttm['cash_div'].sum())
    count = len(df_ttm)

    # ç”Ÿæˆæ˜ç»†
    details = []
    for _, row in df_ttm.iterrows():
        ex_date = row.get('ex_date', '')
        end_date = row.get('end_date', 'N/A')
        cash_div = float(row.get('cash_div', 0))

        # æ¨æ–­åˆ†çº¢ç±»å‹
        if pd.notna(end_date):
            month = str(end_date)[4:6] if len(str(end_date)) >= 6 else ""
            if month in ['06', '07']:
                div_type = "ä¸­æœŸ"
            elif month in ['12', '01']:
                div_type = "å¹´ç»ˆ"
            else:
                div_type = "å…¶ä»–"
        else:
            div_type = ""

        date_str = ex_date if pd.notna(ex_date) and ex_date else end_date
        details.append({
            "date": str(date_str),
            "amount": cash_div,
            "type": div_type,
            "end_date": str(end_date)
        })

    return ttm_div, details, count, date_range


def calculate_historical_yield_percentiles(
    ts_code: str,
    df_dividend: pd.DataFrame,
    years: int = 5
) -> dict:
    """
    è®¡ç®—å†å²è‚¡æ¯ç‡åˆ†ä½æ•°ï¼ˆä½¿ç”¨çœŸå®å†å²è‚¡ä»·ï¼‰

    é€»è¾‘ï¼š
    1. è·å–è¿‡å»Nå¹´æ¯å¹´å¹´æœ«çš„æ”¶ç›˜ä»·
    2. è®¡ç®—æ¯å¹´çš„å¹´åº¦ç´¯è®¡åˆ†çº¢
    3. å†å²è‚¡æ¯ç‡ = å¹´åº¦åˆ†çº¢ / å¹´æœ«æ”¶ç›˜ä»·
    4. è¿”å›25%/50%/75%åˆ†ä½

    Args:
        ts_code: Tushareæ ¼å¼è‚¡ç¥¨ä»£ç 
        df_dividend: åˆ†çº¢æ•°æ®DataFrame
        years: å›æº¯å¹´æ•°ï¼Œé»˜è®¤5å¹´

    Returns:
        {
            "yield_25_pct": 3.5,   # è¾ƒä½è‚¡æ¯ç‡ï¼ˆä¹è§‚æƒ…æ™¯ï¼‰
            "yield_50_pct": 4.5,   # ä¸­ä½æ•°ï¼ˆä¸­æ€§æƒ…æ™¯ï¼‰
            "yield_75_pct": 5.5,   # è¾ƒé«˜è‚¡æ¯ç‡ï¼ˆæ‚²è§‚æƒ…æ™¯ï¼‰
            "yield_min": 2.0,
            "yield_max": 7.0,
            "data_source": "å†å²5å¹´åˆ†ä½è®¡ç®—" | "è¡Œä¸šç»éªŒå€¼",
            "sample_years": 5,
            "yearly_data": [{"year": "2023", "dividend": 2.55, "close": 41.0, "yield": 6.22}],
            "success": True
        }
    """
    result = {
        "yield_25_pct": None,
        "yield_50_pct": None,
        "yield_75_pct": None,
        "yield_min": None,
        "yield_max": None,
        "data_source": "",
        "sample_years": 0,
        "yearly_data": [],
        "success": False
    }

    try:
        pro = get_pro_api()

        # 1. è·å–è¿‡å»Nå¹´çš„å¹´æœ«æ”¶ç›˜ä»·
        current_year = datetime.now().year
        year_end_prices = {}

        for y in range(current_year - years, current_year):
            # å°è¯•è·å–è¯¥å¹´æœ€åä¸€ä¸ªäº¤æ˜“æ—¥çš„æ”¶ç›˜ä»·
            year_end = f"{y}1231"
            year_start = f"{y}1201"

            try:
                df_price = pro.daily(
                    ts_code=ts_code,
                    start_date=year_start,
                    end_date=year_end,
                    fields='trade_date,close'
                )
                if not df_price.empty:
                    # å–è¯¥æœŸé—´æœ€åä¸€ä¸ªäº¤æ˜“æ—¥
                    year_end_prices[str(y)] = float(df_price.iloc[0]['close'])
            except Exception:
                continue

        if len(year_end_prices) < 3:
            result["data_source"] = "å†å²æ•°æ®ä¸è¶³ï¼Œæ— æ³•è®¡ç®—åˆ†ä½"
            return result

        # 2. è®¡ç®—æ¯å¹´çš„å¹´åº¦ç´¯è®¡åˆ†çº¢
        df_valid = df_dividend[df_dividend['cash_div'].notna() & (df_dividend['cash_div'] > 0)].copy()
        if 'end_date' in df_valid.columns:
            df_valid['year'] = df_valid['end_date'].astype(str).str[:4]
        else:
            result["data_source"] = "åˆ†çº¢æ•°æ®ç¼ºå°‘å¹´åº¦ä¿¡æ¯"
            return result

        # æŒ‰å¹´åº¦æ±‡æ€»åˆ†çº¢
        yearly_dividends = df_valid.groupby('year')['cash_div'].sum().to_dict()

        # 3. è®¡ç®—å„å¹´åº¦è‚¡æ¯ç‡
        yearly_yields = []
        yearly_data = []

        for year, close_price in year_end_prices.items():
            div_amount = yearly_dividends.get(year, 0)
            if div_amount > 0 and close_price > 0:
                yield_pct = (div_amount / close_price) * 100
                yearly_yields.append(yield_pct)
                yearly_data.append({
                    "year": year,
                    "dividend": round(div_amount, 3),
                    "close": round(close_price, 2),
                    "yield": round(yield_pct, 2)
                })

        if len(yearly_yields) < 3:
            result["data_source"] = "æœ‰æ•ˆå¹´åº¦æ•°æ®ä¸è¶³3å¹´"
            return result

        # 4. è®¡ç®—åˆ†ä½æ•°
        yields_array = np.array(yearly_yields)
        result["yield_min"] = round(float(yields_array.min()), 2)
        result["yield_25_pct"] = round(float(np.percentile(yields_array, 25)), 2)
        result["yield_50_pct"] = round(float(np.percentile(yields_array, 50)), 2)
        result["yield_75_pct"] = round(float(np.percentile(yields_array, 75)), 2)
        result["yield_max"] = round(float(yields_array.max()), 2)
        result["data_source"] = f"å†å²{len(yearly_yields)}å¹´åˆ†ä½è®¡ç®—"
        result["sample_years"] = len(yearly_yields)
        result["yearly_data"] = sorted(yearly_data, key=lambda x: x['year'], reverse=True)
        result["success"] = True

    except Exception as e:
        logger.warning(f"è®¡ç®—å†å²è‚¡æ¯ç‡åˆ†ä½å¤±è´¥: {e}")
        result["data_source"] = f"è®¡ç®—å¤±è´¥: {str(e)}"

    return result


def identify_special_dividends(df_valid: pd.DataFrame, avg_div: float) -> tuple:
    """
    è¯†åˆ«ç‰¹æ®Šåˆ†çº¢è®°å½•

    è§„åˆ™ï¼š
    1. å•æ¬¡åˆ†çº¢é‡‘é¢è¶…è¿‡è¿‘5å¹´å‡å€¼200%
    2. é€è‚¡+è½¬å¢æ¯”ä¾‹>5ï¼ˆé«˜é€è½¬ï¼‰

    Args:
        df_valid: æœ‰æ•ˆåˆ†çº¢è®°å½•DataFrame
        avg_div: å¹³å‡åˆ†çº¢é‡‘é¢

    Returns:
        (special_indices, special_records): ç‰¹æ®Šåˆ†çº¢ç´¢å¼•åˆ—è¡¨å’Œè®°å½•è¯¦æƒ…
    """
    special_indices = []
    special_records = []

    for idx, row in df_valid.iterrows():
        cash_div = row.get('cash_div', 0) or 0
        stk_div = row.get('stk_div', 0) or 0
        stk_bo = row.get('stk_bo_rate', 0) or 0
        end_date = row.get('end_date', 'N/A')

        # è§„åˆ™1ï¼šè¶…è¿‡å‡å€¼200%
        if avg_div > 0 and cash_div > avg_div * 2:
            special_indices.append(idx)
            special_records.append(f"{end_date}å¹´åº¦{cash_div:.3f}å…ƒï¼ˆè¶…å‡å€¼200%ï¼‰")
            continue

        # è§„åˆ™2ï¼šé«˜é€è½¬
        if (stk_div + stk_bo) > 5:
            special_indices.append(idx)
            special_records.append(f"{end_date}å¹´åº¦é«˜é€è½¬ï¼ˆé€{stk_div:.0f}è½¬{stk_bo:.0f}ï¼‰")
            continue

    return special_indices, special_records


def select_dividend_base(recent_div: float, avg_3y_div: float, avg_5y_div: float) -> tuple:
    """
    åˆ†çº¢åŸºæ•°é€‰æ‹©è§„åˆ™

    è§„åˆ™ï¼š
    1. é»˜è®¤ä½¿ç”¨TTMåˆ†çº¢ï¼ˆè¿‘1å¹´åˆ†çº¢ï¼‰
    2. è‹¥å½“å¹´åˆ†çº¢è¾ƒ3å¹´å‡å€¼æ³¢åŠ¨è¶…è¿‡Â±50%ï¼Œåˆ™ä½¿ç”¨è¿‘3å¹´å¹³å‡

    Args:
        recent_div: è¿‘1å¹´åˆ†çº¢
        avg_3y_div: è¿‘3å¹´å¹³å‡åˆ†çº¢
        avg_5y_div: è¿‘5å¹´å¹³å‡åˆ†çº¢

    Returns:
        (selected_base, reason): é€‰å®šçš„åŸºæ•°å’Œé€‰æ‹©åŸå› 
    """
    if avg_3y_div <= 0:
        return recent_div, "TTMåˆ†çº¢ï¼ˆæ— å†å²å¯¹æ¯”æ•°æ®ï¼‰"

    # æ£€æµ‹å¼‚å¸¸æ³¢åŠ¨
    volatility = abs(recent_div - avg_3y_div) / avg_3y_div if avg_3y_div > 0 else 0

    if volatility > 0.5:
        # æ³¢åŠ¨è¶…è¿‡50%ï¼Œä½¿ç”¨3å¹´å¹³å‡
        return avg_3y_div, f"è¿‘3å¹´å¹³å‡ï¼ˆTTMæ³¢åŠ¨{volatility*100:.0f}%>50%ï¼‰"
    else:
        return recent_div, "TTMåˆ†çº¢ï¼ˆè¿‘12ä¸ªæœˆï¼‰"


def calculate_cv_excluding_special(df_valid: pd.DataFrame, special_indices: list) -> tuple:
    """
    å‰”é™¤ç‰¹æ®Šåˆ†çº¢åè®¡ç®—æ³¢åŠ¨ç³»æ•°

    Args:
        df_valid: æœ‰æ•ˆåˆ†çº¢è®°å½•DataFrame
        special_indices: ç‰¹æ®Šåˆ†çº¢ç´¢å¼•åˆ—è¡¨

    Returns:
        (cv, excluded_info, sample_count): æ³¢åŠ¨ç³»æ•°ã€å‰”é™¤ä¿¡æ¯ã€æœ‰æ•ˆæ ·æœ¬æ•°
    """
    # å‰”é™¤ç‰¹æ®Šåˆ†çº¢
    df_normal = df_valid.drop(special_indices, errors='ignore')

    if len(df_normal) < 3:
        return None, "æœ‰æ•ˆå¸¸è§„åˆ†çº¢è®°å½•ä¸è¶³3å¹´", 0

    # ä½¿ç”¨è¿‘5å¹´æ•°æ®è®¡ç®—
    div_values = df_normal.head(5)['cash_div']
    div_std = div_values.std()
    div_mean = div_values.mean()
    cv = (div_std / div_mean) * 100 if div_mean > 0 else 100

    excluded_count = len(special_indices)
    excluded_info = f"å‰”é™¤{excluded_count}æ¡ç‰¹æ®Šåˆ†çº¢" if excluded_count > 0 else "æ— ç‰¹æ®Šåˆ†çº¢"

    return cv, excluded_info, len(div_values)


def get_dividend(stock_code: str, current_price: Optional[float] = None) -> str:
    """
    è·å–åˆ†çº¢é€è‚¡å†å²åŠè‚¡æ¯ç‡ä¼°å€¼æ•°æ®

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        current_price: å½“å‰è‚¡ä»·ï¼ˆå¯é€‰ï¼Œè‹¥ä¸æä¾›åˆ™è‡ªåŠ¨è·å–ï¼‰

    Returns:
        åˆ†çº¢å†å²åŠè‚¡æ¯ç‡ä¼°å€¼æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    try:
        pro = get_pro_api()
        ts_code = convert_stock_code(stock_code)

        df = pro.dividend(ts_code=ts_code)

        if df.empty:
            return f"æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„åˆ†çº¢å†å²"

        # å®‰å…¨è½¬æ¢å‡½æ•°
        def safe_float(val, default=0.0):
            if val is None or pd.isna(val):
                return default
            return float(val)

        # ===== è·å–å½“å‰è‚¡ä»·ï¼ˆè‹¥æœªæä¾›ï¼‰=====
        if current_price is None or current_price <= 0:
            try:
                end_date = datetime.now().strftime('%Y%m%d')
                recent_start = (datetime.now() - timedelta(days=10)).strftime('%Y%m%d')
                df_daily = pro.daily(ts_code=ts_code, start_date=recent_start, end_date=end_date, fields='trade_date,close')
                if not df_daily.empty:
                    current_price = safe_float(df_daily.iloc[0]['close'])
            except Exception as e:
                logger.warning(f"è·å–æ”¶ç›˜ä»·å¤±è´¥: {e}")
                current_price = 0.0

        # ===== åˆ†çº¢å†å²è¡¨æ ¼ =====
        df_display = df.head(10)  # å±•ç¤ºæœ€è¿‘10æ¬¡

        result = []
        result.append("# åˆ†çº¢é€è‚¡å†å²\n")
        result.append("| åˆ†çº¢å¹´åº¦ | æ¯è‚¡åˆ†çº¢(å…ƒ) | é€è‚¡(è‚¡) | è½¬å¢(è‚¡) | é™¤æƒæ—¥ |")
        result.append("|---------|------------|---------|---------|--------|")

        for _, row in df_display.iterrows():
            end_date = row.get('end_date', 'N/A')
            cash_div = safe_float(row.get('cash_div', 0))
            stk_div = safe_float(row.get('stk_div', 0))
            stk_bo = safe_float(row.get('stk_bo_rate', 0))
            ex_date = row.get('ex_date', 'N/A')
            result.append(f"| {end_date} | {cash_div:.3f} | {stk_div:.2f} | {stk_bo:.2f} | {ex_date} |")

        result.append("")

        # ===== æå–åˆ†çº¢æ•°æ® =====
        # ç­›é€‰æœ‰æ•ˆåˆ†çº¢è®°å½•ï¼ˆç°é‡‘åˆ†çº¢>0ï¼‰
        df_valid = df[df['cash_div'].notna() & (df['cash_div'] > 0)].copy()
        record_count = len(df_valid)

        # ===== è®¡ç®—TTMåˆ†çº¢ï¼ˆç´¯åŠ è¿‡å»12ä¸ªæœˆæ‰€æœ‰åˆ†çº¢ï¼‰=====
        ttm_div, ttm_details, ttm_count, ttm_date_range = calculate_ttm_dividend(df, ts_code)

        # è¿‘3å¹´å¹³å‡åˆ†çº¢ï¼ˆæŒ‰å¹´åº¦æ±‡æ€»åå¹³å‡ï¼Œéœ€æŒ‰å¹´ä»½é™åºæ’åˆ—å–æœ€è¿‘Nå¹´ï¼‰
        if 'end_date' in df_valid.columns:
            df_valid['year'] = df_valid['end_date'].astype(str).str[:4]
            yearly_sums = df_valid.groupby('year')['cash_div'].sum().sort_index(ascending=False)
            avg_3y_div = safe_float(yearly_sums.head(3).mean()) if len(yearly_sums) >= 1 else 0
            avg_5y_div = safe_float(yearly_sums.head(5).mean()) if len(yearly_sums) >= 1 else 0
        else:
            avg_3y_div = safe_float(df_valid.head(3)['cash_div'].mean()) if record_count >= 1 else 0
            avg_5y_div = safe_float(df_valid.head(5)['cash_div'].mean()) if record_count >= 1 else 0

        # ===== è¯†åˆ«ç‰¹æ®Šåˆ†çº¢ =====
        special_indices, special_records = identify_special_dividends(df_valid.head(5), avg_5y_div)

        # ===== é€‰æ‹©ä¼°å€¼åŸºæ•°ï¼ˆä½¿ç”¨TTMåˆ†çº¢ï¼‰=====
        selected_base, base_reason = select_dividend_base(ttm_div, avg_3y_div, avg_5y_div)

        # ===== è¾“å‡ºTTMåˆ†çº¢ä¿¡æ¯ =====
        result.append("## åˆ†çº¢æ•°æ®æ±‡æ€»\n")
        result.append(f"**TTMåˆ†çº¢ï¼ˆè¿‘12ä¸ªæœˆç´¯è®¡ï¼‰**: {ttm_div:.3f}å…ƒ")

        if ttm_count > 1:
            result.append(f"- åˆ†çº¢æ¬¡æ•°ï¼š{ttm_count}æ¬¡")
            result.append(f"- ç»Ÿè®¡åŒºé—´ï¼š{ttm_date_range}")
            result.append("- åˆ†çº¢æ˜ç»†ï¼š")
            for detail in ttm_details:
                type_str = f"ï¼ˆ{detail['type']}ï¼‰" if detail['type'] else ""
                result.append(f"  - {detail['date']}: {detail['amount']:.3f}å…ƒ{type_str}")
        elif ttm_count == 1:
            result.append(f"- ç»Ÿè®¡è¯´æ˜ï¼š{ttm_date_range}ï¼ˆå•æ¬¡åˆ†çº¢ï¼‰")

        result.append("")
        result.append(f"**è¿‘3å¹´å¹´å‡åˆ†çº¢**: {avg_3y_div:.3f}å…ƒ/å¹´")
        result.append(f"**è¿‘5å¹´å¹´å‡åˆ†çº¢**: {avg_5y_div:.3f}å…ƒ/å¹´")
        result.append("")
        result.append(f"**ğŸ“Œ ä¼°å€¼åŸºæ•°é€‰æ‹©**: {selected_base:.3f}å…ƒ ({base_reason})")
        if special_records:
            result.append(f"**âš ï¸ ç‰¹æ®Šåˆ†çº¢è¯†åˆ«**: {'; '.join(special_records)}")
        result.append("")

        # ===== å½“å‰è‚¡æ¯ç‡è®¡ç®—ï¼ˆä½¿ç”¨TTMåˆ†çº¢ï¼‰=====
        if current_price > 0 and ttm_div > 0:
            current_yield = (ttm_div / current_price) * 100
            result.append(f"**å½“å‰è‚¡ä»·**: {current_price:.2f}å…ƒ")
            result.append(f"**å½“å‰è‚¡æ¯ç‡**: {current_yield:.2f}%ï¼ˆTTMåˆ†çº¢{ttm_div:.3f}å…ƒ Ã· è‚¡ä»·{current_price:.2f}å…ƒï¼‰")
            result.append("")

            # ===== è‚¡æ¯ç‡å†å²åˆ†ä½è®¡ç®—ï¼ˆä½¿ç”¨çœŸå®å†å²è‚¡ä»·ï¼‰=====
            hist_yield = calculate_historical_yield_percentiles(ts_code, df, years=5)

            if hist_yield["success"]:
                result.append("## è‚¡æ¯ç‡å†å²åˆ†ä½ï¼ˆçœŸå®å†å²è‚¡ä»·è®¡ç®—ï¼‰\n")
                result.append("| æœ€å°å€¼ | 25%åˆ†ä½ | ä¸­ä½æ•° | 75%åˆ†ä½ | æœ€å¤§å€¼ | æ ·æœ¬å¹´æ•° |")
                result.append("|--------|---------|--------|---------|--------|---------|")
                result.append(f"| {hist_yield['yield_min']:.2f}% | {hist_yield['yield_25_pct']:.2f}% | {hist_yield['yield_50_pct']:.2f}% | {hist_yield['yield_75_pct']:.2f}% | {hist_yield['yield_max']:.2f}% | {hist_yield['sample_years']}å¹´ |")
                result.append(f"\n**æ•°æ®æ¥æº**: {hist_yield['data_source']}")
                result.append("")

                # å¹´åº¦æ˜ç»†è¡¨
                if hist_yield["yearly_data"]:
                    result.append("**å¹´åº¦è‚¡æ¯ç‡æ˜ç»†**:")
                    result.append("| å¹´åº¦ | å¹´åº¦åˆ†çº¢(å…ƒ) | å¹´æœ«è‚¡ä»·(å…ƒ) | è‚¡æ¯ç‡ |")
                    result.append("|------|-------------|-------------|--------|")
                    for yd in hist_yield["yearly_data"][:5]:
                        result.append(f"| {yd['year']} | {yd['dividend']:.3f} | {yd['close']:.2f} | {yd['yield']:.2f}% |")
                    result.append("")

                # å½“å‰è‚¡æ¯ç‡åˆ†ä½è¯„ä¼°
                if current_yield <= hist_yield['yield_25_pct']:
                    result.append(f"**å½“å‰è‚¡æ¯ç‡{current_yield:.2f}%ä½äºå†å²ä½ä½**ï¼ˆ<25%åˆ†ä½ï¼‰ï¼Œè‚¡ä»·å¯èƒ½è¢«é«˜ä¼°")
                elif current_yield >= hist_yield['yield_75_pct']:
                    result.append(f"**å½“å‰è‚¡æ¯ç‡{current_yield:.2f}%ä½äºå†å²é«˜ä½**ï¼ˆ>75%åˆ†ä½ï¼‰ï¼Œè‚¡ä»·å¯èƒ½è¢«ä½ä¼°")
                else:
                    result.append(f"**å½“å‰è‚¡æ¯ç‡{current_yield:.2f}%ä½äºå†å²ä¸­ä½åŒºé—´**")
                result.append("")

            else:
                # å›é€€è¡Œä¸šå›ºå®šåŒºé—´
                result.append("## è‚¡æ¯ç‡å‚è€ƒåŒºé—´ï¼ˆè¡Œä¸šç»éªŒå€¼ï¼‰\n")
                result.append(f"âš ï¸ {hist_yield['data_source']}ï¼Œä½¿ç”¨è¡Œä¸šç»éªŒå€¼ï¼Œ**ç½®ä¿¡åº¦-10%**\n")
                result.append("| è¡Œä¸š | 25%åˆ†ä½ | ä¸­ä½æ•° | 75%åˆ†ä½ | è¯´æ˜ |")
                result.append("|------|---------|--------|---------|------|")
                result.append("| å…¬ç”¨äº‹ä¸š(ç”µåŠ›) | 3.0% | 3.5% | 4.5% | é•¿æ±Ÿç”µåŠ›ç­‰ |")
                result.append("| é“¶è¡Œ | 4.0% | 5.0% | 6.0% | å›½æœ‰å¤§è¡Œ |")
                result.append("| ç…¤ç‚­ | 4.0% | 5.5% | 7.0% | ä¸­å›½ç¥åç­‰ |")
                result.append("| é«˜é€Ÿå…¬è·¯ | 4.0% | 5.0% | 7.0% | ç°é‡‘æµç¨³å®š |")
                result.append("| æ¸¯å£ | 3.5% | 4.5% | 6.0% | å‘¨æœŸæ€§è¾ƒå¼± |")
                result.append("")

            # ===== è‚¡æ¯ç‡ç›®æ ‡ä»·å‚è€ƒï¼ˆä½¿ç”¨å†å²åˆ†ä½æˆ–è¡Œä¸šç»éªŒå€¼ï¼‰=====
            result.append("## è‚¡æ¯ç‡ç›®æ ‡ä»·å‚è€ƒ\n")
            result.append("**ç”¨äºé«˜è‚¡æ¯è‚¡ç¥¨ï¼ˆå…¬ç”¨äº‹ä¸š/é“¶è¡Œ/ç…¤ç‚­/é«˜é€Ÿå…¬è·¯ï¼‰çš„ä¼°å€¼äº¤å‰éªŒè¯**\n")
            result.append(f"**ä¼°å€¼åŸºæ•°**: {selected_base:.3f}å…ƒ ({base_reason})\n")

            # ä½¿ç”¨å†å²åˆ†ä½æˆ–è¡Œä¸šç»éªŒå€¼ç”Ÿæˆç›®æ ‡è‚¡æ¯ç‡
            if hist_yield["success"]:
                yield_pessimistic = hist_yield['yield_75_pct']  # é«˜è‚¡æ¯ç‡ = æ‚²è§‚
                yield_neutral = hist_yield['yield_50_pct']      # ä¸­ä½æ•° = ä¸­æ€§
                yield_optimistic = hist_yield['yield_25_pct']   # ä½è‚¡æ¯ç‡ = ä¹è§‚
                yield_source = "å†å²åˆ†ä½"
            else:
                # é»˜è®¤ä½¿ç”¨ç…¤ç‚­/é«˜è‚¡æ¯è¡Œä¸šç»éªŒå€¼
                yield_pessimistic = 7.0
                yield_neutral = 5.5
                yield_optimistic = 4.0
                yield_source = "è¡Œä¸šç»éªŒå€¼"

            result.append(f"**ç›®æ ‡è‚¡æ¯ç‡æ¥æº**: {yield_source}\n")
            result.append("| æƒ…æ™¯ | ç›®æ ‡è‚¡æ¯ç‡ | å¯¹åº”ç›®æ ‡ä»· | è¾ƒå½“å‰æ¶¨è·Œå¹… |")
            result.append("|------|-----------|-----------|------------|")

            scenarios = [
                ("æ‚²è§‚ï¼ˆé«˜æ”¶ç›Šè¦æ±‚ï¼‰", yield_pessimistic),
                ("ä¸­æ€§", yield_neutral),
                ("ä¹è§‚ï¼ˆä½æ”¶ç›Šæ¥å—ï¼‰", yield_optimistic),
            ]

            for scenario, target_yield in scenarios:
                if selected_base > 0 and target_yield > 0:
                    target_price = selected_base / (target_yield / 100)
                    change_pct = (target_price - current_price) / current_price * 100
                    result.append(f"| {scenario} | {target_yield:.1f}% | {target_price:.2f}å…ƒ | {change_pct:+.1f}% |")

            # è®¡ç®—åŠ æƒç›®æ ‡ä»·
            if selected_base > 0:
                weighted_price = (
                    0.25 * (selected_base / (yield_pessimistic / 100)) +
                    0.50 * (selected_base / (yield_neutral / 100)) +
                    0.25 * (selected_base / (yield_optimistic / 100))
                )
                weighted_change = (weighted_price - current_price) / current_price * 100
                result.append(f"| **åŠ æƒï¼ˆ25/50/25ï¼‰** | - | **{weighted_price:.2f}å…ƒ** | **{weighted_change:+.1f}%** |")

            result.append("")
            result.append(f"**è®¡ç®—å…¬å¼**: ç›®æ ‡ä»· = ä¼°å€¼åŸºæ•°({selected_base:.3f}å…ƒ) Ã· ç›®æ ‡è‚¡æ¯ç‡")
            result.append("")

            # ===== åˆ†çº¢ç¨³å®šæ€§è¯„ä¼°ï¼ˆå‰”é™¤ç‰¹æ®Šåˆ†çº¢ï¼‰=====
            if record_count >= 3:
                div_cv, excluded_info, sample_count = calculate_cv_excluding_special(
                    df_valid.head(5), special_indices
                )

                result.append("## åˆ†çº¢ç¨³å®šæ€§è¯„ä¼°\n")

                if special_records:
                    result.append(f"**å‰”é™¤è®°å½•**: {'; '.join(special_records)}")
                    result.append(f"**æœ‰æ•ˆæ ·æœ¬**: è¿‘{sample_count}å¹´å¸¸è§„åˆ†çº¢ï¼ˆ{excluded_info}ï¼‰")
                    result.append("")

                if div_cv is not None:
                    if div_cv < 10:
                        result.append(f"âœ… **åˆ†çº¢éå¸¸ç¨³å®š**ï¼šæ³¢åŠ¨ç³»æ•°{div_cv:.1f}%ï¼ˆ<10%ï¼‰ï¼Œé€‚åˆè‚¡æ¯ç‡ä¼°å€¼")
                    elif div_cv < 30:
                        result.append(f"âš ï¸ **åˆ†çº¢è¾ƒç¨³å®š**ï¼šæ³¢åŠ¨ç³»æ•°{div_cv:.1f}%ï¼ˆ10%-30%ï¼‰ï¼Œè‚¡æ¯ç‡ä¼°å€¼å¯å‚è€ƒ")
                    else:
                        result.append(f"âŒ **åˆ†çº¢æ³¢åŠ¨è¾ƒå¤§**ï¼šæ³¢åŠ¨ç³»æ•°{div_cv:.1f}%ï¼ˆ>30%ï¼‰ï¼Œè‚¡æ¯ç‡ä¼°å€¼ç½®ä¿¡åº¦è¾ƒä½")
                else:
                    result.append(f"âš ï¸ {excluded_info}ï¼Œæ— æ³•è®¡ç®—æ³¢åŠ¨ç³»æ•°")
                result.append("")

        else:
            if ttm_div <= 0:
                result.append("âš ï¸ **æ— ç°é‡‘åˆ†çº¢è®°å½•**ï¼Œä¸é€‚ç”¨è‚¡æ¯ç‡ä¼°å€¼æ³•")
            elif current_price <= 0:
                result.append("âš ï¸ æ— æ³•è·å–å½“å‰è‚¡ä»·ï¼Œè‚¡æ¯ç‡ç›¸å…³è®¡ç®—ç•¥è¿‡")
            result.append("")

        return "\n".join(result)

    except Exception as e:
        logger.error(f"è·å–åˆ†çº¢å†å²å¤±è´¥: {str(e)}")
        return f"è·å–åˆ†çº¢å†å²å¤±è´¥: {str(e)}"


def get_top_list(stock_code: str, days: int = 30) -> str:
    """
    è·å–é¾™è™æ¦œæ•°æ®

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        days: æŸ¥è¯¢å¤©æ•°ï¼Œé»˜è®¤30å¤©

    Returns:
        é¾™è™æ¦œæ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    try:
        pro = get_pro_api()
        ts_code = convert_stock_code(stock_code)

        # TuShare top_list APIè¦æ±‚ä½¿ç”¨trade_dateå‚æ•°
        # å…ˆè·å–æœ€è¿‘çš„äº¤æ˜“æ—¥å†ï¼Œç„¶åé€æ—¥æŸ¥è¯¢
        end_date = datetime.now().strftime('%Y%m%d')
        start_date = (datetime.now() - timedelta(days=days * 2)).strftime('%Y%m%d')

        # è·å–äº¤æ˜“æ—¥å†
        cal_df = pro.trade_cal(exchange='SSE', start_date=start_date, end_date=end_date, is_open='1')
        if cal_df.empty:
            return f"è·å–äº¤æ˜“æ—¥å†å¤±è´¥"

        trade_dates = cal_df.sort_values('cal_date', ascending=False)['cal_date'].head(days).tolist()

        all_data = []
        for trade_date in trade_dates[:10]:  # æœ€å¤šæŸ¥è¯¢æœ€è¿‘10ä¸ªäº¤æ˜“æ—¥
            try:
                df = pro.top_list(trade_date=trade_date, ts_code=ts_code)
                if not df.empty:
                    all_data.append(df)
            except Exception:
                continue

        if not all_data:
            return f"è‚¡ç¥¨ {stock_code} è¿‘æœŸæœªä¸Šé¾™è™æ¦œ"

        df = pd.concat(all_data, ignore_index=True)
        df = df.sort_values('trade_date', ascending=False)

        result = []
        result.append("# é¾™è™æ¦œåˆ†æ\n")

        for _, row in df.iterrows():
            result.append(f"## {row['trade_date']} é¾™è™æ¦œ\n")
            result.append(f"- **ä¸Šæ¦œåŸå› **: {row.get('reason', 'N/A')}")
            result.append(f"- **æ”¶ç›˜ä»·**: {row.get('close', 0):.2f}å…ƒ")
            result.append(f"- **æ¶¨è·Œå¹…**: {row.get('pct_change', 0):.2f}%")
            result.append(f"- **æ¢æ‰‹ç‡**: {row.get('turnover_rate', 0):.2f}%")

            l_buy = row.get('l_buy', 0) / 1e8 if pd.notna(row.get('l_buy')) else 0
            l_sell = row.get('l_sell', 0) / 1e8 if pd.notna(row.get('l_sell')) else 0
            net = row.get('net_amount', 0) / 1e8 if pd.notna(row.get('net_amount')) else 0

            result.append(f"- **é¾™è™æ¦œä¹°å…¥**: {l_buy:.2f}äº¿å…ƒ")
            result.append(f"- **é¾™è™æ¦œå–å‡º**: {l_sell:.2f}äº¿å…ƒ")
            result.append(f"- **å‡€ä¹°å…¥**: {net:+.2f}äº¿å…ƒ")
            result.append("")

        return "\n".join(result)

    except Exception as e:
        return f"è·å–é¾™è™æ¦œæ•°æ®å¤±è´¥: {str(e)}"


# ç»¼åˆæ•°æ®è·å–å‡½æ•°ï¼ˆä¾›å·¥å…·è°ƒç”¨ï¼‰

def get_china_stock_comprehensive(stock_code: str, trade_date: Optional[str] = None) -> str:
    """
    è·å–ä¸­å›½Aè‚¡ç»¼åˆæ•°æ®

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        trade_date: äº¤æ˜“æ—¥æœŸ

    Returns:
        ç»¼åˆæ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    result = []

    # åŸºæœ¬ä¿¡æ¯
    result.append(get_stock_basic_info(stock_code))

    # ä¼°å€¼æ•°æ®
    result.append(get_daily_basic(stock_code, trade_date))

    # è´¢åŠ¡æŒ‡æ ‡
    result.append(get_financial_indicators(stock_code))

    # ä¸šç»©é¢„å‘Š
    result.append(get_forecast(stock_code))

    return "\n".join(result)


def get_china_stock_fundamentals(stock_code: str) -> str:
    """
    è·å–åŸºæœ¬é¢ç»¼åˆæ•°æ®

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 

    Returns:
        åŸºæœ¬é¢æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    result = []

    # è´¢åŠ¡æŠ¥è¡¨
    result.append(get_financial_statements(stock_code))

    # è´¢åŠ¡æŒ‡æ ‡
    result.append(get_financial_indicators(stock_code))

    # ä¸šç»©é¢„å‘Š
    result.append(get_forecast(stock_code))

    # åˆ†çº¢å†å²
    result.append(get_dividend(stock_code))

    return "\n".join(result)


def get_china_stock_sentiment(stock_code: str) -> str:
    """
    è·å–å¸‚åœºæƒ…ç»ªç»¼åˆæ•°æ®

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 

    Returns:
        å¸‚åœºæƒ…ç»ªæ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    result = []

    # èµ„é‡‘æµå‘
    result.append(get_moneyflow(stock_code))

    # åŒ—å‘èµ„é‡‘ï¼ˆä½¿ç”¨åå¤§æˆäº¤è‚¡æ›¿ä»£å·²åœæ›´çš„æ•´ä½“æµå‘ï¼‰
    result.append(get_hsgt_top10())

    # èèµ„èåˆ¸
    result.append(get_margin_data(stock_code))

    # è‚¡ä¸œæ•°æ®ï¼ˆå«é¦™æ¸¯ä¸­å¤®ç»“ç®—æŒè‚¡æ¯”ä¾‹ï¼‰
    result.append(get_top10_holders(stock_code))
    result.append(get_holder_number(stock_code))

    return "\n".join(result)


# ============= æ–°å¢æ•°æ®æºå‡½æ•°ï¼ˆPhase 1.1 æ‰©å±•ï¼‰ =============


# ============= å·²åºŸå¼ƒå‡½æ•°è¯´æ˜ =============
#
# get_hk_hold() å‡½æ•°å·²ç§»é™¤
# åºŸå¼ƒåŸå› ï¼šæ¸¯äº¤æ‰€è‡ª2024å¹´8æœˆ20æ—¥èµ·åœæ­¢æŠ«éœ²åŒ—å‘èµ„é‡‘æ¯æ—¥æ•°æ®
# hk_hold API ç›®å‰ä»…è¿”å›å­£åº¦æ•°æ®ï¼ˆæ¯å¹´3/6/9/12æœˆï¼‰ï¼Œæ— æ³•ç”¨äºçŸ­æœŸäº¤æ˜“åˆ†æ
#
# æ›¿ä»£æ–¹æ¡ˆï¼š
# 1. get_hsgt_top10() - æŸ¥çœ‹æ¯æ—¥åŒ—å‘èµ„é‡‘åå¤§æˆäº¤è‚¡
# 2. get_top10_holders() - é€šè¿‡"é¦™æ¸¯ä¸­å¤®ç»“ç®—"æŒè‚¡æ¯”ä¾‹å­£åº¦å˜åŒ–åˆ¤æ–­å¤–èµ„æ€åº¦
# ============================================


def get_hsgt_top10(trade_date: Optional[str] = None) -> str:
    """
    è·å–æ²ªæ·±æ¸¯é€šåå¤§æˆäº¤è‚¡

    Args:
        trade_date: äº¤æ˜“æ—¥æœŸ YYYYMMDDï¼Œé»˜è®¤æœ€è¿‘äº¤æ˜“æ—¥

    Returns:
        æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼ŒåŒ…å«ä¹°å…¥/å–å‡ºæˆäº¤é¢å‰10ã€å‡€ä¹°å…¥é‡‘é¢
    """
    try:
        pro = get_pro_api()

        if trade_date is None:
            # è·å–æœ€è¿‘äº¤æ˜“æ—¥
            end_date = datetime.now().strftime('%Y%m%d')
            start_date = (datetime.now() - timedelta(days=10)).strftime('%Y%m%d')
            # å…ˆè·å–ä¸€æ¡æ•°æ®ç¡®å®šæœ€æ–°äº¤æ˜“æ—¥
            df_check = pro.hsgt_top10(start_date=start_date, end_date=end_date)
            if df_check.empty:
                return "æœªè·å–åˆ°æ²ªæ·±æ¸¯é€šåå¤§æˆäº¤è‚¡æ•°æ®"
            trade_date = df_check['trade_date'].max()

        # è·å–æ²ªè‚¡é€šåå¤§ (market_type='1') å’Œæ·±è‚¡é€šåå¤§ (market_type='3')
        df_sh = pro.hsgt_top10(trade_date=trade_date, market_type='1')
        df_sz = pro.hsgt_top10(trade_date=trade_date, market_type='3')

        result = []
        result.append(f"# æ²ªæ·±æ¸¯é€šåå¤§æˆäº¤è‚¡ ({trade_date})\n")

        if not df_sh.empty:
            result.append("## æ²ªè‚¡é€šåå¤§æˆäº¤è‚¡\n")
            result.append("| æ’å | ä»£ç  | åç§° | æ”¶ç›˜ä»· | æ¶¨è·Œå¹…(%) | å‡€ä¹°å…¥(ä¸‡) |")
            result.append("|------|------|------|--------|----------|-----------|")
            for _, row in df_sh.head(10).iterrows():
                rank = row.get('rank', 0)
                ts_code = row.get('ts_code', 'N/A')
                name = row.get('name', 'N/A')[:8]
                close = row.get('close', 0)
                change = row.get('change', 0) if pd.notna(row.get('change')) else 0
                net_amount = row.get('net_amount', 0) / 10000 if pd.notna(row.get('net_amount')) else 0
                result.append(f"| {rank} | {ts_code} | {name} | {close:.2f} | {change:.2f} | {net_amount:+.2f} |")
            result.append("")

        if not df_sz.empty:
            result.append("## æ·±è‚¡é€šåå¤§æˆäº¤è‚¡\n")
            result.append("| æ’å | ä»£ç  | åç§° | æ”¶ç›˜ä»· | æ¶¨è·Œå¹…(%) | å‡€ä¹°å…¥(ä¸‡) |")
            result.append("|------|------|------|--------|----------|-----------|")
            for _, row in df_sz.head(10).iterrows():
                rank = row.get('rank', 0)
                ts_code = row.get('ts_code', 'N/A')
                name = row.get('name', 'N/A')[:8]
                close = row.get('close', 0)
                change = row.get('change', 0) if pd.notna(row.get('change')) else 0
                net_amount = row.get('net_amount', 0) / 10000 if pd.notna(row.get('net_amount')) else 0
                result.append(f"| {rank} | {ts_code} | {name} | {close:.2f} | {change:.2f} | {net_amount:+.2f} |")
            result.append("")

        return "\n".join(result) if result else "æœªè·å–åˆ°æ²ªæ·±æ¸¯é€šåå¤§æˆäº¤è‚¡æ•°æ®"

    except Exception as e:
        return f"è·å–æ²ªæ·±æ¸¯é€šåå¤§æˆäº¤è‚¡æ•°æ®å¤±è´¥: {str(e)}"


def get_block_trade(stock_code: str, days: int = 30) -> str:
    """
    è·å–å¤§å®—äº¤æ˜“æ•°æ®

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        days: è·å–å¤©æ•°

    Returns:
        æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼ŒåŒ…å«äº¤æ˜“æ—¥æœŸã€æˆäº¤ä»·ã€æŠ˜æº¢ä»·ç‡ã€ä¹°å–è¥ä¸šéƒ¨
    """
    try:
        pro = get_pro_api()
        ts_code = convert_stock_code(stock_code)

        end_date = datetime.now().strftime('%Y%m%d')
        start_date = (datetime.now() - timedelta(days=days * 2)).strftime('%Y%m%d')

        df = pro.block_trade(ts_code=ts_code, start_date=start_date, end_date=end_date)

        if df.empty:
            return f"è‚¡ç¥¨ {stock_code} è¿‘æœŸæ— å¤§å®—äº¤æ˜“è®°å½•"

        df = df.head(20)  # æœ€è¿‘20ç¬”

        result = []
        result.append("# å¤§å®—äº¤æ˜“åˆ†æ\n")
        result.append(f"## è¿‘æœŸå¤§å®—äº¤æ˜“è®°å½•ï¼ˆ{stock_code}ï¼‰\n")
        result.append("| æ—¥æœŸ | æˆäº¤ä»· | æˆäº¤é‡(ä¸‡è‚¡) | æˆäº¤é¢(ä¸‡) | æŠ˜æº¢ä»·(%) | ä¹°æ–¹ | å–æ–¹ |")
        result.append("|------|--------|------------|----------|----------|------|------|")

        total_vol = 0
        total_amount = 0
        discount_trades = 0

        for _, row in df.iterrows():
            trade_date = row.get('trade_date', 'N/A')
            price = row.get('price', 0)
            vol = row.get('vol', 0) / 10000 if pd.notna(row.get('vol')) else 0  # è‚¡è½¬ä¸‡è‚¡
            amount = row.get('amount', 0) / 10000 if pd.notna(row.get('amount')) else 0  # å…ƒè½¬ä¸‡å…ƒ

            # è®¡ç®—æŠ˜æº¢ä»·ç‡ï¼ˆéœ€è¦å½“æ—¥æ”¶ç›˜ä»·ï¼‰
            # ç®€åŒ–å¤„ç†ï¼šæ˜¾ç¤ºä¸ºN/Aï¼Œæˆ–é€šè¿‡å…¶ä»–æ–¹å¼è·å–
            discount = "N/A"

            buyer = row.get('buyer', 'N/A')[:10] if row.get('buyer') else 'N/A'
            seller = row.get('seller', 'N/A')[:10] if row.get('seller') else 'N/A'

            result.append(f"| {trade_date} | {price:.2f} | {vol:.2f} | {amount:.2f} | {discount} | {buyer} | {seller} |")

            total_vol += vol
            total_amount += amount

        result.append("")
        result.append(f"**ç»Ÿè®¡æ±‡æ€»**: å…±{len(df)}ç¬”å¤§å®—äº¤æ˜“")
        result.append(f"**ç´¯è®¡æˆäº¤**: {total_vol:.2f}ä¸‡è‚¡ï¼Œ{total_amount:.2f}ä¸‡å…ƒ")

        # åˆ†æ
        if len(df) >= 5:
            result.append("")
            result.append("**é£é™©æç¤º**: è¿‘æœŸå¤§å®—äº¤æ˜“é¢‘ç¹ï¼Œéœ€å…³æ³¨æ˜¯å¦å­˜åœ¨å‡æŒå‹åŠ›")

        result.append("")
        return "\n".join(result)

    except Exception as e:
        return f"è·å–å¤§å®—äº¤æ˜“æ•°æ®å¤±è´¥: {str(e)}"


def get_pledge_stat(stock_code: str) -> str:
    """
    è·å–è‚¡æƒè´¨æŠ¼ç»Ÿè®¡

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 

    Returns:
        æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼ŒåŒ…å«è´¨æŠ¼æ€»è‚¡æ•°ã€è´¨æŠ¼æ¯”ä¾‹ã€é£é™©æç¤º
    """
    try:
        pro = get_pro_api()
        ts_code = convert_stock_code(stock_code)

        df = pro.pledge_stat(ts_code=ts_code)

        if df.empty:
            return f"æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„è‚¡æƒè´¨æŠ¼æ•°æ®"

        df = df.head(8)  # æœ€è¿‘8æœŸ

        result = []
        result.append("# è‚¡æƒè´¨æŠ¼åˆ†æ\n")
        result.append("## è‚¡æƒè´¨æŠ¼ç»Ÿè®¡\n")
        result.append("| æˆªæ­¢æ—¥æœŸ | è´¨æŠ¼æ¬¡æ•° | æ— é™å”®è´¨æŠ¼(ä¸‡è‚¡) | é™å”®è´¨æŠ¼(ä¸‡è‚¡) | æ€»è‚¡æœ¬(ä¸‡è‚¡) | è´¨æŠ¼æ¯”ä¾‹(%) |")
        result.append("|---------|---------|----------------|--------------|------------|------------|")

        latest_ratio = 0
        for _, row in df.iterrows():
            end_date = row.get('end_date', 'N/A')
            pledge_count = row.get('pledge_count', 0)
            unrest_pledge = row.get('unrest_pledge', 0) / 10000 if pd.notna(row.get('unrest_pledge')) else 0
            rest_pledge = row.get('rest_pledge', 0) / 10000 if pd.notna(row.get('rest_pledge')) else 0
            total_share = row.get('total_share', 0) / 10000 if pd.notna(row.get('total_share')) else 0
            pledge_ratio = row.get('pledge_ratio', 0) if pd.notna(row.get('pledge_ratio')) else 0

            if latest_ratio == 0:
                latest_ratio = pledge_ratio

            result.append(f"| {end_date} | {pledge_count} | {unrest_pledge:.2f} | {rest_pledge:.2f} | {total_share:.2f} | {pledge_ratio:.2f} |")

        result.append("")

        # é£é™©è¯„ä¼°
        if latest_ratio > 50:
            risk_level = "ã€é«˜é£é™©ã€‘è´¨æŠ¼æ¯”ä¾‹è¶…è¿‡50%ï¼Œå­˜åœ¨é‡å¤§å¹³ä»“é£é™©"
        elif latest_ratio > 30:
            risk_level = "ã€ä¸­é£é™©ã€‘è´¨æŠ¼æ¯”ä¾‹è¾ƒé«˜ï¼Œéœ€å¯†åˆ‡å…³æ³¨è‚¡ä»·æ³¢åŠ¨"
        elif latest_ratio > 10:
            risk_level = "ã€ä½é£é™©ã€‘è´¨æŠ¼æ¯”ä¾‹é€‚ä¸­ï¼Œé£é™©å¯æ§"
        else:
            risk_level = "ã€å®‰å…¨ã€‘è´¨æŠ¼æ¯”ä¾‹è¾ƒä½ï¼Œæ— æ˜æ˜¾é£é™©"

        result.append(f"**å½“å‰è´¨æŠ¼æ¯”ä¾‹**: {latest_ratio:.2f}%")
        result.append(f"**é£é™©è¯„ä¼°**: {risk_level}")
        result.append("")

        return "\n".join(result)

    except Exception as e:
        return f"è·å–è‚¡æƒè´¨æŠ¼æ•°æ®å¤±è´¥: {str(e)}"


def get_share_float(stock_code: str) -> str:
    """
    è·å–é™å”®è§£ç¦æ—¥å†ï¼ˆç²¾ç®€ç‰ˆï¼Œåªè¿”å›æ±‡æ€»å’Œå‰20å¤§è‚¡ä¸œï¼‰

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 

    Returns:
        æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼ŒåŒ…å«è§£ç¦æ±‡æ€»ç»Ÿè®¡å’Œå‰20å¤§è‚¡ä¸œæ˜ç»†
    """
    try:
        pro = get_pro_api()
        ts_code = convert_stock_code(stock_code)

        df = pro.share_float(ts_code=ts_code)

        if df.empty:
            return f"æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„è§£ç¦æ•°æ®"

        # ç­›é€‰æœªæ¥6ä¸ªæœˆçš„è§£ç¦
        today = datetime.now().strftime('%Y%m%d')
        future_date = (datetime.now() + timedelta(days=180)).strftime('%Y%m%d')

        # è¿‡æ»¤æœªæ¥è§£ç¦
        df_future = df[(df['float_date'] >= today) & (df['float_date'] <= future_date)].copy()

        result = []
        result.append("# é™å”®è§£ç¦æ—¥å†\n")

        if df_future.empty:
            result.append("## æœªæ¥6ä¸ªæœˆæ— é‡å¤§è§£ç¦\n")
            result.append("è¯¥è‚¡ç¥¨æœªæ¥6ä¸ªæœˆå†…æš‚æ— é™å”®è‚¡è§£ç¦å®‰æ’ã€‚\n")
        else:
            # è®¡ç®—æ±‡æ€»ç»Ÿè®¡
            df_future['float_share_wan'] = df_future['float_share'].fillna(0) / 10000
            total_float = df_future['float_share_wan'].sum()
            total_ratio = df_future['float_ratio'].fillna(0).sum()
            total_holders = len(df_future)

            # æŒ‰è§£ç¦æ—¥æœŸåˆ†ç»„ç»Ÿè®¡
            date_summary = df_future.groupby('float_date').agg({
                'float_share_wan': 'sum',
                'float_ratio': 'sum'
            }).reset_index()

            result.append("## è§£ç¦æ±‡æ€»ç»Ÿè®¡\n")
            result.append(f"- **æœªæ¥6ä¸ªæœˆç´¯è®¡è§£ç¦**: {total_float:.2f}ä¸‡è‚¡")
            result.append(f"- **å æ€»è‚¡æœ¬æ¯”ä¾‹**: {total_ratio:.2f}%")
            result.append(f"- **è§£ç¦è‚¡ä¸œæ•°é‡**: {total_holders}ä¸ª")
            result.append("")

            # æŒ‰æ—¥æœŸæ±‡æ€»ï¼ˆæœ€å¤šæ˜¾ç¤º5ä¸ªæ—¥æœŸï¼‰
            result.append("## è§£ç¦æ—¥æœŸåˆ†å¸ƒ\n")
            result.append("| è§£ç¦æ—¥æœŸ | è§£ç¦æ•°é‡(ä¸‡è‚¡) | å æ€»è‚¡æœ¬(%) |")
            result.append("|---------|--------------|------------|")
            for _, row in date_summary.head(5).iterrows():
                result.append(f"| {row['float_date']} | {row['float_share_wan']:.2f} | {row['float_ratio']:.2f} |")
            if len(date_summary) > 5:
                result.append(f"| ... | å…±{len(date_summary)}ä¸ªè§£ç¦æ—¥æœŸ | ... |")
            result.append("")

            # åªæ˜¾ç¤ºå‰20å¤§è‚¡ä¸œï¼ˆæŒ‰è§£ç¦æ•°é‡é™åºï¼‰
            df_top20 = df_future.nlargest(20, 'float_share_wan')

            result.append("## å‰20å¤§è§£ç¦è‚¡ä¸œ\n")
            result.append("| è§£ç¦æ—¥æœŸ | è§£ç¦æ•°é‡(ä¸‡è‚¡) | å æ€»è‚¡æœ¬(%) | è‚¡ä¸œåç§° | è§£ç¦ç±»å‹ |")
            result.append("|---------|--------------|------------|---------|---------|")

            for _, row in df_top20.iterrows():
                float_date = row.get('float_date', 'N/A')
                float_share = row['float_share_wan']
                float_ratio = row.get('float_ratio', 0) if pd.notna(row.get('float_ratio')) else 0
                holder_name = row.get('holder_name', 'N/A')[:20] if row.get('holder_name') else 'N/A'
                share_type = row.get('share_type', 'N/A')

                result.append(f"| {float_date} | {float_share:.2f} | {float_ratio:.2f} | {holder_name} | {share_type} |")

            if total_holders > 20:
                result.append(f"\n*æ³¨ï¼šå…±{total_holders}ä¸ªè‚¡ä¸œï¼Œä»…æ˜¾ç¤ºå‰20å¤§*")

            result.append("")

            # é£é™©æç¤º
            if total_float > 10000:  # è¶…è¿‡1äº¿è‚¡
                result.append("**é£é™©æç¤º**: è§£ç¦è§„æ¨¡è¾ƒå¤§ï¼Œå¯èƒ½å¯¹è‚¡ä»·å½¢æˆå‹åŠ›")
            elif total_ratio > 10:  # å æ¯”è¶…è¿‡10%
                result.append("**é£é™©æç¤º**: è§£ç¦å æ¯”è¾ƒé«˜ï¼Œå…³æ³¨å‡æŒå…¬å‘Š")

        result.append("")

        # æ˜¾ç¤ºå†å²è§£ç¦æƒ…å†µï¼ˆæœ€å¤š5æ¡ï¼‰
        df_past = df[df['float_date'] < today].head(5)
        if not df_past.empty:
            result.append("## è¿‘æœŸå·²è§£ç¦è®°å½•\n")
            result.append("| è§£ç¦æ—¥æœŸ | è§£ç¦æ•°é‡(ä¸‡è‚¡) | å æ€»è‚¡æœ¬(%) |")
            result.append("|---------|--------------|------------|")
            for _, row in df_past.iterrows():
                float_date = row.get('float_date', 'N/A')
                float_share = row.get('float_share', 0) / 10000 if pd.notna(row.get('float_share')) else 0
                float_ratio = row.get('float_ratio', 0) if pd.notna(row.get('float_ratio')) else 0
                result.append(f"| {float_date} | {float_share:.2f} | {float_ratio:.2f} |")
            result.append("")

        return "\n".join(result)

    except Exception as e:
        return f"è·å–è§£ç¦æ•°æ®å¤±è´¥: {str(e)}"


def get_index_daily(index_code: str, days: int = 60) -> str:
    """
    è·å–æŒ‡æ•°æ—¥çº¿è¡Œæƒ…

    Args:
        index_code: æŒ‡æ•°ä»£ç ï¼ˆå¦‚ 000300.SH æ²ªæ·±300, 399006.SZ åˆ›ä¸šæ¿æŒ‡, 399318.SZ æœ‰è‰²é‡‘å±ï¼‰
        days: è·å–å¤©æ•°

    Returns:
        æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼ŒåŒ…å«æŒ‡æ•°æ”¶ç›˜ä»·ã€æ¶¨è·Œå¹…ã€æˆäº¤é¢
    """
    try:
        pro = get_pro_api()

        end_date = datetime.now().strftime('%Y%m%d')
        start_date = (datetime.now() - timedelta(days=days * 2)).strftime('%Y%m%d')

        df = pro.index_daily(ts_code=index_code, start_date=start_date, end_date=end_date)

        if df.empty:
            return f"æœªæ‰¾åˆ°æŒ‡æ•° {index_code} çš„è¡Œæƒ…æ•°æ®"

        df = df.head(days)

        # è·å–æŒ‡æ•°åç§°
        index_name_map = {
            '000300.SH': 'æ²ªæ·±300',
            '399006.SZ': 'åˆ›ä¸šæ¿æŒ‡',
            '399318.SZ': 'å›½è¯æœ‰è‰²',
            '000016.SH': 'ä¸Šè¯50',
            '399001.SZ': 'æ·±è¯æˆæŒ‡',
            '000001.SH': 'ä¸Šè¯æŒ‡æ•°',
        }
        index_name = index_name_map.get(index_code, index_code)

        result = []
        result.append(f"# {index_name}({index_code}) è¡Œæƒ…åˆ†æ\n")
        result.append(f"## è¿‘æœŸèµ°åŠ¿ï¼ˆæœ€è¿‘{min(len(df), 20)}ä¸ªäº¤æ˜“æ—¥ï¼‰\n")
        result.append("| æ—¥æœŸ | æ”¶ç›˜ | æ¶¨è·Œå¹…(%) | æˆäº¤é¢(äº¿) | æŒ¯å¹…(%) |")
        result.append("|------|------|----------|----------|--------|")

        for _, row in df.head(20).iterrows():
            trade_date = row.get('trade_date', 'N/A')
            close = row.get('close', 0)
            pct_chg = row.get('pct_chg', 0) if pd.notna(row.get('pct_chg')) else 0
            amount = row.get('amount', 0) / 100000 if pd.notna(row.get('amount')) else 0  # åƒå…ƒè½¬äº¿å…ƒ

            # è®¡ç®—æŒ¯å¹…
            high = row.get('high', 0)
            low = row.get('low', 0)
            pre_close = row.get('pre_close', close)
            amplitude = (high - low) / pre_close * 100 if pre_close > 0 else 0

            result.append(f"| {trade_date} | {close:.2f} | {pct_chg:+.2f} | {amount:.2f} | {amplitude:.2f} |")

        result.append("")

        # è®¡ç®—ç»Ÿè®¡æŒ‡æ ‡
        latest_close = df.iloc[0]['close']
        oldest_close = df.iloc[-1]['close']
        period_return = (latest_close - oldest_close) / oldest_close * 100

        result.append(f"**åŒºé—´æ¶¨è·Œå¹…**: {period_return:+.2f}%ï¼ˆè¿‘{len(df)}ä¸ªäº¤æ˜“æ—¥ï¼‰")
        result.append(f"**æœ€æ–°æ”¶ç›˜**: {latest_close:.2f}")

        # å‡å€¼åˆ†æ
        avg_amount = df['amount'].mean() / 100000
        result.append(f"**æ—¥å‡æˆäº¤é¢**: {avg_amount:.2f}äº¿å…ƒ")
        result.append("")

        return "\n".join(result)

    except Exception as e:
        return f"è·å–æŒ‡æ•°è¡Œæƒ…æ•°æ®å¤±è´¥: {str(e)}"


def get_sector_benchmark_data(stock_code: str, days: int = 60) -> str:
    """
    æ™ºèƒ½è·å–ä¸ªè‚¡æ‰€å±è¡Œä¸šçš„æ¿å—æŒ‡æ•°æ•°æ®ã€‚
    åªéœ€ä¼ å…¥ä¸ªè‚¡ä»£ç ï¼Œè‡ªåŠ¨æŸ¥æ‰¾å…¶è¡Œä¸šå¹¶è¿”å›å¯¹åº”è¡Œä¸šæŒ‡æ•°èµ°åŠ¿ã€‚

    è¿™æ˜¯ä¸€ä¸ª"å‚»ç“œåŒ–"å·¥å…·ï¼ŒAgentåªéœ€è¦ä¼ å…¥è‚¡ç¥¨ä»£ç ï¼ŒPythonå†…éƒ¨ä¼šè‡ªåŠ¨ï¼š
    1. æŸ¥è¯¢è‚¡ç¥¨æ‰€å±è¡Œä¸š
    2. æ˜ å°„åˆ°å¯¹åº”çš„è¡Œä¸šæŒ‡æ•°ï¼ˆé‡‡ç”¨ä¸‰çº§fallbackç­–ç•¥ï¼‰
    3. è·å–æŒ‡æ•°æ•°æ®å¹¶è¿”å›

    ä¸‰çº§ fallback ç­–ç•¥ï¼š
    - Level 1: è¡Œä¸šæ˜ å°„ï¼ˆæ ¹æ®è¡Œä¸šåç§°åŒ¹é…å¯¹åº”è¡Œä¸šæŒ‡æ•°ï¼‰
    - Level 2: å¸‚åœºæ¿å—ï¼ˆç§‘åˆ›æ¿â†’ç§‘åˆ›50ï¼Œåˆ›ä¸šæ¿â†’åˆ›ä¸šæ¿æŒ‡ï¼‰
    - Level 3: é»˜è®¤å…œåº•ï¼ˆæ²ªæ·±300ï¼‰

    Args:
        stock_code: è‚¡ç¥¨ä»£ç ï¼Œå¦‚ "601899", "000001", "300750"
        days: è·å–å¤©æ•°ï¼Œé»˜è®¤60å¤©

    Returns:
        åŒ…å«è¡Œä¸šåç§°ã€æŒ‡æ•°ä»£ç ã€æŒ‡æ•°èµ°åŠ¿ã€ç›¸å¯¹å¼ºå¼±åˆ†æçš„å®Œæ•´æŠ¥å‘Š
    """
    try:
        pro = get_pro_api()
        ts_code = convert_stock_code(stock_code)

        # 1. è·å–ä¸ªè‚¡è¡Œä¸š + å¸‚åœºæ¿å—
        df_basic = pro.stock_basic(ts_code=ts_code, fields='ts_code,name,industry,market')
        if df_basic.empty:
            return f"[not_found] æ— æ³•è·å–è‚¡ç¥¨ {stock_code} çš„è¡Œä¸šä¿¡æ¯"

        stock_name = df_basic.iloc[0]['name']
        industry_name = df_basic.iloc[0]['industry']
        market = df_basic.iloc[0].get('market', '')  # å¸‚åœºæ¿å—å­—æ®µ

        # 2. ä¸‰çº§ fallback ç­–ç•¥
        mapping = None
        fallback_source = "è¡Œä¸šåŒ¹é…"

        # 2.1 å…ˆå°è¯•è¡Œä¸šæ˜ å°„
        if industry_name in INDUSTRY_TO_INDEX:
            mapping = INDUSTRY_TO_INDEX[industry_name]
        else:
            # 2.2 è¡Œä¸šæ— åŒ¹é…ï¼Œæ ¹æ®å¸‚åœºæ¿å—é€‰æ‹©
            fallback_source = "å¸‚åœºæ¿å—"
            if market == "ç§‘åˆ›æ¿" or ts_code.startswith("688"):
                mapping = {"index": "000688.SH", "index_name": "ç§‘åˆ›50", "futures": None}
            elif market == "åˆ›ä¸šæ¿" or ts_code.startswith("300") or ts_code.startswith("301"):
                mapping = {"index": "399006.SZ", "index_name": "åˆ›ä¸šæ¿æŒ‡", "futures": None}
            else:
                # 2.3 é»˜è®¤ fallback
                mapping = INDUSTRY_TO_INDEX["_default"]
                fallback_source = "é»˜è®¤å…œåº•"

        index_code = mapping["index"]
        index_name = mapping["index_name"]
        futures_codes = mapping.get("futures")

        # 3. è·å–æŒ‡æ•°æ•°æ®
        index_data = get_index_daily(index_code, days=days)

        # 4. è·å–ä¸ªè‚¡æ•°æ®ç”¨äºç›¸å¯¹å¼ºå¼±å¯¹æ¯”
        end_date = datetime.now().strftime('%Y%m%d')
        start_date = (datetime.now() - timedelta(days=days * 2)).strftime('%Y%m%d')

        df_stock = pro.daily(ts_code=ts_code, start_date=start_date, end_date=end_date)

        relative_strength = ""
        if not df_stock.empty and len(df_stock) >= 2:
            df_stock = df_stock.head(days)
            stock_latest = df_stock.iloc[0]['close']
            stock_oldest = df_stock.iloc[-1]['close']
            stock_return = (stock_latest - stock_oldest) / stock_oldest * 100

            # è·å–æŒ‡æ•°åŒæœŸæ¶¨å¹…
            df_index = pro.index_daily(ts_code=index_code, start_date=start_date, end_date=end_date)
            if not df_index.empty and len(df_index) >= 2:
                df_index = df_index.head(days)
                index_latest = df_index.iloc[0]['close']
                index_oldest = df_index.iloc[-1]['close']
                index_return = (index_latest - index_oldest) / index_oldest * 100

                relative = stock_return - index_return
                strength_text = "å¼ºåŠ¿ï¼ˆè·‘èµ¢æ¿å—ï¼‰" if relative > 0 else "å¼±åŠ¿ï¼ˆè·‘è¾“æ¿å—ï¼‰"

                relative_strength = f"""
## ç›¸å¯¹å¼ºå¼±åˆ†æ

| æŒ‡æ ‡ | ä¸ªè‚¡ | æ¿å— | å·®å€¼ |
|------|------|------|------|
| åŒºé—´æ¶¨å¹… | {stock_return:+.2f}% | {index_return:+.2f}% | {relative:+.2f}% |
| åˆ¤æ–­ | - | - | **{strength_text}** |
"""

        # 5. å‘¨æœŸè¡Œä¸šæç¤º
        cyclic_hint = ""
        if is_cyclic_industry(industry_name):
            futures_str = ", ".join(futures_codes) if futures_codes else "æ— "
            cyclic_hint = f"""
## å‘¨æœŸè¡Œä¸šæç¤º

è¯¥è‚¡å±äº**å‘¨æœŸèµ„æºè¡Œä¸š**ï¼Œå»ºè®®åŒæ—¶åˆ†æå•†å“æœŸè´§èµ°åŠ¿ï¼š
- ç›¸å…³æœŸè´§ä»£ç : {futures_str}
- è¯·è°ƒç”¨ `get_tushare_fut_daily` è·å–æœŸè´§æ•°æ®è¿›è¡Œè”åŠ¨åˆ†æ
"""

        # 6. æ ¼å¼åŒ–è¾“å‡º
        result = f"""
# {stock_name}({ts_code}) æ¿å—å¯¹æ¯”åˆ†æ

- **æ‰€å±è¡Œä¸š**: {industry_name}
- **å¯¹æ ‡æŒ‡æ•°**: {index_name}({index_code})
- **åŒ¹é…æ–¹å¼**: {fallback_source}
- **å‘¨æœŸå±æ€§**: {"æ˜¯ï¼ˆéœ€è¦æœŸè´§è”åŠ¨åˆ†æï¼‰" if is_cyclic_industry(industry_name) else "å¦"}

{index_data}
{relative_strength}
{cyclic_hint}
"""
        return result

    except Exception as e:
        logger.error(f"è·å–æ¿å—æ•°æ®å¤±è´¥ [{stock_code}]: {e}")
        return f"[error] è·å–æ¿å—æ•°æ®å¤±è´¥: {str(e)}"


def get_index_member(index_code: str = "399318.SZ") -> str:
    """
    è·å–æŒ‡æ•°æˆåˆ†è‚¡

    Args:
        index_code: æŒ‡æ•°ä»£ç ï¼Œé»˜è®¤ä¸ºæœ‰è‰²é‡‘å±æŒ‡æ•° 399318.SZ

    Returns:
        æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼ŒåŒ…å«æˆåˆ†è‚¡åˆ—è¡¨
    """
    try:
        pro = get_pro_api()

        index_name_map = {
            '399318.SZ': 'å›½è¯æœ‰è‰²',
            '000300.SH': 'æ²ªæ·±300',
            '399006.SZ': 'åˆ›ä¸šæ¿æŒ‡',
            '000016.SH': 'ä¸Šè¯50',
            '000905.SH': 'ä¸­è¯500',
            '399001.SZ': 'æ·±è¯æˆæŒ‡',
            '000001.SH': 'ä¸Šè¯æŒ‡æ•°',
            '399673.SZ': 'åˆ›ä¸šæ¿50',
            '000688.SH': 'ç§‘åˆ›50',
        }
        index_name = index_name_map.get(index_code, index_code)

        end_date = datetime.now().strftime('%Y%m%d')
        start_date = (datetime.now() - timedelta(days=60)).strftime('%Y%m%d')

        df = pd.DataFrame()

        # æ–¹æ³•1: ä½¿ç”¨ index_member APIï¼ˆä¸»æµæŒ‡æ•°ï¼‰
        try:
            df = pro.index_member(index_code=index_code)
        except:
            pass

        # æ–¹æ³•2: å¦‚æœä¸ºç©ºï¼Œå°è¯•ä½¿ç”¨ index_weight APIï¼ˆè·å–æƒé‡æ•°æ®ï¼‰
        if df.empty:
            try:
                df_weight = pro.index_weight(index_code=index_code, start_date=start_date, end_date=end_date)
                if not df_weight.empty:
                    # è·å–æœ€æ–°æ—¥æœŸçš„æƒé‡æ•°æ®
                    latest_date = df_weight['trade_date'].max()
                    df_latest = df_weight[df_weight['trade_date'] == latest_date].copy()

                    result = []
                    result.append(f"# {index_name}({index_code}) æˆåˆ†è‚¡æƒé‡\n")
                    result.append(f"## æœ€æ–°æˆåˆ†è‚¡åˆ—è¡¨ï¼ˆ{latest_date}ï¼Œå…±{len(df_latest)}åªï¼‰\n")
                    result.append("| ä»£ç  | æƒé‡(%) |")
                    result.append("|------|--------|")

                    df_latest = df_latest.sort_values('weight', ascending=False)
                    for _, row in df_latest.head(30).iterrows():
                        con_code = row.get('con_code', 'N/A')
                        weight = row.get('weight', 0)
                        result.append(f"| {con_code} | {weight:.2f} |")

                    if len(df_latest) > 30:
                        result.append(f"\n*æ³¨ï¼šä»…æ˜¾ç¤ºæƒé‡å‰30åªæˆåˆ†è‚¡ï¼Œå…±{len(df_latest)}åª*")

                    result.append("")
                    return "\n".join(result)
            except:
                pass

        # æ–¹æ³•3: å¯¹äºå›½è¯ç³»åˆ—æŒ‡æ•°ï¼Œå°è¯•ä½¿ç”¨ ths_memberï¼ˆåŒèŠ±é¡ºæ¦‚å¿µæ¿å—ï¼‰
        if df.empty and index_code.startswith('399'):
            try:
                # å°è¯•è·å–åŒèŠ±é¡ºè¡Œä¸šæˆåˆ†
                df_ths = pro.ths_member(ts_code=index_code)
                if not df_ths.empty:
                    result = []
                    result.append(f"# {index_name}({index_code}) æˆåˆ†è‚¡\n")
                    result.append(f"## åŒèŠ±é¡ºæ¿å—æˆåˆ†ï¼ˆå…±{len(df_ths)}åªï¼‰\n")
                    result.append("| ä»£ç  | åç§° |")
                    result.append("|------|------|")

                    for _, row in df_ths.head(30).iterrows():
                        code = row.get('code', 'N/A')
                        name = row.get('name', 'N/A')
                        result.append(f"| {code} | {name} |")

                    if len(df_ths) > 30:
                        result.append(f"\n*æ³¨ï¼šä»…æ˜¾ç¤ºå‰30åªæˆåˆ†è‚¡ï¼Œå…±{len(df_ths)}åª*")
                    result.append("")
                    return "\n".join(result)
            except:
                pass

        # æ–¹æ³•4: å¯¹äºç‰¹å®šè¡Œä¸šæŒ‡æ•°ï¼Œè¿”å›è¡Œä¸šè¯´æ˜
        if df.empty:
            # å›½è¯ç³»åˆ—è¡Œä¸šæŒ‡æ•°å¯èƒ½æ²¡æœ‰æˆåˆ†è‚¡APIï¼Œè¿”å›è¯´æ˜ä¿¡æ¯
            industry_indices = {
                '399318.SZ': 'æœ‰è‰²é‡‘å±',
                '399395.SZ': 'å›½è¯é“¶è¡Œ',
                '399396.SZ': 'å›½è¯é£Ÿå“',
                '399441.SZ': 'å›½è¯ç”Ÿç§‘',
            }
            if index_code in industry_indices:
                industry = industry_indices[index_code]
                return (f"# {index_name}({index_code})\n\n"
                        f"è¯¥æŒ‡æ•°ä¸ºå›½è¯ç³»åˆ—{industry}è¡Œä¸šæŒ‡æ•°ï¼ŒTuShareæš‚æœªæä¾›æˆåˆ†è‚¡æ˜ç»†æ•°æ®ã€‚\n\n"
                        f"**å»ºè®®**: ä½¿ç”¨ get_index_daily API è·å–æŒ‡æ•°è¡Œæƒ…èµ°åŠ¿ï¼Œä¸ä¸ªè‚¡è¿›è¡Œè”åŠ¨åˆ†æã€‚\n\n"
                        f"*æç¤º: å¯é€šè¿‡å›½è¯æŒ‡æ•°å®˜ç½‘æŸ¥è¯¢å®Œæ•´æˆåˆ†è‚¡åˆ—è¡¨*")

            return f"æœªæ‰¾åˆ°æŒ‡æ•° {index_code} çš„æˆåˆ†è‚¡æ•°æ®ï¼ˆè¯¥æŒ‡æ•°å¯èƒ½ä¸åœ¨TuShareæ•°æ®è¦†ç›–èŒƒå›´å†…ï¼Œå»ºè®®ä½¿ç”¨æ²ªæ·±300/ä¸Šè¯50ç­‰ä¸»æµæŒ‡æ•°ï¼‰"

        # è¿‡æ»¤å½“å‰æœ‰æ•ˆçš„æˆåˆ†è‚¡ï¼ˆout_dateä¸ºç©ºæˆ–å¤§äºä»Šå¤©ï¼‰
        today = datetime.now().strftime('%Y%m%d')
        df_valid = df[(df['out_date'].isna()) | (df['out_date'] > today)]

        result = []
        result.append(f"# {index_name}({index_code}) æˆåˆ†è‚¡\n")
        result.append(f"## å½“å‰æˆåˆ†è‚¡åˆ—è¡¨ï¼ˆå…±{len(df_valid)}åªï¼‰\n")
        result.append("| ä»£ç  | åç§° | çº³å…¥æ—¥æœŸ |")
        result.append("|------|------|---------|")

        for _, row in df_valid.head(30).iterrows():  # æœ€å¤šæ˜¾ç¤º30åª
            con_code = row.get('con_code', 'N/A')
            con_name = row.get('con_name', 'N/A')
            in_date = row.get('in_date', 'N/A')
            result.append(f"| {con_code} | {con_name} | {in_date} |")

        if len(df_valid) > 30:
            result.append(f"\n*æ³¨ï¼šä»…æ˜¾ç¤ºå‰30åªæˆåˆ†è‚¡ï¼Œå…±{len(df_valid)}åª*")

        result.append("")
        return "\n".join(result)

    except Exception as e:
        return f"è·å–æŒ‡æ•°æˆåˆ†è‚¡æ•°æ®å¤±è´¥: {str(e)}"


def get_stk_surv(stock_code: str) -> str:
    """
    è·å–æœºæ„è°ƒç ”æ•°æ®

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 

    Returns:
        æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼ŒåŒ…å«è¿‘æœŸè°ƒç ”è®°å½•
    """
    try:
        pro = get_pro_api()
        ts_code = convert_stock_code(stock_code)

        # è·å–æœ€è¿‘6ä¸ªæœˆçš„è°ƒç ”æ•°æ®
        end_date = datetime.now().strftime('%Y%m%d')
        start_date = (datetime.now() - timedelta(days=180)).strftime('%Y%m%d')

        df = pro.stk_surv(ts_code=ts_code, start_date=start_date, end_date=end_date)

        if df.empty:
            return f"è‚¡ç¥¨ {stock_code} è¿‘6ä¸ªæœˆæ— æœºæ„è°ƒç ”è®°å½•"

        # æ³¨æ„ï¼šstk_surv API æ¯è¡Œè¿”å›ä¸€å®¶æœºæ„çš„è°ƒç ”è®°å½•
        # å­—æ®µï¼šsurv_date(è°ƒç ”æ—¥æœŸ), rece_org(æ¥å¾…æœºæ„), org_type(æœºæ„ç±»å‹), rece_mode(æ¥å¾…æ–¹å¼)
        # éœ€è¦æŒ‰æ—¥æœŸåˆ†ç»„ç»Ÿè®¡

        result = []
        result.append("# æœºæ„è°ƒç ”åˆ†æ\n")
        result.append(f"## è¿‘æœŸæœºæ„è°ƒç ”è®°å½•ï¼ˆ{stock_code}ï¼‰\n")

        # æŒ‰æ—¥æœŸåˆ†ç»„ç»Ÿè®¡
        date_stats = {}
        org_type_stats = {}

        for _, row in df.iterrows():
            surv_date = row.get('surv_date', 'N/A')
            org_type = row.get('org_type', 'å…¶ä»–')
            rece_mode = row.get('rece_mode', 'N/A')
            rece_org = row.get('rece_org', 'N/A')

            # æŒ‰æ—¥æœŸç»Ÿè®¡
            if surv_date not in date_stats:
                date_stats[surv_date] = {'count': 0, 'modes': set(), 'orgs': []}
            date_stats[surv_date]['count'] += 1
            if rece_mode and rece_mode != 'N/A':
                date_stats[surv_date]['modes'].add(rece_mode.split(',')[0])  # å–ç¬¬ä¸€ä¸ªæ¨¡å¼
            date_stats[surv_date]['orgs'].append(rece_org)

            # æŒ‰æœºæ„ç±»å‹ç»Ÿè®¡
            if org_type:
                org_type_stats[org_type] = org_type_stats.get(org_type, 0) + 1

        # è¾“å‡ºæŒ‰æ—¥æœŸçš„è°ƒç ”æ±‡æ€»ï¼ˆæœ€è¿‘10ä¸ªæ—¥æœŸï¼‰
        result.append("| è°ƒç ”æ—¥æœŸ | æœºæ„æ•°é‡ | è°ƒç ”å½¢å¼ | å‚ä¸æœºæ„ï¼ˆéƒ¨åˆ†ï¼‰ |")
        result.append("|---------|---------|---------|----------------|")

        sorted_dates = sorted(date_stats.keys(), reverse=True)[:10]
        for date in sorted_dates:
            stats = date_stats[date]
            modes = '/'.join(list(stats['modes'])[:2]) if stats['modes'] else 'N/A'
            orgs_preview = ', '.join(stats['orgs'][:3])
            if len(stats['orgs']) > 3:
                orgs_preview += f" ç­‰{len(stats['orgs'])}å®¶"
            result.append(f"| {date} | {stats['count']} | {modes} | {orgs_preview} |")

        result.append("")

        # æœºæ„ç±»å‹åˆ†å¸ƒ
        result.append("### æœºæ„ç±»å‹åˆ†å¸ƒ")
        result.append("| æœºæ„ç±»å‹ | å‚ä¸æ¬¡æ•° |")
        result.append("|---------|---------|")
        for org_type, count in sorted(org_type_stats.items(), key=lambda x: x[1], reverse=True):
            result.append(f"| {org_type} | {count} |")

        result.append("")
        total_records = len(df)
        unique_dates = len(date_stats)
        result.append(f"**è°ƒç ”ç»Ÿè®¡**: è¿‘6ä¸ªæœˆå…±{unique_dates}æ¬¡è°ƒç ”æ´»åŠ¨ï¼Œç´¯è®¡{total_records}å®¶æœºæ„å‚ä¸")

        # åˆ†æ
        if unique_dates >= 5:
            result.append("")
            result.append("**è°ƒç ”å¯†åº¦åˆ†æ**: è°ƒç ”é¢‘ç¹ï¼Œæœºæ„å…³æ³¨åº¦è¾ƒé«˜")
        elif unique_dates >= 2:
            result.append("")
            result.append("**è°ƒç ”å¯†åº¦åˆ†æ**: è°ƒç ”æ´»åŠ¨æ­£å¸¸ï¼Œæœºæ„ä¿æŒå…³æ³¨")

        result.append("")
        return "\n".join(result)

    except Exception as e:
        return f"è·å–æœºæ„è°ƒç ”æ•°æ®å¤±è´¥: {str(e)}"


def get_report_rc(stock_code: str, days: int = 30) -> str:
    """
    è·å–åˆ¸å•†ç ”æŠ¥æ•°æ®

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        days: è·å–å¤©æ•°

    Returns:
        æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼ŒåŒ…å«è¿‘æœŸç ”æŠ¥æ ‡é¢˜ã€è¯„çº§ã€ç›®æ ‡ä»·
    """
    try:
        pro = get_pro_api()
        ts_code = convert_stock_code(stock_code)

        end_date = datetime.now().strftime('%Y%m%d')
        start_date = (datetime.now() - timedelta(days=days * 2)).strftime('%Y%m%d')

        df = pro.report_rc(ts_code=ts_code, start_date=start_date, end_date=end_date)

        if df.empty:
            return f"è‚¡ç¥¨ {stock_code} è¿‘æœŸæ— åˆ¸å•†ç ”æŠ¥"

        df = df.head(15)  # æœ€è¿‘15ç¯‡

        result = []
        result.append("# åˆ¸å•†ç ”æŠ¥åˆ†æ\n")
        result.append(f"## è¿‘æœŸåˆ¸å•†ç ”æŠ¥ï¼ˆ{stock_code}ï¼‰\n")
        result.append("| æ—¥æœŸ | æœºæ„ | è¯„çº§ | ç›®æ ‡ä»· | ç ”æŠ¥æ ‡é¢˜ |")
        result.append("|------|------|------|--------|---------|")

        rating_count = {'ä¹°å…¥': 0, 'å¢æŒ': 0, 'æŒæœ‰': 0, 'å‡æŒ': 0, 'å–å‡º': 0, 'å…¶ä»–': 0}
        target_prices = []

        for _, row in df.iterrows():
            report_date = row.get('report_date', 'N/A')
            organ_name = row.get('organ_name', 'N/A')[:8] if row.get('organ_name') else 'N/A'
            rating = row.get('rating', 'N/A')
            target_price = row.get('target_price', None)
            title = row.get('report_title', 'N/A')[:25] if row.get('report_title') else 'N/A'

            # ç»Ÿè®¡è¯„çº§
            if rating in rating_count:
                rating_count[rating] += 1
            else:
                rating_count['å…¶ä»–'] += 1

            # æ”¶é›†ç›®æ ‡ä»·
            if target_price and pd.notna(target_price) and target_price > 0:
                target_prices.append(target_price)

            tp_str = f"{target_price:.2f}" if target_price and pd.notna(target_price) and target_price > 0 else "-"
            result.append(f"| {report_date} | {organ_name} | {rating} | {tp_str} | {title} |")

        result.append("")

        # è¯„çº§ç»Ÿè®¡
        result.append("## è¯„çº§ç»Ÿè®¡\n")
        result.append(f"- **ä¹°å…¥/å¢æŒ**: {rating_count['ä¹°å…¥'] + rating_count['å¢æŒ']}å®¶")
        result.append(f"- **æŒæœ‰**: {rating_count['æŒæœ‰']}å®¶")
        result.append(f"- **å‡æŒ/å–å‡º**: {rating_count['å‡æŒ'] + rating_count['å–å‡º']}å®¶")

        # ç›®æ ‡ä»·ç»Ÿè®¡
        if target_prices:
            avg_target = sum(target_prices) / len(target_prices)
            max_target = max(target_prices)
            min_target = min(target_prices)
            result.append("")
            result.append("## ç›®æ ‡ä»·ç»Ÿè®¡\n")
            result.append(f"- **å¹³å‡ç›®æ ‡ä»·**: {avg_target:.2f}å…ƒ")
            result.append(f"- **æœ€é«˜ç›®æ ‡ä»·**: {max_target:.2f}å…ƒ")
            result.append(f"- **æœ€ä½ç›®æ ‡ä»·**: {min_target:.2f}å…ƒ")

        result.append("")
        return "\n".join(result)

    except Exception as e:
        return f"è·å–åˆ¸å•†ç ”æŠ¥æ•°æ®å¤±è´¥: {str(e)}"


def get_fut_daily(fut_code: str, days: int = 60) -> str:
    """
    è·å–æœŸè´§æ—¥çº¿æ•°æ®ï¼ˆé“œ/é‡‘ä¸»åŠ›åˆçº¦ï¼‰

    Args:
        fut_code: æœŸè´§ä»£ç ï¼ˆå¦‚ CU.SHF æ²ªé“œ, AU.SHF æ²ªé‡‘ï¼‰
                  å¸¸ç”¨ä»£ç : CU=é“œ, AU=é»„é‡‘, AG=ç™½é“¶, AL=é“
        days: è·å–å¤©æ•°

    Returns:
        æ ¼å¼åŒ–å­—ç¬¦ä¸²ï¼ŒåŒ…å«æœŸè´§ä»·æ ¼èµ°åŠ¿
    """
    try:
        pro = get_pro_api()

        end_date = datetime.now().strftime('%Y%m%d')
        start_date = (datetime.now() - timedelta(days=days * 2)).strftime('%Y%m%d')

        # è·å–ä¸»åŠ›åˆçº¦æ˜ å°„
        # é¦–å…ˆå°è¯•è·å–ä¸»åŠ›åˆçº¦ä»£ç 
        df_mapping = pro.fut_mapping(ts_code=fut_code)
        if not df_mapping.empty:
            # ä½¿ç”¨ä¸»åŠ›åˆçº¦
            main_contract = df_mapping.iloc[0]['mapping_ts_code']
        else:
            main_contract = fut_code

        df = pro.fut_daily(ts_code=main_contract, start_date=start_date, end_date=end_date)

        if df.empty:
            return f"æœªæ‰¾åˆ°æœŸè´§ {fut_code} çš„è¡Œæƒ…æ•°æ®"

        df = df.head(days)

        # æœŸè´§åç§°æ˜ å°„
        fut_name_map = {
            'CU': 'æ²ªé“œ',
            'AU': 'æ²ªé‡‘',
            'AG': 'æ²ªé“¶',
            'AL': 'æ²ªé“',
            'ZN': 'æ²ªé”Œ',
            'PB': 'æ²ªé“…',
            'NI': 'æ²ªé•',
            'SN': 'æ²ªé”¡',
        }
        fut_prefix = fut_code.split('.')[0][:2] if '.' in fut_code else fut_code[:2]
        fut_name = fut_name_map.get(fut_prefix, fut_code)

        result = []
        result.append(f"# {fut_name} æœŸè´§è¡Œæƒ…åˆ†æ\n")
        result.append(f"## ä¸»åŠ›åˆçº¦èµ°åŠ¿ï¼ˆ{main_contract}ï¼‰\n")
        result.append("| æ—¥æœŸ | æ”¶ç›˜ä»· | ç»“ç®—ä»· | æ¶¨è·Œå¹…(%) | æˆäº¤é‡(æ‰‹) | æŒä»“é‡(æ‰‹) |")
        result.append("|------|--------|--------|----------|-----------|-----------|")

        for _, row in df.head(20).iterrows():
            trade_date = row.get('trade_date', 'N/A')
            close = row.get('close', 0)
            settle = row.get('settle', 0)
            # è®¡ç®—æ¶¨è·Œå¹…
            pre_settle = row.get('pre_settle', settle)
            pct_chg = (close - pre_settle) / pre_settle * 100 if pre_settle > 0 else 0
            vol = row.get('vol', 0)
            oi = row.get('oi', 0)

            result.append(f"| {trade_date} | {close:.0f} | {settle:.0f} | {pct_chg:+.2f} | {vol:.0f} | {oi:.0f} |")

        result.append("")

        # ç»Ÿè®¡åˆ†æ
        latest_close = df.iloc[0]['close']
        oldest_close = df.iloc[-1]['close']
        period_return = (latest_close - oldest_close) / oldest_close * 100

        result.append(f"**åŒºé—´æ¶¨è·Œå¹…**: {period_return:+.2f}%ï¼ˆè¿‘{len(df)}ä¸ªäº¤æ˜“æ—¥ï¼‰")
        result.append(f"**æœ€æ–°æ”¶ç›˜ä»·**: {latest_close:.0f}")

        # è¶‹åŠ¿åˆ¤æ–­
        if period_return > 5:
            trend = "æœŸè´§ä»·æ ¼ä¸Šæ¶¨è¶‹åŠ¿æ˜æ˜¾ï¼Œå¯¹ç›¸å…³è‚¡ç¥¨å½¢æˆåˆ©å¥½"
        elif period_return < -5:
            trend = "æœŸè´§ä»·æ ¼ä¸‹è·Œè¶‹åŠ¿ï¼Œå¯èƒ½å½±å“ç›¸å…³è‚¡ç¥¨ç›ˆåˆ©é¢„æœŸ"
        else:
            trend = "æœŸè´§ä»·æ ¼éœ‡è¡ï¼ŒçŸ­æœŸå½±å“æœ‰é™"

        result.append(f"**è¶‹åŠ¿åˆ¤æ–­**: {trend}")
        result.append("")

        return "\n".join(result)

    except Exception as e:
        return f"è·å–æœŸè´§è¡Œæƒ…æ•°æ®å¤±è´¥: {str(e)}"


# ============= æ‰©å±•ç»¼åˆæ•°æ®è·å–å‡½æ•° =============


def get_china_stock_capital_deep(stock_code: str) -> str:
    """
    è·å–æ·±åº¦èµ„é‡‘åˆ†ææ•°æ®ï¼ˆæ•´åˆå¤§å®—äº¤æ˜“ã€è‚¡æƒè´¨æŠ¼ã€è§£ç¦æ—¥å†ç­‰ï¼‰

    æ³¨ï¼šåŒ—å‘èµ„é‡‘æŒè‚¡æ˜ç»†(hk_hold)å·²ç§»é™¤ï¼Œæ¸¯äº¤æ‰€è‡ª2024å¹´8æœˆ20æ—¥èµ·ä»…æä¾›å­£åº¦æ•°æ®ã€‚
    å¤–èµ„æ€åº¦å¯é€šè¿‡å‰åå¤§è‚¡ä¸œä¸­"é¦™æ¸¯ä¸­å¤®ç»“ç®—"æŒè‚¡æ¯”ä¾‹å˜åŒ–æ¥åˆ¤æ–­ã€‚

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 

    Returns:
        æ·±åº¦èµ„é‡‘åˆ†ææ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    result = []

    # å¤§å®—äº¤æ˜“
    result.append(get_block_trade(stock_code))

    # è‚¡æƒè´¨æŠ¼
    result.append(get_pledge_stat(stock_code))

    # è§£ç¦æ—¥å†
    result.append(get_share_float(stock_code))

    return "\n".join(result)


def get_china_stock_institution(stock_code: str) -> str:
    """
    è·å–æœºæ„è§‚ç‚¹æ•°æ®ï¼ˆæ•´åˆè°ƒç ”ã€ç ”æŠ¥ï¼‰

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 

    Returns:
        æœºæ„è§‚ç‚¹æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    result = []

    # æœºæ„è°ƒç ”
    result.append(get_stk_surv(stock_code))

    # åˆ¸å•†ç ”æŠ¥
    result.append(get_report_rc(stock_code))

    return "\n".join(result)


# ==================== æ–°é—»æ•°æ®æ¥å£ ====================

def get_cctv_news(date: str = None) -> str:
    """
    è·å–æ–°é—»è”æ’­æ–‡å­—ç¨¿

    Args:
        date: æ—¥æœŸï¼Œæ ¼å¼ YYYYMMDDï¼Œé»˜è®¤ä»Šå¤©

    Returns:
        æ–°é—»è”æ’­å†…å®¹çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    try:
        pro = get_pro_api()
    except ValueError as e:
        return f"[æ•°æ®è·å–å¤±è´¥] {str(e)}"

    try:
        if date is None:
            date = datetime.now().strftime("%Y%m%d")

        df = pro.cctv_news(date=date)

        if df is None or df.empty:
            return f"[æ— æ•°æ®] {date} æ— æ–°é—»è”æ’­æ•°æ®"

        result = [f"# æ–°é—»è”æ’­ ({date})\n"]

        # ç­›é€‰ç»æµç›¸å…³æ–°é—»
        economic_keywords = ['ç»æµ', 'é‡‘è', 'è‚¡å¸‚', 'æŠ•èµ„', 'è´¸æ˜“', 'äº§ä¸š', 'åˆ¶é€ ', 'ç§‘æŠ€', 'æ”¹é©', 'å‘å±•', 'ä¼ä¸š']

        for idx, row in df.iterrows():
            title = row.get('title', '')
            content = row.get('content', '')

            # æ£€æŸ¥æ˜¯å¦ä¸ç»æµç›¸å…³
            is_economic = any(kw in title or kw in str(content)[:200] for kw in economic_keywords)

            if is_economic:
                result.append(f"## {title}\n")
                if content:
                    # æˆªæ–­è¿‡é•¿å†…å®¹
                    content_preview = content[:500] + '...' if len(str(content)) > 500 else content
                    result.append(f"{content_preview}\n")

        if len(result) == 1:
            result.append("ä»Šæ—¥æ— ç»æµç›¸å…³é‡ç‚¹æ–°é—»")

        return "\n".join(result)

    except Exception as e:
        return f"[æ•°æ®è·å–å¤±è´¥] è·å–æ–°é—»è”æ’­æ•°æ®å¤±è´¥: {str(e)}"


def get_major_news(start_date: str = None, end_date: str = None, src: str = None) -> str:
    """
    è·å–é‡å¤§æ–°é—»ï¼ˆéœ€è¦å•ç‹¬å¼€é€šæƒé™ï¼‰

    Args:
        start_date: å¼€å§‹æ—¥æœŸæ—¶é—´ï¼Œæ ¼å¼ 'YYYY-MM-DD HH:MM:SS'
        end_date: ç»“æŸæ—¥æœŸæ—¶é—´ï¼Œæ ¼å¼ 'YYYY-MM-DD HH:MM:SS'
        src: æ–°é—»æ¥æºï¼Œå¦‚ 'æ–°æµªè´¢ç»', 'åŒèŠ±é¡º'

    Returns:
        é‡å¤§æ–°é—»çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    try:
        pro = get_pro_api()
    except ValueError as e:
        return f"[æ•°æ®è·å–å¤±è´¥] {str(e)}"

    try:
        if end_date is None:
            end_date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        if start_date is None:
            # é»˜è®¤è·å–æœ€è¿‘24å°æ—¶çš„æ–°é—»
            start_date = (datetime.now() - timedelta(days=1)).strftime("%Y-%m-%d %H:%M:%S")

        params = {
            'start_date': start_date,
            'end_date': end_date,
        }
        if src:
            params['src'] = src

        df = pro.major_news(**params)

        if df is None or df.empty:
            return "[æ— æ•°æ®] æ— é‡å¤§æ–°é—»æ•°æ®ï¼ˆå¯èƒ½éœ€è¦å¼€é€šæƒé™ï¼‰"

        result = ["# é‡å¤§è´¢ç»æ–°é—»\n"]

        for idx, row in df.head(20).iterrows():
            title = row.get('title', '')
            pub_time = row.get('pub_time', '')
            source = row.get('src', '')
            content = row.get('content', '')

            result.append(f"**[{pub_time}] [{source}]** {title}")
            if content:
                content_preview = content[:300] + '...' if len(str(content)) > 300 else content
                result.append(f"  {content_preview}")
            result.append("")

        return "\n".join(result)

    except Exception as e:
        error_msg = str(e)
        if 'æƒé™' in error_msg or 'permission' in error_msg.lower():
            return "[æƒé™ä¸è¶³] é‡å¤§æ–°é—»æ¥å£éœ€è¦å•ç‹¬å¼€é€šæƒé™ï¼Œè¯·è”ç³» Tushare"
        return f"[æ•°æ®è·å–å¤±è´¥] è·å–é‡å¤§æ–°é—»å¤±è´¥: {error_msg}"


def get_china_market_news_tushare(date: str = None) -> str:
    """
    è·å–ä¸­å›½è´¢ç»å¸‚åœºæ–°é—»ï¼ˆTushare ç‰ˆæœ¬ï¼‰

    æ•´åˆæ–°é—»è”æ’­å’Œé‡å¤§æ–°é—»æ•°æ®

    Args:
        date: æ—¥æœŸï¼Œæ ¼å¼ YYYY-MM-DD æˆ– YYYYMMDD

    Returns:
        æ ¼å¼åŒ–çš„å¸‚åœºæ–°é—»å­—ç¬¦ä¸²
    """
    result_parts = ["# ä¸­å›½è´¢ç»å¸‚åœºæ–°é—» (Tushare)\n"]

    # æ ¼å¼åŒ–æ—¥æœŸ
    if date:
        date_clean = date.replace("-", "")
    else:
        date_clean = datetime.now().strftime("%Y%m%d")

    # 1. è·å–æ–°é—»è”æ’­
    cctv_result = get_cctv_news(date_clean)
    if "[æ•°æ®è·å–å¤±è´¥]" not in cctv_result and "[æ— æ•°æ®]" not in cctv_result:
        result_parts.append(cctv_result)
        result_parts.append("\n---\n")

    # 2. å°è¯•è·å–é‡å¤§æ–°é—»ï¼ˆå¯èƒ½æ²¡æœ‰æƒé™ï¼‰
    major_result = get_major_news()
    if "[æƒé™ä¸è¶³]" not in major_result and "[æ•°æ®è·å–å¤±è´¥]" not in major_result:
        result_parts.append(major_result)
    else:
        result_parts.append("## è´¢ç»å¿«è®¯\n")
        result_parts.append("é‡å¤§æ–°é—»æ¥å£æš‚ä¸å¯ç”¨ï¼Œè¯·å‚è€ƒæ–°é—»è”æ’­å†…å®¹æˆ–ä½¿ç”¨å…¶ä»–æ–°é—»æºã€‚\n")

    return "\n".join(result_parts)


# ============================================================================
# å…¨å¸‚åœºè¡Œæƒ…æ•°æ®ï¼ˆç”¨äºæ’è¡Œæ¦œï¼Œæ›¿ä»£æ…¢é€Ÿçš„ akshare APIï¼‰
# ============================================================================

import threading

# å…¨å¸‚åœºæ•°æ®ç¼“å­˜
_market_data_cache = None
_market_data_cache_time = None
_market_data_cache_lock = threading.Lock()
_MARKET_DATA_CACHE_TTL = 1800  # 30åˆ†é’Ÿç¼“å­˜


def get_all_stocks_daily(trade_date: str = None) -> pd.DataFrame:
    """
    è·å–å…¨å¸‚åœºæ—¥çº¿è¡Œæƒ…æ•°æ®ï¼ˆå¸¦ç¼“å­˜ï¼‰

    ä½¿ç”¨ tushare çš„ daily + daily_basic æ¥å£ï¼Œæ¯” akshare å¿«çº¦ 50 å€ã€‚

    Args:
        trade_date: äº¤æ˜“æ—¥æœŸ YYYYMMDDï¼Œé»˜è®¤æœ€è¿‘äº¤æ˜“æ—¥

    Returns:
        DataFrame åŒ…å«: ä»£ç , åç§°, æœ€æ–°ä»·, æ¶¨è·Œå¹…, æˆäº¤é¢, æ¢æ‰‹ç‡, å¸‚å€¼ç­‰
    """
    global _market_data_cache, _market_data_cache_time

    with _market_data_cache_lock:
        now = datetime.now()

        # æ£€æŸ¥ç¼“å­˜
        if _market_data_cache is not None and _market_data_cache_time is not None:
            age = (now - _market_data_cache_time).total_seconds()
            if age < _MARKET_DATA_CACHE_TTL:
                logger.debug(f"[tushare] ä½¿ç”¨ç¼“å­˜çš„å…¨å¸‚åœºæ•°æ® (age={age:.0f}s)")
                return _market_data_cache.copy()

        # è·å–æ–°æ•°æ®
        logger.info("[tushare] è·å–å…¨å¸‚åœºè¡Œæƒ…æ•°æ®...")
        start_time = datetime.now()

        try:
            pro = get_pro_api()

            # ç¡®å®šäº¤æ˜“æ—¥æœŸ
            if not trade_date:
                # ä½¿ç”¨æœ€è¿‘çš„äº¤æ˜“æ—¥
                today = datetime.now().strftime("%Y%m%d")
                yesterday = (datetime.now() - timedelta(days=1)).strftime("%Y%m%d")
                day_before = (datetime.now() - timedelta(days=2)).strftime("%Y%m%d")
                dates_to_try = [today, yesterday, day_before]
            else:
                dates_to_try = [trade_date]

            df_daily = None
            df_basic = None
            used_date = None

            for date in dates_to_try:
                try:
                    df_daily = pro.daily(trade_date=date)
                    if df_daily is not None and not df_daily.empty:
                        df_basic = pro.daily_basic(trade_date=date)
                        used_date = date
                        break
                except Exception:
                    continue

            if df_daily is None or df_daily.empty:
                logger.warning("[tushare] æ— æ³•è·å–æ—¥çº¿æ•°æ®")
                return pd.DataFrame()

            # è·å–è‚¡ç¥¨åç§°
            df_names = pro.stock_basic(
                exchange='',
                list_status='L',
                fields='ts_code,name'
            )

            # åˆå¹¶æ•°æ®
            df = df_daily.merge(df_names, on='ts_code', how='left')

            if df_basic is not None and not df_basic.empty:
                # é¿å…åˆ—åå†²çª
                df_basic_cols = ['ts_code', 'turnover_rate', 'volume_ratio', 'pe_ttm', 'pb', 'total_mv', 'circ_mv']
                df_basic_subset = df_basic[[c for c in df_basic_cols if c in df_basic.columns]]
                df = df.merge(df_basic_subset, on='ts_code', how='left')

            # é‡å‘½ååˆ—ä¸ºä¸­æ–‡ï¼ˆä¸ akshare å…¼å®¹ï¼‰
            column_map = {
                'ts_code': 'ä»£ç ',
                'name': 'åç§°',
                'close': 'æœ€æ–°ä»·',
                'pct_chg': 'æ¶¨è·Œå¹…',
                'change': 'æ¶¨è·Œé¢',
                'vol': 'æˆäº¤é‡',
                'amount': 'æˆäº¤é¢',  # åƒå…ƒ â†’ éœ€è¦è½¬æ¢
                'open': 'ä»Šå¼€',
                'high': 'æœ€é«˜',
                'low': 'æœ€ä½',
                'pre_close': 'æ˜¨æ”¶',
                'turnover_rate': 'æ¢æ‰‹ç‡',
                'volume_ratio': 'é‡æ¯”',
                'pe_ttm': 'å¸‚ç›ˆç‡-åŠ¨æ€',
                'pb': 'å¸‚å‡€ç‡',
                'total_mv': 'æ€»å¸‚å€¼',  # ä¸‡å…ƒ
                'circ_mv': 'æµé€šå¸‚å€¼',  # ä¸‡å…ƒ
            }
            df = df.rename(columns={k: v for k, v in column_map.items() if k in df.columns})

            # è½¬æ¢æˆäº¤é¢å•ä½ï¼šåƒå…ƒ â†’ å…ƒ
            if 'æˆäº¤é¢' in df.columns:
                df['æˆäº¤é¢'] = df['æˆäº¤é¢'] * 1000

            # è½¬æ¢å¸‚å€¼å•ä½ï¼šä¸‡å…ƒ â†’ å…ƒ
            if 'æ€»å¸‚å€¼' in df.columns:
                df['æ€»å¸‚å€¼'] = df['æ€»å¸‚å€¼'] * 10000
            if 'æµé€šå¸‚å€¼' in df.columns:
                df['æµé€šå¸‚å€¼'] = df['æµé€šå¸‚å€¼'] * 10000

            # æ¸…ç†ä»£ç æ ¼å¼ï¼ˆå»æ‰ .SH/.SZ åç¼€ï¼‰
            if 'ä»£ç ' in df.columns:
                df['ä»£ç '] = df['ä»£ç '].str.replace(r'\.(SH|SZ|BJ)$', '', regex=True)

            elapsed = (datetime.now() - start_time).total_seconds()
            logger.info(f"[tushare] å…¨å¸‚åœºæ•°æ®è·å–å®Œæˆ: {len(df)} åªè‚¡ç¥¨, è€—æ—¶ {elapsed:.1f}s")

            # æ›´æ–°ç¼“å­˜
            _market_data_cache = df
            _market_data_cache_time = now

            return df.copy()

        except Exception as e:
            logger.error(f"[tushare] è·å–å…¨å¸‚åœºæ•°æ®å¤±è´¥: {e}")
            # å¦‚æœæœ‰æ—§ç¼“å­˜ï¼Œè¿”å›æ—§æ•°æ®
            if _market_data_cache is not None:
                logger.warning("[tushare] ä½¿ç”¨è¿‡æœŸç¼“å­˜æ•°æ®")
                return _market_data_cache.copy()
            return pd.DataFrame()


# ============================================================
# æ–°å¢æ•°æ®æ¥å£ï¼ˆ2024-01 æ‰©å±•ï¼‰
# ============================================================

def get_repurchase(stock_code: str) -> str:
    """
    è·å–è‚¡ç¥¨å›è´­æ•°æ®

    å›è´­æ˜¯ç®¡ç†å±‚è®¤ä¸ºè‚¡ä»·è¢«ä½ä¼°æ—¶çš„é‡è¦ä¿¡å·ï¼Œå¯¹æŠ•èµ„å†³ç­–æœ‰é‡è¦å‚è€ƒä»·å€¼ã€‚

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 

    Returns:
        å›è´­æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    try:
        pro = get_pro_api()
        ts_code = convert_stock_code(stock_code)

        # è·å–å›è´­æ•°æ®
        df = pro.repurchase(ts_code=ts_code)

        if df is None or df.empty:
            return f"æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„å›è´­æ•°æ®ï¼ˆå¯èƒ½æš‚æ— å›è´­è®¡åˆ’ï¼‰"

        result = []
        result.append("# è‚¡æƒå›è´­åˆ†æ\n")
        result.append(f"## {stock_code} å›è´­è®°å½•\n")

        # æŒ‰å…¬å‘Šæ—¥æœŸæ’åºï¼Œæœ€æ–°çš„åœ¨å‰
        df = df.sort_values('ann_date', ascending=False)

        for _, row in df.head(5).iterrows():  # æœ€è¿‘5æ¡
            result.append(f"### å…¬å‘Šæ—¥æœŸ: {row.get('ann_date', 'N/A')}")
            result.append(f"- **å›è´­è¿›åº¦**: {row.get('proc', 'N/A')}")

            # å›è´­é‡‘é¢
            exp_amount = row.get('exp_amount', 0)
            if pd.notna(exp_amount) and exp_amount > 0:
                result.append(f"- **è®¡åˆ’å›è´­é‡‘é¢**: {exp_amount/10000:.2f}äº¿å…ƒ")

            amount = row.get('amount', 0)
            if pd.notna(amount) and amount > 0:
                result.append(f"- **å·²å›è´­é‡‘é¢**: {amount/10000:.2f}äº¿å…ƒ")

            # å›è´­è‚¡æ•°
            vol = row.get('vol', 0)
            if pd.notna(vol) and vol > 0:
                result.append(f"- **å·²å›è´­è‚¡æ•°**: {vol/10000:.2f}ä¸‡è‚¡")

            # å›è´­ä»·æ ¼
            high_limit = row.get('high_limit', 0)
            if pd.notna(high_limit) and high_limit > 0:
                result.append(f"- **å›è´­ä»·æ ¼ä¸Šé™**: {high_limit:.2f}å…ƒ")

            # å›è´­ç›®çš„
            purpose = row.get('purpose', '')
            if purpose:
                result.append(f"- **å›è´­ç›®çš„**: {purpose}")

            result.append("")

        # æŠ•èµ„æç¤º
        result.append("## æŠ•èµ„æç¤º")
        result.append("- å›è´­é€šå¸¸è¡¨æ˜ç®¡ç†å±‚è®¤ä¸ºè‚¡ä»·è¢«ä½ä¼°")
        result.append("- æ³¨æ„å›è´­è¿›åº¦å’Œå®Œæˆç‡")
        result.append("- å…³æ³¨å›è´­ç›®çš„ï¼ˆæ³¨é”€/è‚¡æƒæ¿€åŠ±/å‘˜å·¥æŒè‚¡ï¼‰")

        return "\n".join(result)

    except Exception as e:
        return f"è·å–å›è´­æ•°æ®å¤±è´¥: {str(e)}"


def get_fund_shares(stock_code: str, period: str = None) -> str:
    """
    è·å–åŸºé‡‘æŒè‚¡æ•°æ®

    æŸ¥è¯¢å…¬å‹ŸåŸºé‡‘æŒæœ‰æŸåªè‚¡ç¥¨çš„æƒ…å†µï¼ˆå­£åº¦æ•°æ®ï¼‰ã€‚

    Args:
        stock_code: è‚¡ç¥¨ä»£ç ï¼ˆå¦‚ 600036.SH æˆ– 600036ï¼‰
        period: æŠ¥å‘ŠæœŸï¼Œå¦‚ "20240930"ï¼Œé»˜è®¤è·å–æœ€æ–°ä¸€æœŸ

    Returns:
        åŸºé‡‘æŒè‚¡æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    try:
        pro = get_pro_api()

        # fund_portfolio æ¥å£ä½¿ç”¨ symbol å‚æ•°ï¼ˆå¸¦åç¼€çš„å®Œæ•´ä»£ç å¦‚ 600036.SHï¼‰
        ts_code = convert_stock_code(stock_code)
        symbol = ts_code  # ä½¿ç”¨å®Œæ•´ä»£ç 

        # å¦‚æœæ²¡æœ‰æŒ‡å®šæœŸï¼Œå°è¯•è·å–æœ€è¿‘å¯ç”¨çš„å­£åº¦æ•°æ®
        # åŸºé‡‘æŒä»“æ•°æ®ä¸€èˆ¬æ»å1-2ä¸ªå­£åº¦å‘å¸ƒ
        if not period:
            # å°è¯•å‡ ä¸ªæœ€è¿‘çš„å­£åº¦æœ«ï¼Œç›´åˆ°æ‰¾åˆ°æœ‰æ•°æ®çš„
            now = datetime.now()
            quarters_to_try = []
            for i in range(6):  # å°è¯•æœ€è¿‘6ä¸ªå­£åº¦
                # è®¡ç®—å¾€å‰æ¨iä¸ªå­£åº¦çš„å­£æœ«æ—¥æœŸ
                month = now.month - (now.month - 1) % 3  # å½“å‰å­£åº¦é¦–æœˆ
                quarter_date = datetime(now.year, month, 1) - timedelta(days=1 + 90*i)
                # æ‰¾åˆ°è¯¥å­£åº¦çš„æœ«æ—¥
                qe_month = ((quarter_date.month - 1) // 3 + 1) * 3
                qe_day = 31 if qe_month == 12 else (30 if qe_month in [6, 9] else 31)
                if qe_month == 3:
                    qe_day = 31
                qe = datetime(quarter_date.year, qe_month, qe_day)
                quarters_to_try.append(qe.strftime('%Y%m%d'))

            # ä½¿ç”¨æœ€è¿‘ä¸€ä¸ªå¯èƒ½æœ‰æ•°æ®çš„å­£åº¦ï¼ˆé€šå¸¸æ˜¯2-3ä¸ªå­£åº¦å‰ï¼‰
            period = quarters_to_try[2] if len(quarters_to_try) > 2 else quarters_to_try[0]

        # è·å–åŸºé‡‘æŒè‚¡æ•°æ®
        df = pro.fund_portfolio(symbol=symbol, period=period)

        if df is None or df.empty:
            return f"æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} åœ¨ {period} æœŸçš„åŸºé‡‘æŒè‚¡æ•°æ®"

        result = []
        result.append("# åŸºé‡‘æŒè‚¡åˆ†æ\n")

        # è·å–æŠ¥å‘ŠæœŸ
        report_period = df['end_date'].iloc[0] if 'end_date' in df.columns else period
        result.append(f"## æˆªè‡³ {report_period} åŸºé‡‘æŒè‚¡æƒ…å†µ\n")

        # æŒ‰æŒè‚¡æ•°é‡æ’åº
        if 'amount' in df.columns:
            df = df.sort_values('amount', ascending=False)

        result.append("| åŸºé‡‘ä»£ç  | æŒè‚¡æ•°é‡(ä¸‡è‚¡) | å¸‚å€¼å æ¯”(%) | æµé€šè‚¡å æ¯”(%) |")
        result.append("|---------|--------------|------------|--------------|")

        for _, row in df.head(15).iterrows():
            fund_code = row.get('ts_code', 'N/A')

            amount = row.get('amount', 0)
            amount_str = f"{amount/10000:.2f}" if pd.notna(amount) else 'N/A'

            mkv_ratio = row.get('stk_mkv_ratio', 0)
            mkv_str = f"{mkv_ratio:.2f}" if pd.notna(mkv_ratio) else 'N/A'

            float_ratio = row.get('stk_float_ratio', 0)
            float_str = f"{float_ratio:.2f}" if pd.notna(float_ratio) else 'N/A'

            result.append(f"| {fund_code} | {amount_str} | {mkv_str} | {float_str} |")

        result.append("")

        # æ±‡æ€»ç»Ÿè®¡
        total_funds = len(df)
        total_amount = df['amount'].sum() if 'amount' in df.columns else 0
        avg_float_ratio = df['stk_float_ratio'].mean() if 'stk_float_ratio' in df.columns else 0

        result.append(f"**æŒè‚¡åŸºé‡‘æ•°é‡**: {total_funds} åª")
        result.append(f"**åŸºé‡‘åˆè®¡æŒè‚¡**: {total_amount/10000:.2f} ä¸‡è‚¡")
        result.append(f"**å¹³å‡æµé€šè‚¡å æ¯”**: {avg_float_ratio:.4f}%")

        result.append("\n## æŠ•èµ„æç¤º")
        if total_funds > 100:
            result.append("- åŸºé‡‘æ‰å †æŒæœ‰ï¼Œæœºæ„å…³æ³¨åº¦é«˜")
        elif total_funds > 50:
            result.append("- åŸºé‡‘æŒè‚¡è¾ƒå¤šï¼Œæœºæ„è®¤å¯åº¦è¾ƒå¥½")
        else:
            result.append("- åŸºé‡‘æŒè‚¡æ•°é‡ä¸€èˆ¬ï¼Œæœºæ„å…³æ³¨åº¦ä¸­ç­‰")

        return "\n".join(result)

    except Exception as e:
        return f"è·å–åŸºé‡‘æŒè‚¡æ•°æ®å¤±è´¥: {str(e)}"


def get_adj_factor(stock_code: str, start_date: str = None, end_date: str = None) -> str:
    """
    è·å–å¤æƒå› å­æ•°æ®

    å¤æƒå› å­ç”¨äºè®¡ç®—é™¤æƒé™¤æ¯åçš„çœŸå®ä»·æ ¼æ¶¨è·Œå¹…ã€‚

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        start_date: å¼€å§‹æ—¥æœŸ YYYYMMDD
        end_date: ç»“æŸæ—¥æœŸ YYYYMMDD

    Returns:
        å¤æƒå› å­æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    try:
        pro = get_pro_api()
        ts_code = convert_stock_code(stock_code)

        # é»˜è®¤è·å–æœ€è¿‘ä¸€å¹´æ•°æ®
        if not end_date:
            end_date = datetime.now().strftime('%Y%m%d')
        if not start_date:
            start_date = (datetime.now() - timedelta(days=365)).strftime('%Y%m%d')

        # è·å–å¤æƒå› å­
        df = pro.adj_factor(ts_code=ts_code, start_date=start_date, end_date=end_date)

        if df is None or df.empty:
            return f"æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„å¤æƒå› å­æ•°æ®"

        result = []
        result.append("# å¤æƒå› å­åˆ†æ\n")
        result.append(f"## {stock_code} å¤æƒå› å­ ({start_date} ~ {end_date})\n")

        # æŒ‰æ—¥æœŸæ’åº
        df = df.sort_values('trade_date', ascending=False)

        # è·å–æœ€æ–°å’Œæœ€æ—©çš„å¤æƒå› å­
        latest = df.iloc[0]
        earliest = df.iloc[-1]

        latest_adj = latest['adj_factor']
        earliest_adj = earliest['adj_factor']

        result.append(f"**æœ€æ–°å¤æƒå› å­**: {latest_adj:.4f} ({latest['trade_date']})")
        result.append(f"**æœŸåˆå¤æƒå› å­**: {earliest_adj:.4f} ({earliest['trade_date']})")

        # è®¡ç®—æœŸé—´å¤æƒè°ƒæ•´å¹…åº¦
        if earliest_adj > 0:
            adj_change = (latest_adj / earliest_adj - 1) * 100
            result.append(f"**æœŸé—´å¤æƒè°ƒæ•´**: {adj_change:+.2f}%")
        result.append("")

        # æ£€æµ‹é™¤æƒé™¤æ¯äº‹ä»¶ï¼ˆå¤æƒå› å­çªå˜ï¼‰
        df['adj_change'] = df['adj_factor'].diff(-1)  # ä¸å‰ä¸€å¤©æ¯”è¾ƒ
        events = df[df['adj_change'].abs() > 0.001]  # å˜åŠ¨è¶…è¿‡0.1%

        if not events.empty:
            result.append("## é™¤æƒé™¤æ¯äº‹ä»¶\n")
            result.append("| æ—¥æœŸ | å¤æƒå› å­ | å˜åŠ¨å¹…åº¦ |")
            result.append("|------|---------|---------|")

            for _, row in events.head(10).iterrows():
                change_pct = (row['adj_change'] / row['adj_factor']) * 100 if row['adj_factor'] > 0 else 0
                result.append(f"| {row['trade_date']} | {row['adj_factor']:.4f} | {change_pct:+.2f}% |")

        result.append("")
        result.append("## ä½¿ç”¨è¯´æ˜")
        result.append("- å‰å¤æƒä»·æ ¼ = åŸå§‹ä»·æ ¼ Ã— å¤æƒå› å­ / æœ€æ–°å¤æƒå› å­")
        result.append("- å¤æƒå› å­å˜åŠ¨è¡¨ç¤ºæœ‰åˆ†çº¢ã€é…è‚¡ã€é€è‚¡ç­‰äº‹ä»¶")

        return "\n".join(result)

    except Exception as e:
        return f"è·å–å¤æƒå› å­å¤±è´¥: {str(e)}"


def get_concept(stock_code: str) -> str:
    """
    è·å–è‚¡ç¥¨æ‰€å±æ¦‚å¿µæ¿å—

    äº†è§£è‚¡ç¥¨æ‰€å±çš„çƒ­ç‚¹æ¦‚å¿µï¼Œåˆ¤æ–­æ¿å—è”åŠ¨æ•ˆåº”ã€‚

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 

    Returns:
        æ¦‚å¿µæ¿å—æ•°æ®çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    try:
        pro = get_pro_api()
        ts_code = convert_stock_code(stock_code)

        # è·å–æ¦‚å¿µæ¿å—æˆåˆ†
        df = pro.concept_detail(ts_code=ts_code)

        if df is None or df.empty:
            return f"æœªæ‰¾åˆ°è‚¡ç¥¨ {stock_code} çš„æ¦‚å¿µæ¿å—æ•°æ®"

        result = []
        result.append("# æ¦‚å¿µæ¿å—åˆ†æ\n")
        result.append(f"## {stock_code} æ‰€å±æ¦‚å¿µæ¿å—\n")

        result.append("| æ¦‚å¿µåç§° | æ¦‚å¿µä»£ç  | æ¿å—è¯´æ˜ |")
        result.append("|---------|---------|---------|")

        for _, row in df.iterrows():
            concept_name = row.get('concept_name', 'N/A')
            concept_code = row.get('id', row.get('concept_code', 'N/A'))

            # å°è¯•è·å–æ¦‚å¿µè¯´æ˜
            desc = row.get('concept_desc', '')
            if not desc and 'in_date' in row:
                desc = f"çº³å…¥æ—¥æœŸ: {row['in_date']}"
            if len(desc) > 30:
                desc = desc[:30] + '...'

            result.append(f"| {concept_name} | {concept_code} | {desc} |")

        result.append("")
        result.append(f"**æ‰€å±æ¦‚å¿µæ•°é‡**: {len(df)} ä¸ª")
        result.append("")

        # æŠ•èµ„æç¤º
        result.append("## æŠ•èµ„æç¤º")
        result.append("- å…³æ³¨çƒ­ç‚¹æ¦‚å¿µæ¿å—çš„è½®åŠ¨æœºä¼š")
        result.append("- åŒä¸€æ¦‚å¿µæ¿å—å†…çš„è‚¡ç¥¨å¯èƒ½å­˜åœ¨è”åŠ¨æ•ˆåº”")
        result.append("- æ¦‚å¿µç‚’ä½œéœ€æ³¨æ„é£é™©ï¼Œå…³æ³¨åŸºæœ¬é¢æ”¯æ’‘")

        return "\n".join(result)

    except Exception as e:
        return f"è·å–æ¦‚å¿µæ¿å—å¤±è´¥: {str(e)}"


# ============================================================
# è¡Œä¸šTAMï¼ˆTotal Addressable Marketï¼‰æ•°æ®å·¥å…·
# ============================================================

# è¡Œä¸šå¸¸æ•°è¯å…¸ - ç”¨äºTAMä¼°ç®—çš„å…œåº•ç­–ç•¥
INDUSTRY_CONSTANTS = {
    # åŒ»ç–—æœåŠ¡è¡Œä¸š
    "åŒ»ç–—æœåŠ¡": {
        "growth_type": "é«˜å¢é•¿",
        "growth_range": "15-25%",
        "penetration": "ä½",
        "logic": "è¿é”æ‰©å¼ ã€åºŠä½å¢é•¿ã€ä¸“ç§‘å¤åˆ¶",
        "cr5_estimate": 0.15,
        "comps": ["çˆ±å°”çœ¼ç§‘", "é€šç­–åŒ»ç–—", "æµ·å‰äºšåŒ»ç–—"],
        "valuation_method": "PSä¼°å€¼+æœŸæƒä¼°å€¼",
        "key_metrics": ["åºŠä½æ•°å¢é•¿", "å•åº—æ”¶å…¥", "å‡€åˆ©ç‡æå‡ç©ºé—´"],
    },
    "åŒ»è¯ç”Ÿç‰©": {
        "growth_type": "ä¸­é«˜å¢é•¿",
        "growth_range": "10-20%",
        "penetration": "ä¸­",
        "logic": "åˆ›æ–°è¯ç®¡çº¿ã€é›†é‡‡å½±å“ã€å‡ºæµ·é€»è¾‘",
        "cr5_estimate": 0.20,
        "comps": ["æ’ç‘åŒ»è¯", "è¯æ˜åº·å¾·", "è¿ˆç‘åŒ»ç–—"],
        "valuation_method": "DCF+ç®¡çº¿ä¼°å€¼",
        "key_metrics": ["ç ”å‘æŠ•å…¥", "ç®¡çº¿è¿›åº¦", "æµ·å¤–æ”¶å…¥å æ¯”"],
    },
    # é“¶è¡Œé‡‘è
    "é“¶è¡Œ": {
        "growth_type": "ä½å¢é•¿",
        "growth_range": "5-10%",
        "penetration": "é«˜",
        "logic": "æ¯å·®ç®¡ç†ã€èµ„äº§è´¨é‡ã€åˆ†çº¢ç¨³å®š",
        "cr5_estimate": 0.45,
        "comps": ["å·¥å•†é“¶è¡Œ", "å»ºè®¾é“¶è¡Œ", "æ‹›å•†é“¶è¡Œ"],
        "valuation_method": "PBä¼°å€¼+è‚¡æ¯ç‡",
        "key_metrics": ["å‡€æ¯å·®", "ä¸è‰¯ç‡", "æ‹¨å¤‡è¦†ç›–ç‡", "åˆ†çº¢ç‡"],
    },
    "ä¿é™©": {
        "growth_type": "ä¸­ç­‰å¢é•¿",
        "growth_range": "8-15%",
        "penetration": "ä¸­",
        "logic": "ä¿è´¹å¢é•¿ã€æŠ•èµ„æ”¶ç›Šã€æ–°ä¸šåŠ¡ä»·å€¼",
        "cr5_estimate": 0.70,
        "comps": ["ä¸­å›½å¹³å®‰", "ä¸­å›½äººå¯¿", "ä¸­å›½å¤ªä¿"],
        "valuation_method": "å†…å«ä»·å€¼(EV)ä¼°å€¼",
        "key_metrics": ["æ–°ä¸šåŠ¡ä»·å€¼", "å†…å«ä»·å€¼", "ç»¼åˆæˆæœ¬ç‡"],
    },
    "åˆ¸å•†": {
        "growth_type": "å‘¨æœŸæ³¢åŠ¨",
        "growth_range": "-20%~+50%",
        "penetration": "é«˜",
        "logic": "æˆäº¤é‡å¼¹æ€§ã€è´¢å¯Œç®¡ç†è½¬å‹ã€æŠ•è¡Œä¸šåŠ¡",
        "cr5_estimate": 0.35,
        "comps": ["ä¸­ä¿¡è¯åˆ¸", "åæ³°è¯åˆ¸", "ä¸œæ–¹è´¢å¯Œ"],
        "valuation_method": "PBä¼°å€¼",
        "key_metrics": ["æ—¥å‡æˆäº¤é¢", "ä¸¤èä½™é¢", "èµ„ç®¡è§„æ¨¡"],
    },
    # å‘¨æœŸèµ„æº
    "æœ‰è‰²é‡‘å±": {
        "growth_type": "å‘¨æœŸæ³¢åŠ¨",
        "growth_range": "-20%~+50%",
        "penetration": "N/A",
        "logic": "å•†å“ä»·æ ¼å¼¹æ€§ã€äº§èƒ½å‘¨æœŸã€åº“å­˜å‘¨æœŸ",
        "cr5_estimate": 0.35,
        "comps": ["ç´«é‡‘çŸ¿ä¸š", "æ´›é˜³é’¼ä¸š", "æ±Ÿè¥¿é“œä¸š"],
        "valuation_method": "å‘¨æœŸè°ƒæ•´PE+èµ„æºå‚¨é‡ä¼°å€¼",
        "key_metrics": ["é“œ/é‡‘/é”‚ä»·æ ¼", "èµ„æºå‚¨é‡", "äº§èƒ½åˆ©ç”¨ç‡"],
        "commodity_link": ["æ²ªé“œ", "æ²ªé‡‘", "ç¢³é…¸é”‚"],
    },
    "ç…¤ç‚­": {
        "growth_type": "å‘¨æœŸæ³¢åŠ¨",
        "growth_range": "-30%~+80%",
        "penetration": "N/A",
        "logic": "ç…¤ä»·å¼¹æ€§ã€äº§èƒ½çº¦æŸã€é«˜åˆ†çº¢",
        "cr5_estimate": 0.30,
        "comps": ["ä¸­å›½ç¥å", "é™•è¥¿ç…¤ä¸š", "å…–çŸ¿èƒ½æº"],
        "valuation_method": "è‚¡æ¯ç‡ä¼°å€¼+å‘¨æœŸè°ƒæ•´PE",
        "key_metrics": ["åŠ¨åŠ›ç…¤ä»·æ ¼", "äº§èƒ½åˆ©ç”¨ç‡", "åˆ†çº¢ç‡"],
        "commodity_link": ["åŠ¨åŠ›ç…¤æœŸè´§", "ç„¦ç…¤æœŸè´§"],
    },
    "é’¢é“": {
        "growth_type": "å‘¨æœŸæ³¢åŠ¨",
        "growth_range": "-40%~+60%",
        "penetration": "N/A",
        "logic": "é’¢ä»·å¼¹æ€§ã€äº§èƒ½ç½®æ¢ã€ç‰¹é’¢æº¢ä»·",
        "cr5_estimate": 0.25,
        "comps": ["å®é’¢è‚¡ä»½", "åè±é’¢é“", "ä¸­ä¿¡ç‰¹é’¢"],
        "valuation_method": "PBä¼°å€¼+å‘¨æœŸè°ƒæ•´PE",
        "key_metrics": ["èºçº¹é’¢ä»·æ ¼", "å¨é’¢æ¯›åˆ©", "äº§èƒ½åˆ©ç”¨ç‡"],
        "commodity_link": ["èºçº¹é’¢æœŸè´§", "çƒ­å·æœŸè´§"],
    },
    "åŒ–å·¥": {
        "growth_type": "å‘¨æœŸæ³¢åŠ¨",
        "growth_range": "-25%~+40%",
        "penetration": "N/A",
        "logic": "äº§å“ä»·å·®ã€äº§èƒ½å‘¨æœŸã€ä¸€ä½“åŒ–ä¼˜åŠ¿",
        "cr5_estimate": 0.20,
        "comps": ["ä¸‡ååŒ–å­¦", "æ’åŠ›çŸ³åŒ–", "è£ç››çŸ³åŒ–"],
        "valuation_method": "å‘¨æœŸè°ƒæ•´PE",
        "key_metrics": ["ä¸»è¦äº§å“ä»·å·®", "äº§èƒ½åˆ©ç”¨ç‡", "æˆæœ¬ä¼˜åŠ¿"],
        "commodity_link": ["åŸæ²¹æœŸè´§", "PTAæœŸè´§"],
    },
    # æ¶ˆè´¹
    "ç™½é…’": {
        "growth_type": "ä¸­é«˜å¢é•¿",
        "growth_range": "10-20%",
        "penetration": "ä¸­",
        "logic": "ä»·æ ¼å¸¦å‡çº§ã€æ¸ é“æ‰©å¼ ã€å“ç‰Œæº¢ä»·",
        "cr5_estimate": 0.55,
        "comps": ["è´µå·èŒ…å°", "äº”ç²®æ¶²", "æ³¸å·è€çª–"],
        "valuation_method": "PEä¼°å€¼",
        "key_metrics": ["æ‰¹ä»·", "åº“å­˜å‘¨æœŸ", "ç»é”€å•†æ•°é‡"],
    },
    "é£Ÿå“é¥®æ–™": {
        "growth_type": "ä¸­ç­‰å¢é•¿",
        "growth_range": "8-15%",
        "penetration": "é«˜",
        "logic": "æ¶ˆè´¹å‡çº§ã€æ¸ é“ä¸‹æ²‰ã€å“ç±»æ‰©å¼ ",
        "cr5_estimate": 0.35,
        "comps": ["ä¼Šåˆ©è‚¡ä»½", "æµ·å¤©å‘³ä¸š", "å†œå¤«å±±æ³‰"],
        "valuation_method": "PEä¼°å€¼",
        "key_metrics": ["è¥æ”¶å¢é€Ÿ", "æ¯›åˆ©ç‡", "æ¸ é“è¦†ç›–"],
    },
    "å®¶ç”µ": {
        "growth_type": "ä½å¢é•¿",
        "growth_range": "3-8%",
        "penetration": "é«˜",
        "logic": "å­˜é‡æ¢æ–°ã€é«˜ç«¯åŒ–ã€å‡ºæµ·",
        "cr5_estimate": 0.60,
        "comps": ["ç¾çš„é›†å›¢", "æ ¼åŠ›ç”µå™¨", "æµ·å°”æ™ºå®¶"],
        "valuation_method": "PEä¼°å€¼+è‚¡æ¯ç‡",
        "key_metrics": ["å†…é”€/å¤–é”€å¢é€Ÿ", "é«˜ç«¯å æ¯”", "åˆ†çº¢ç‡"],
    },
    # ç§‘æŠ€æˆé•¿
    "æ–°èƒ½æº": {
        "growth_type": "é«˜å¢é•¿",
        "growth_range": "20-40%",
        "penetration": "ä¸­",
        "logic": "æ¸—é€ç‡æå‡ã€æŠ€æœ¯è¿­ä»£ã€äº§èƒ½æ‰©å¼ ",
        "cr5_estimate": 0.40,
        "comps": ["å®å¾·æ—¶ä»£", "æ¯”äºšè¿ª", "éš†åŸºç»¿èƒ½"],
        "valuation_method": "PE+äº§èƒ½ä¼°å€¼",
        "key_metrics": ["è£…æœºé‡", "æ¸—é€ç‡", "äº§èƒ½åˆ©ç”¨ç‡"],
    },
    "åŠå¯¼ä½“": {
        "growth_type": "é«˜å¢é•¿",
        "growth_range": "15-30%",
        "penetration": "ä½",
        "logic": "å›½äº§æ›¿ä»£ã€å‘¨æœŸå¤è‹ã€æŠ€æœ¯çªç ´",
        "cr5_estimate": 0.25,
        "comps": ["ä¸­èŠ¯å›½é™…", "éŸ¦å°”è‚¡ä»½", "åŒ—æ–¹ååˆ›"],
        "valuation_method": "PSä¼°å€¼+å‘¨æœŸè°ƒæ•´PE",
        "key_metrics": ["æ™¶åœ†ä»£å·¥ä»·æ ¼", "è®¾å¤‡è®¢å•", "å›½äº§åŒ–ç‡"],
    },
    "äº’è”ç½‘": {
        "growth_type": "ä¸­é«˜å¢é•¿",
        "growth_range": "10-25%",
        "penetration": "é«˜",
        "logic": "ç”¨æˆ·å˜ç°ã€AIèµ‹èƒ½ã€å‡ºæµ·å¢é‡",
        "cr5_estimate": 0.70,
        "comps": ["è…¾è®¯æ§è‚¡", "é˜¿é‡Œå·´å·´", "ç¾å›¢"],
        "valuation_method": "SOTP+PEä¼°å€¼",
        "key_metrics": ["MAU", "ARPU", "å˜ç°ç‡"],
    },
    # å…¬ç”¨äº‹ä¸š
    "ç”µåŠ›": {
        "growth_type": "ä½å¢é•¿",
        "growth_range": "3-8%",
        "penetration": "é«˜",
        "logic": "ç”µä»·å¸‚åœºåŒ–ã€ç»¿ç”µæº¢ä»·ã€ç¨³å®šåˆ†çº¢",
        "cr5_estimate": 0.35,
        "comps": ["é•¿æ±Ÿç”µåŠ›", "åèƒ½å›½é™…", "å›½ç”µç”µåŠ›"],
        "valuation_method": "è‚¡æ¯ç‡ä¼°å€¼",
        "key_metrics": ["ä¸Šç½‘ç”µä»·", "åˆ©ç”¨å°æ—¶æ•°", "åˆ†çº¢ç‡"],
    },
    "ç‡ƒæ°”": {
        "growth_type": "ä¸­ç­‰å¢é•¿",
        "growth_range": "8-15%",
        "penetration": "ä¸­",
        "logic": "æ°”é‡å¢é•¿ã€é¡ºä»·æœºåˆ¶ã€æ¥é©³è´¹",
        "cr5_estimate": 0.25,
        "comps": ["æ–°å¥¥è‚¡ä»½", "æ˜†ä»‘èƒ½æº", "åæ¶¦ç‡ƒæ°”"],
        "valuation_method": "PEä¼°å€¼",
        "key_metrics": ["å”®æ°”é‡å¢é€Ÿ", "ä»·å·®", "æ¥é©³æˆ·æ•°"],
    },
    # åœ°äº§å»ºç­‘
    "æˆ¿åœ°äº§": {
        "growth_type": "ä½å¢é•¿/è´Ÿå¢é•¿",
        "growth_range": "-10%~+5%",
        "penetration": "é«˜",
        "logic": "é›†ä¸­åº¦æå‡ã€åœŸå‚¨ä»·å€¼ã€æ”¿ç­–è¾¹é™…æ”¹å–„",
        "cr5_estimate": 0.25,
        "comps": ["ä¿åˆ©å‘å±•", "ä¸‡ç§‘A", "æ‹›å•†è›‡å£"],
        "valuation_method": "NAVä¼°å€¼",
        "key_metrics": ["é”€å”®é¢", "åœŸå‚¨è´§å€¼", "èèµ„æˆæœ¬"],
    },
    "å»ºç­‘": {
        "growth_type": "ä½å¢é•¿",
        "growth_range": "0-8%",
        "penetration": "é«˜",
        "logic": "è®¢å•å¢é•¿ã€ç°é‡‘æµæ”¹å–„ã€ä¸€å¸¦ä¸€è·¯",
        "cr5_estimate": 0.40,
        "comps": ["ä¸­å›½å»ºç­‘", "ä¸­å›½ä¸­é“", "ä¸­å›½äº¤å»º"],
        "valuation_method": "PEä¼°å€¼+è®¢å•ä¼°å€¼",
        "key_metrics": ["æ–°ç­¾è®¢å•", "è¥æ”¶ç¡®è®¤è¿›åº¦", "ç»è¥ç°é‡‘æµ"],
    },
}

# ç”³ä¸‡è¡Œä¸šä»£ç æ˜ å°„ï¼ˆç”¨äºè·å–è¡Œä¸šæˆåˆ†è‚¡ï¼‰
SHENWAN_INDUSTRY_CODES = {
    "é“¶è¡Œ": "801780.SI",
    "éé“¶é‡‘è": "801790.SI",
    "æˆ¿åœ°äº§": "801180.SI",
    "å»ºç­‘è£…é¥°": "801720.SI",
    "å»ºç­‘ææ–™": "801710.SI",
    "é’¢é“": "801040.SI",
    "æœ‰è‰²é‡‘å±": "801050.SI",
    "ç…¤ç‚­": "801020.SI",
    "çŸ³æ²¹çŸ³åŒ–": "801960.SI",
    "åŒ–å·¥": "801030.SI",
    "ç”µåŠ›è®¾å¤‡": "801730.SI",
    "æœºæ¢°è®¾å¤‡": "801890.SI",
    "å›½é˜²å†›å·¥": "801740.SI",
    "æ±½è½¦": "801880.SI",
    "å®¶ç”¨ç”µå™¨": "801110.SI",
    "é£Ÿå“é¥®æ–™": "801120.SI",
    "çººç»‡æœé¥°": "801130.SI",
    "è½»å·¥åˆ¶é€ ": "801140.SI",
    "åŒ»è¯ç”Ÿç‰©": "801150.SI",
    "å…¬ç”¨äº‹ä¸š": "801160.SI",
    "äº¤é€šè¿è¾“": "801170.SI",
    "å•†è´¸é›¶å”®": "801200.SI",
    "ç¤¾ä¼šæœåŠ¡": "801210.SI",
    "ä¼ åª’": "801760.SI",
    "é€šä¿¡": "801770.SI",
    "è®¡ç®—æœº": "801750.SI",
    "ç”µå­": "801080.SI",
    "å†œæ—ç‰§æ¸”": "801010.SI",
    "ç»¼åˆ": "801230.SI",
    "ç¾å®¹æŠ¤ç†": "801980.SI",
    "ç¯ä¿": "801970.SI",
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# è¡Œä¸š â†’ æŒ‡æ•°/æœŸè´§ æ˜ å°„è¡¨ï¼ˆç”¨äºæ¿å—å¯¹æ¯”å’Œå•†å“è”åŠ¨åˆ†æï¼‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
INDUSTRY_TO_INDEX = {
    # å‘¨æœŸèµ„æºè¡Œä¸šï¼ˆéœ€è¦æœŸè´§è”åŠ¨ï¼‰- ç”³ä¸‡ä¸€çº§
    "æœ‰è‰²é‡‘å±": {"index": "399318.SZ", "index_name": "å›½è¯æœ‰è‰²", "futures": ["CU.SHF", "AL.SHF", "AU.SHF", "AG.SHF"]},
    "ç…¤ç‚­": {"index": "399998.SZ", "index_name": "ä¸­è¯ç…¤ç‚­", "futures": ["ZC.ZCE", "JM.DCE"]},
    "é’¢é“": {"index": "399994.SZ", "index_name": "ä¸­è¯æœ‰è‰²", "futures": ["RB.SHF", "HC.SHF"]},
    "åŒ–å·¥": {"index": "399993.SZ", "index_name": "ä¸­è¯åŒ–å·¥", "futures": ["MA.ZCE", "TA.ZCE", "PTA.ZCE"]},
    "åŸºç¡€åŒ–å·¥": {"index": "399993.SZ", "index_name": "ä¸­è¯åŒ–å·¥", "futures": ["MA.ZCE", "TA.ZCE"]},
    "çŸ³æ²¹çŸ³åŒ–": {"index": "399975.SZ", "index_name": "è¯åˆ¸é¾™å¤´", "futures": ["SC.INE", "FU.SHF"]},

    # æœ‰è‰²é‡‘å±ç»†åˆ†è¡Œä¸šï¼ˆTushareè¿”å›çš„å¯èƒ½æ˜¯ç»†åˆ†è¡Œä¸šåï¼‰
    "é“œ": {"index": "399318.SZ", "index_name": "å›½è¯æœ‰è‰²", "futures": ["CU.SHF"]},
    "é‡‘": {"index": "399318.SZ", "index_name": "å›½è¯æœ‰è‰²", "futures": ["AU.SHF"]},
    "é»„é‡‘": {"index": "399318.SZ", "index_name": "å›½è¯æœ‰è‰²", "futures": ["AU.SHF"]},
    "é“¶": {"index": "399318.SZ", "index_name": "å›½è¯æœ‰è‰²", "futures": ["AG.SHF"]},
    "ç™½é“¶": {"index": "399318.SZ", "index_name": "å›½è¯æœ‰è‰²", "futures": ["AG.SHF"]},
    "é“": {"index": "399318.SZ", "index_name": "å›½è¯æœ‰è‰²", "futures": ["AL.SHF"]},
    "é”Œ": {"index": "399318.SZ", "index_name": "å›½è¯æœ‰è‰²", "futures": ["ZN.SHF"]},
    "é“…": {"index": "399318.SZ", "index_name": "å›½è¯æœ‰è‰²", "futures": ["PB.SHF"]},
    "é•": {"index": "399318.SZ", "index_name": "å›½è¯æœ‰è‰²", "futures": ["NI.SHF"]},
    "é”¡": {"index": "399318.SZ", "index_name": "å›½è¯æœ‰è‰²", "futures": ["SN.SHF"]},
    "ç¨€åœŸ": {"index": "399318.SZ", "index_name": "å›½è¯æœ‰è‰²", "futures": None},
    "é”‚": {"index": "399318.SZ", "index_name": "å›½è¯æœ‰è‰²", "futures": ["LC.GFE"]},
    "é’´": {"index": "399318.SZ", "index_name": "å›½è¯æœ‰è‰²", "futures": None},
    "é’¨": {"index": "399318.SZ", "index_name": "å›½è¯æœ‰è‰²", "futures": None},
    "é’¼": {"index": "399318.SZ", "index_name": "å›½è¯æœ‰è‰²", "futures": None},

    # ç…¤ç‚­ç»†åˆ†è¡Œä¸š
    "ç…¤ç‚­å¼€é‡‡": {"index": "399998.SZ", "index_name": "ä¸­è¯ç…¤ç‚­", "futures": ["ZC.ZCE", "JM.DCE"]},
    "ç„¦ç‚­": {"index": "399998.SZ", "index_name": "ä¸­è¯ç…¤ç‚­", "futures": ["J.DCE", "JM.DCE"]},

    # é’¢é“ç»†åˆ†è¡Œä¸š
    "æ™®é’¢": {"index": "399994.SZ", "index_name": "ä¸­è¯æœ‰è‰²", "futures": ["RB.SHF", "HC.SHF"]},
    "ç‰¹é’¢": {"index": "399994.SZ", "index_name": "ä¸­è¯æœ‰è‰²", "futures": ["RB.SHF"]},

    # é‡‘èè¡Œä¸š
    "é“¶è¡Œ": {"index": "399986.SZ", "index_name": "ä¸­è¯é“¶è¡Œ", "futures": None},
    "éé“¶é‡‘è": {"index": "399975.SZ", "index_name": "ä¸­è¯è¯åˆ¸", "futures": None},
    "è¯åˆ¸": {"index": "399975.SZ", "index_name": "ä¸­è¯è¯åˆ¸", "futures": None},      # ä¸œæ–¹è´¢å¯Œã€ä¸­ä¿¡è¯åˆ¸ç­‰
    "ä¿é™©": {"index": "399986.SZ", "index_name": "ä¸­è¯é“¶è¡Œ", "futures": None},       # ä¿é™©ä¸é“¶è¡ŒåŒå±å¤§é‡‘è
    "å¤šå…ƒé‡‘è": {"index": "399975.SZ", "index_name": "ä¸­è¯è¯åˆ¸", "futures": None},   # ä¿¡æ‰˜ã€æœŸè´§ç­‰

    # æˆé•¿è¡Œä¸š
    "ç”µå­": {"index": "399678.SZ", "index_name": "æ·±è¯ç”µå­", "futures": None},
    "è®¡ç®—æœº": {"index": "399996.SZ", "index_name": "ä¸­è¯ä¿¡æ¯", "futures": None},
    "é€šä¿¡": {"index": "399996.SZ", "index_name": "ä¸­è¯ä¿¡æ¯", "futures": None},
    "ä¼ åª’": {"index": "399996.SZ", "index_name": "ä¸­è¯ä¿¡æ¯", "futures": None},
    "åŒ»è¯ç”Ÿç‰©": {"index": "399989.SZ", "index_name": "ä¸­è¯åŒ»è¯", "futures": None},

    # åŠå¯¼ä½“åŠé›†æˆç”µè·¯ï¼ˆç§‘æŠ€ç¡¬ä»¶ï¼‰- ä¸­èŠ¯å›½é™…ç­‰
    "åŠå¯¼ä½“": {"index": "399976.SZ", "index_name": "ä¸­è¯åŠå¯¼", "futures": None},
    "é›†æˆç”µè·¯": {"index": "399976.SZ", "index_name": "ä¸­è¯åŠå¯¼", "futures": None},
    "èŠ¯ç‰‡": {"index": "399976.SZ", "index_name": "ä¸­è¯åŠå¯¼", "futures": None},
    "åŠå¯¼ä½“ææ–™": {"index": "399976.SZ", "index_name": "ä¸­è¯åŠå¯¼", "futures": None},
    "åŠå¯¼ä½“è®¾å¤‡": {"index": "399976.SZ", "index_name": "ä¸­è¯åŠå¯¼", "futures": None},

    # ç”µå­å…ƒå™¨ä»¶ï¼ˆæ¶ˆè´¹ç”µå­ï¼‰
    "å…ƒå™¨ä»¶": {"index": "399978.SZ", "index_name": "ä¸­è¯å…ƒå™¨ä»¶", "futures": None},
    "ç”µå­å…ƒå™¨ä»¶": {"index": "399978.SZ", "index_name": "ä¸­è¯å…ƒå™¨ä»¶", "futures": None},
    "PCB": {"index": "399978.SZ", "index_name": "ä¸­è¯å…ƒå™¨ä»¶", "futures": None},
    "è¢«åŠ¨å…ƒä»¶": {"index": "399978.SZ", "index_name": "ä¸­è¯å…ƒå™¨ä»¶", "futures": None},

    # é€šä¿¡è®¾å¤‡ç»†åˆ†
    "é€šä¿¡è®¾å¤‡": {"index": "399996.SZ", "index_name": "ä¸­è¯ä¿¡æ¯", "futures": None},
    "é€šä¿¡æœåŠ¡": {"index": "399996.SZ", "index_name": "ä¸­è¯ä¿¡æ¯", "futures": None},
    "å…‰é€šä¿¡": {"index": "399996.SZ", "index_name": "ä¸­è¯ä¿¡æ¯", "futures": None},

    # è½¯ä»¶ä¸ITæœåŠ¡
    "è½¯ä»¶æœåŠ¡": {"index": "399996.SZ", "index_name": "ä¸­è¯ä¿¡æ¯", "futures": None},
    "è½¯ä»¶å¼€å‘": {"index": "399996.SZ", "index_name": "ä¸­è¯ä¿¡æ¯", "futures": None},
    "ITæœåŠ¡": {"index": "399996.SZ", "index_name": "ä¸­è¯ä¿¡æ¯", "futures": None},
    "äº’è”ç½‘æœåŠ¡": {"index": "399996.SZ", "index_name": "ä¸­è¯ä¿¡æ¯", "futures": None},
    "äº‘è®¡ç®—": {"index": "399996.SZ", "index_name": "ä¸­è¯ä¿¡æ¯", "futures": None},

    # å…‰å­¦å…‰ç”µ
    "å…‰å­¦å…‰ç”µå­": {"index": "399678.SZ", "index_name": "æ·±è¯ç”µå­", "futures": None},
    "æ¶ˆè´¹ç”µå­": {"index": "399678.SZ", "index_name": "æ·±è¯ç”µå­", "futures": None},
    "ç”µåŠ›è®¾å¤‡": {"index": "399808.SZ", "index_name": "ä¸­è¯æ–°èƒ½", "futures": None},
    # ç”µåŠ›è®¾å¤‡ç»†åˆ†è¡Œä¸šï¼ˆTushareè¿”å›çš„å¯èƒ½æ˜¯ä¸åŒåç§°ï¼‰
    "ç”µæ°”è®¾å¤‡": {"index": "399808.SZ", "index_name": "ä¸­è¯æ–°èƒ½", "futures": None},  # å®å¾·æ—¶ä»£ç­‰
    "ç”µå™¨ä»ªè¡¨": {"index": "399808.SZ", "index_name": "ä¸­è¯æ–°èƒ½", "futures": None},  # å…¼å®¹æ—§ç‰ˆåˆ†ç±»
    "ç”µæºè®¾å¤‡": {"index": "399808.SZ", "index_name": "ä¸­è¯æ–°èƒ½", "futures": None},  # ç»†åˆ†
    "æ–°èƒ½æº": {"index": "399808.SZ", "index_name": "ä¸­è¯æ–°èƒ½", "futures": None},    # æ–°èƒ½æºæ•´ä½“
    "å…‰ä¼è®¾å¤‡": {"index": "399808.SZ", "index_name": "ä¸­è¯æ–°èƒ½", "futures": None},  # å…‰ä¼ç»†åˆ†
    "é£ç”µè®¾å¤‡": {"index": "399808.SZ", "index_name": "ä¸­è¯æ–°èƒ½", "futures": None},  # é£ç”µç»†åˆ†
    "å‚¨èƒ½è®¾å¤‡": {"index": "399808.SZ", "index_name": "ä¸­è¯æ–°èƒ½", "futures": None},  # å‚¨èƒ½ç»†åˆ†
    "ç”µæ± ": {"index": "399808.SZ", "index_name": "ä¸­è¯æ–°èƒ½", "futures": None},      # ç”µæ± ç»†åˆ†

    # æ¶ˆè´¹è¡Œä¸š
    "é£Ÿå“é¥®æ–™": {"index": "399987.SZ", "index_name": "ä¸­è¯é…’", "futures": None},
    "å®¶ç”¨ç”µå™¨": {"index": "399987.SZ", "index_name": "ä¸­è¯é…’", "futures": None},
    "æ±½è½¦": {"index": "399971.SZ", "index_name": "ä¸­è¯æ±½è½¦", "futures": None},
    "å•†è´¸é›¶å”®": {"index": "399971.SZ", "index_name": "ä¸­è¯æ±½è½¦", "futures": None},
    "ç¤¾ä¼šæœåŠ¡": {"index": "399971.SZ", "index_name": "ä¸­è¯æ±½è½¦", "futures": None},
    "çººç»‡æœé¥°": {"index": "399971.SZ", "index_name": "ä¸­è¯æ±½è½¦", "futures": None},
    "ç¾å®¹æŠ¤ç†": {"index": "399971.SZ", "index_name": "ä¸­è¯æ±½è½¦", "futures": None},

    # å…¶ä»–è¡Œä¸š
    "æˆ¿åœ°äº§": {"index": "399393.SZ", "index_name": "å›½è¯åœ°äº§", "futures": None},
    "å»ºç­‘è£…é¥°": {"index": "399393.SZ", "index_name": "å›½è¯åœ°äº§", "futures": None},
    "å»ºç­‘ææ–™": {"index": "399393.SZ", "index_name": "å›½è¯åœ°äº§", "futures": None},
    "äº¤é€šè¿è¾“": {"index": "399106.SZ", "index_name": "æ·±è¯ç»¼æŒ‡", "futures": None},
    "å…¬ç”¨äº‹ä¸š": {"index": "399106.SZ", "index_name": "æ·±è¯ç»¼æŒ‡", "futures": None},
    "æœºæ¢°è®¾å¤‡": {"index": "399106.SZ", "index_name": "æ·±è¯ç»¼æŒ‡", "futures": None},
    "å›½é˜²å†›å·¥": {"index": "399106.SZ", "index_name": "æ·±è¯ç»¼æŒ‡", "futures": None},
    "è½»å·¥åˆ¶é€ ": {"index": "399106.SZ", "index_name": "æ·±è¯ç»¼æŒ‡", "futures": None},
    "å†œæ—ç‰§æ¸”": {"index": "399106.SZ", "index_name": "æ·±è¯ç»¼æŒ‡", "futures": None},
    "ç¯ä¿": {"index": "399106.SZ", "index_name": "æ·±è¯ç»¼æŒ‡", "futures": None},
    "ç»¼åˆ": {"index": "399106.SZ", "index_name": "æ·±è¯ç»¼æŒ‡", "futures": None},

    # é»˜è®¤å€¼
    "_default": {"index": "000300.SH", "index_name": "æ²ªæ·±300", "futures": None},
}

# å‘¨æœŸè¡Œä¸šé›†åˆï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦éœ€è¦æœŸè´§è”åŠ¨åˆ†æï¼‰
# åŒ…å«ç”³ä¸‡ä¸€çº§è¡Œä¸šå’Œç»†åˆ†è¡Œä¸š
CYCLIC_INDUSTRIES = {
    # ç”³ä¸‡ä¸€çº§
    "æœ‰è‰²é‡‘å±", "ç…¤ç‚­", "é’¢é“", "åŒ–å·¥", "åŸºç¡€åŒ–å·¥", "çŸ³æ²¹çŸ³åŒ–",
    # æœ‰è‰²ç»†åˆ†
    "é“œ", "é‡‘", "é»„é‡‘", "é“¶", "ç™½é“¶", "é“", "é”Œ", "é“…", "é•", "é”¡", "ç¨€åœŸ", "é”‚", "é’´", "é’¨", "é’¼",
    # ç…¤ç‚­ç»†åˆ†
    "ç…¤ç‚­å¼€é‡‡", "ç„¦ç‚­",
    # é’¢é“ç»†åˆ†
    "æ™®é’¢", "ç‰¹é’¢",
}


def get_industry_index_code(industry: str) -> str:
    """æ ¹æ®è¡Œä¸šåç§°è·å–å¯¹åº”çš„æŒ‡æ•°ä»£ç """
    mapping = INDUSTRY_TO_INDEX.get(industry, INDUSTRY_TO_INDEX["_default"])
    return mapping["index"]


def get_industry_futures_codes(industry: str) -> list:
    """æ ¹æ®è¡Œä¸šåç§°è·å–å¯¹åº”çš„æœŸè´§ä»£ç åˆ—è¡¨"""
    mapping = INDUSTRY_TO_INDEX.get(industry, INDUSTRY_TO_INDEX["_default"])
    return mapping.get("futures") or []


def is_cyclic_industry(industry: str) -> bool:
    """åˆ¤æ–­æ˜¯å¦ä¸ºå‘¨æœŸè¡Œä¸šï¼ˆéœ€è¦æœŸè´§è”åŠ¨åˆ†æï¼‰"""
    return industry in CYCLIC_INDUSTRIES


def get_industry_index_name(industry: str) -> str:
    """æ ¹æ®è¡Œä¸šåç§°è·å–å¯¹åº”çš„æŒ‡æ•°åç§°"""
    mapping = INDUSTRY_TO_INDEX.get(industry, INDUSTRY_TO_INDEX["_default"])
    return mapping["index_name"]


def get_industry_tam_data(industry: str, stock_code: str = None) -> str:
    """
    è·å–è¡Œä¸šTAMï¼ˆTotal Addressable Marketï¼‰å’Œå¸‚åœºæ ¼å±€æ•°æ®

    é‡‡ç”¨ä¸‰çº§é™çº§ç­–ç•¥ï¼š
    - Level 1: ç²¾ç¡®TAMæ•°æ®ï¼ˆå¦‚æœ‰è¡Œä¸šç ”æŠ¥æ•°æ®ï¼‰
    - Level 2: Top5è¥æ”¶ä¼°ç®— + è¡Œä¸šç‰¹å¾ï¼ˆä½¿ç”¨Tushareæ•°æ®ï¼‰
    - Level 3: è¡Œä¸šå¸¸æ•°è¯å…¸æè¿°ï¼ˆå…œåº•æ–¹æ¡ˆï¼‰

    Args:
        industry: è¡Œä¸šåç§°ï¼ˆå¦‚"åŒ»ç–—æœåŠ¡"ã€"é“¶è¡Œ"ã€"æœ‰è‰²é‡‘å±"ç­‰ï¼‰
        stock_code: å¯é€‰ï¼Œè‚¡ç¥¨ä»£ç ï¼Œç”¨äºç¡®å®šå…·ä½“è¡Œä¸šå½’å±

    Returns:
        è¡Œä¸šTAMä¼°ç®—ã€å¢é•¿ç‰¹å¾ã€ç«äº‰æ ¼å±€çš„æ ¼å¼åŒ–å­—ç¬¦ä¸²
    """
    try:
        pro = get_pro_api()
        result = []
        result.append(f"# è¡Œä¸šTAMä¸å¸‚åœºæ ¼å±€åˆ†æ\n")
        result.append(f"**ç›®æ ‡è¡Œä¸š**: {industry}\n")

        # å°è¯•åŒ¹é…è¡Œä¸šå¸¸æ•°
        industry_info = None
        matched_industry = None

        # ç²¾ç¡®åŒ¹é…
        if industry in INDUSTRY_CONSTANTS:
            industry_info = INDUSTRY_CONSTANTS[industry]
            matched_industry = industry
        else:
            # æ¨¡ç³ŠåŒ¹é…
            for key in INDUSTRY_CONSTANTS:
                if key in industry or industry in key:
                    industry_info = INDUSTRY_CONSTANTS[key]
                    matched_industry = key
                    break

        # Level 2: å°è¯•è·å–Top5æ•°æ®è¿›è¡ŒTAMä¼°ç®—
        level2_success = False
        if matched_industry and matched_industry in SHENWAN_INDUSTRY_CODES:
            try:
                index_code = SHENWAN_INDUSTRY_CODES[matched_industry]

                # è·å–è¡Œä¸šæˆåˆ†è‚¡
                df_members = pro.index_member(index_code=index_code)
                if df_members is not None and not df_members.empty:
                    # è·å–æˆåˆ†è‚¡çš„å¸‚å€¼å’Œè¥æ”¶æ•°æ®
                    member_codes = df_members['con_code'].tolist()[:20]  # å–å‰20åªè®¡ç®—

                    # è·å–æœ€æ–°è´¢åŠ¡æ•°æ®
                    total_revenue = 0
                    total_market_cap = 0
                    company_data = []

                    for code in member_codes[:10]:  # å–Top10
                        try:
                            # è·å–å¸‚å€¼æ•°æ®
                            df_basic = pro.daily_basic(
                                ts_code=code,
                                fields='ts_code,total_mv,pe_ttm,pb'
                            )
                            if df_basic is not None and not df_basic.empty:
                                mv = df_basic.iloc[0].get('total_mv', 0)
                                if mv and mv > 0:
                                    total_market_cap += mv

                            # è·å–æœ€æ–°å¹´æŠ¥è¥æ”¶
                            df_income = pro.income(
                                ts_code=code,
                                fields='ts_code,end_date,revenue,n_income'
                            )
                            if df_income is not None and not df_income.empty:
                                # å–æœ€æ–°ä¸€æœŸ
                                df_income = df_income.sort_values('end_date', ascending=False)
                                revenue = df_income.iloc[0].get('revenue', 0)
                                if revenue and revenue > 0:
                                    total_revenue += revenue
                                    company_data.append({
                                        'code': code,
                                        'revenue': revenue / 1e8,  # è½¬æ¢ä¸ºäº¿å…ƒ
                                        'market_cap': mv / 1e4 if mv else 0  # è½¬æ¢ä¸ºäº¿å…ƒ
                                    })
                        except Exception:
                            continue

                    if total_revenue > 0 and industry_info:
                        cr5 = industry_info.get('cr5_estimate', 0.3)
                        # ä¼°ç®—è¡Œä¸šTAM
                        top10_revenue = total_revenue / 1e8  # äº¿å…ƒ
                        estimated_tam = top10_revenue / cr5 if cr5 > 0 else top10_revenue * 3

                        result.append("## Level 2: Topä¼ä¸šä¼°ç®—\n")
                        result.append(f"**æ•°æ®æ¥æº**: Tushareè¡Œä¸šæˆåˆ†è‚¡è´¢åŠ¡æ•°æ®\n")
                        result.append(f"**é‡‡æ ·èŒƒå›´**: {matched_industry}è¡Œä¸šTop10ä¸Šå¸‚å…¬å¸\n")
                        result.append(f"**Top10åˆè®¡è¥æ”¶**: {top10_revenue:.1f} äº¿å…ƒ\n")
                        result.append(f"**è¡Œä¸šé›†ä¸­åº¦å‡è®¾(CR5)**: {cr5*100:.0f}%\n")
                        result.append(f"**ä¼°ç®—è¡Œä¸šTAM**: {estimated_tam:.0f} äº¿å…ƒ\n")
                        result.append(f"**Top10åˆè®¡å¸‚å€¼**: {total_market_cap/1e4:.0f} äº¿å…ƒ\n")
                        result.append("")

                        # Top5è¯¦æƒ…
                        if company_data:
                            company_data.sort(key=lambda x: x['revenue'], reverse=True)
                            result.append("### Top5ä¼ä¸šè¥æ”¶")
                            result.append("| æ’å | ä»£ç  | è¥æ”¶(äº¿) | å¸‚å€¼(äº¿) |")
                            result.append("|-----|------|---------|---------|")
                            for i, c in enumerate(company_data[:5]):
                                result.append(f"| {i+1} | {c['code']} | {c['revenue']:.1f} | {c['market_cap']:.0f} |")
                            result.append("")

                        level2_success = True

            except Exception as e:
                result.append(f"*Level 2æ•°æ®è·å–å¼‚å¸¸: {str(e)[:50]}*\n")

        # Level 3: è¡Œä¸šå¸¸æ•°è¯å…¸ï¼ˆå…œåº•æˆ–è¡¥å……ï¼‰
        if industry_info:
            result.append("## è¡Œä¸šç‰¹å¾ç”»åƒ\n")
            result.append(f"**å¢é•¿ç±»å‹**: {industry_info.get('growth_type', 'N/A')}\n")
            result.append(f"**å¢é€ŸåŒºé—´**: {industry_info.get('growth_range', 'N/A')}\n")
            result.append(f"**æ¸—é€ç‡æ°´å¹³**: {industry_info.get('penetration', 'N/A')}\n")
            result.append(f"**æ ¸å¿ƒé€»è¾‘**: {industry_info.get('logic', 'N/A')}\n")
            result.append(f"**æ¨èä¼°å€¼æ–¹æ³•**: {industry_info.get('valuation_method', 'N/A')}\n")
            result.append("")

            # å¯æ¯”å…¬å¸
            comps = industry_info.get('comps', [])
            if comps:
                result.append(f"**è¡Œä¸šé¾™å¤´**: {', '.join(comps)}\n")

            # å…³é”®æŒ‡æ ‡
            key_metrics = industry_info.get('key_metrics', [])
            if key_metrics:
                result.append(f"**å…³é”®è·Ÿè¸ªæŒ‡æ ‡**: {', '.join(key_metrics)}\n")

            # å•†å“è”åŠ¨ï¼ˆå‘¨æœŸè‚¡ï¼‰
            commodity_link = industry_info.get('commodity_link', [])
            if commodity_link:
                result.append(f"**å•†å“ä»·æ ¼è”åŠ¨**: {', '.join(commodity_link)}\n")

            result.append("")

            # å¤šå¤´ç­–ç•¥æç¤º
            result.append("## å¤šå¤´ç­–ç•¥é€‚ç”¨æ€§\n")
            growth_type = industry_info.get('growth_type', '')
            if 'é«˜å¢é•¿' in growth_type:
                result.append("**é€‚ç”¨ç­–ç•¥**: æˆé•¿è‚¡ç»ˆå±€æ€ç»´\n")
                result.append("- TAMå€’æ¨æ³•ï¼šå¸‚åœºè§„æ¨¡ Ã— ä»½é¢å‡è®¾ = æœªæ¥è¥æ”¶\n")
                result.append("- PSå¯¹æ ‡æ³•ï¼šå¯¹æ¯”å¯æ¯”å…¬å¸æ‰©å¼ æœŸPS\n")
                result.append("- æœŸæƒä¼°å€¼ï¼šåŸºç¡€ä¸šåŠ¡ + æŠ€æœ¯/äº§èƒ½æœŸæƒ\n")
            elif 'å‘¨æœŸ' in growth_type:
                result.append("**é€‚ç”¨ç­–ç•¥**: å‘¨æœŸè‚¡é€†å‘å¸ƒå±€\n")
                result.append("- å‘¨æœŸæ‚–è®ºï¼šé«˜PE=ç›ˆåˆ©åº•éƒ¨=ä¹°å…¥ä¿¡å·\n")
                result.append("- äº§èƒ½å‡ºæ¸…ï¼šç«äº‰å¯¹æ‰‹é€€å‡º=é¾™å¤´çº¢åˆ©\n")
                result.append("- å•†å“å¼¹æ€§ï¼šä»·æ ¼å›å‡=åˆ©æ¶¦é«˜å¼¹æ€§\n")
            else:
                result.append("**é€‚ç”¨ç­–ç•¥**: ä»·å€¼è‚¡æ—¶é—´å¤åˆ©\n")
                result.append("- è‚¡æ¯å¤åˆ©ï¼šè‚¡æ¯å†æŠ•èµ„çš„é•¿æœŸå¢å€¼\n")
                result.append("- å‡å€¼å›å½’ï¼šå†å²åˆ†ä½çš„å‡å€¼å›å½’æœºä¼š\n")
                result.append("- èµ„äº§é‡ä¼°ï¼šPBç ´å‡€æ—¶çš„éšè—ä»·å€¼\n")

        else:
            # æœªåŒ¹é…åˆ°è¡Œä¸šå¸¸æ•°
            result.append("## è¡Œä¸šæ•°æ®çŠ¶æ€\n")
            result.append(f"**æ³¨æ„**: æœªåœ¨é¢„è®¾è¡Œä¸šåº“ä¸­æ‰¾åˆ°ã€Œ{industry}ã€çš„ç²¾ç¡®åŒ¹é…\n")
            result.append("å»ºè®®ä½¿ç”¨åŸºæœ¬é¢æŠ¥å‘Šä¸­çš„è¡Œä¸šåˆ¤æ–­ï¼Œæˆ–æŒ‡å®šæ›´å…·ä½“çš„è¡Œä¸šåç§°\n")
            result.append("")
            result.append("**å¯ç”¨è¡Œä¸š**: " + ", ".join(list(INDUSTRY_CONSTANTS.keys())[:10]) + "...\n")

        # æ•°æ®æ—¶æ•ˆæ€§æç¤º
        result.append("\n---")
        result.append("*æ•°æ®è¯´æ˜: TAMä¼°ç®—åŸºäºä¸Šå¸‚å…¬å¸å…¬å¼€è´¢åŠ¡æ•°æ®ï¼Œä»…ä¾›å‚è€ƒ*")

        return "\n".join(result)

    except Exception as e:
        return f"è·å–è¡Œä¸šTAMæ•°æ®å¤±è´¥: {str(e)}"
